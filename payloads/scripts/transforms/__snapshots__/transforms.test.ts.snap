// Vitest Snapshot v1, https://vitest.dev/guide/snapshot.html

exports[`anthropic → chat-completions > complexReasoningRequest > request 1`] = `
{
  "max_completion_tokens": 20000,
  "messages": [
    {
      "content": "There is a digital clock, with minutes and hours in the form of 00:00. The clock shows all times from 00:00 to 23:59 and repeating. Imagine you had a list of all these times. Which digit(s) is the most common and which is the rarest? Can you find their percentage?",
      "role": "user",
    },
  ],
  "model": "gpt-5-nano",
}
`;

exports[`anthropic → chat-completions > complexReasoningRequest > response 1`] = `
{
  "content": [
    {
      "text": "Total times: 24 hours × 60 minutes = 1440 times. Each time has 4 digits (HHMM), so 1440 × 4 = 5760 digits in total.

Count digits in each position:

- Hour tens (H1): 0 for 00–09 (10 hours) and 1 for 10–19 (10 hours), 2 for 20–23 (4 hours). So H1 contributes: 0→600, 1→600, 2→240, others→0.
- Hour units (H2): digits 0,1,2,3 appear 3 times each (00,10,20 etc. for 0–3), digits 4–9 appear 2 times each. Across all hours: 0→180, 1→180, 2→180, 3→180, 4→120, 5→120, 6→120, 7→120, 8→120, 9→120.
- Minute tens (M1): digits 0–5 each appear 240 times; digits 6–9 never appear here. So 0→240, 1→240, 2→240, 3→240, 4→240, 5→240, others→0.
- Minute units (M2): each digit 0–9 appears 144 times.

Sum per digit (0–9):

- 0: 600 + 180 + 240 + 144 = 1,164
- 1: 600 + 180 + 240 + 144 = 1,164
- 2: 240 + 180 + 240 + 144 = 804
- 3: 0   + 180 + 240 + 144 = 564
- 4: 0   + 120 + 240 + 144 = 504
- 5: 0   + 120 + 240 + 144 = 504
- 6: 0   + 120 + 0   + 144 = 264
- 7: 0   + 120 + 0   + 144 = 264
- 8: 0   + 120 + 0   + 144 = 264
- 9: 0   + 120 + 0   + 144 = 264

From these counts:
- The most common digits are 0 and 1, each appearing 1,164 times (out of 5,760 digits), i.e., 1,164 / 5,760 ≈ 20.21%.
- The rarest digits are 6, 7, 8, and 9, each appearing 264 times, i.e., 264 / 5,760 ≈ 4.58%.

So: most common - digits 0 and 1 (about 20.21% each); rarest - digits 6–9 (about 4.58% each).",
      "type": "text",
    },
  ],
  "id": "msg_transformed",
  "model": "gpt-5-nano-2025-08-07",
  "role": "assistant",
  "stop_reason": "end_turn",
  "type": "message",
  "usage": {
    "cache_read_input_tokens": 0,
    "input_tokens": 74,
    "output_tokens": 6276,
  },
}
`;

exports[`anthropic → chat-completions > multimodalRequest > request 1`] = `
{
  "max_completion_tokens": 300,
  "messages": [
    {
      "content": [
        {
          "text": "What do you see in this image?",
          "type": "text",
        },
        {
          "image_url": {
            "url": "data:image/jpeg;base64,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",
          },
          "type": "image_url",
        },
      ],
      "role": "user",
    },
  ],
  "model": "gpt-5-nano",
}
`;

exports[`anthropic → chat-completions > multimodalRequest > response 1`] = `
{
  "content": [
    {
      "text": "",
      "type": "text",
    },
  ],
  "id": "msg_transformed",
  "model": "gpt-5-nano-2025-08-07",
  "role": "assistant",
  "stop_reason": "max_tokens",
  "type": "message",
  "usage": {
    "cache_read_input_tokens": 0,
    "input_tokens": 99,
    "output_tokens": 300,
  },
}
`;

exports[`anthropic → chat-completions > reasoningRequest > request 1`] = `
{
  "max_completion_tokens": 20000,
  "messages": [
    {
      "content": "Solve this step by step: If a train travels 60 mph for 2 hours, then 80 mph for 1 hour, what's the average speed?",
      "role": "user",
    },
  ],
  "model": "gpt-5-nano",
}
`;

exports[`anthropic → chat-completions > reasoningRequest > response 1`] = `
{
  "content": [
    {
      "text": "Step 1: Distance for first part = speed × time = 60 mph × 2 h = 120 miles.
Step 2: Distance for second part = 80 mph × 1 h = 80 miles.
Step 3: Total distance = 120 + 80 = 200 miles.
Step 4: Total time = 2 + 1 = 3 hours.
Step 5: Average speed = total distance / total time = 200 / 3 mph = 66 2/3 mph (about 66.67 mph).

Answer: 66 2/3 mph.",
      "type": "text",
    },
  ],
  "id": "msg_transformed",
  "model": "gpt-5-nano-2025-08-07",
  "role": "assistant",
  "stop_reason": "end_turn",
  "type": "message",
  "usage": {
    "cache_read_input_tokens": 0,
    "input_tokens": 38,
    "output_tokens": 454,
  },
}
`;

exports[`anthropic → chat-completions > reasoningRequestTruncated > request 1`] = `
{
  "max_completion_tokens": 100,
  "messages": [
    {
      "content": "Solve this step by step: If a train travels 60 mph for 2 hours, then 80 mph for 1 hour, what's the average speed?",
      "role": "user",
    },
  ],
  "model": "gpt-5-nano",
}
`;

exports[`anthropic → chat-completions > reasoningRequestTruncated > response 1`] = `
{
  "content": [
    {
      "text": "",
      "type": "text",
    },
  ],
  "id": "msg_transformed",
  "model": "gpt-5-nano-2025-08-07",
  "role": "assistant",
  "stop_reason": "max_tokens",
  "type": "message",
  "usage": {
    "cache_read_input_tokens": 0,
    "input_tokens": 38,
    "output_tokens": 100,
  },
}
`;

exports[`anthropic → chat-completions > reasoningWithOutput > request 1`] = `
{
  "max_completion_tokens": 20000,
  "messages": [
    {
      "content": "What color is the sky?",
      "role": "user",
    },
  ],
  "model": "gpt-5-nano",
}
`;

exports[`anthropic → chat-completions > reasoningWithOutput > response 1`] = `
{
  "content": [
    {
      "text": "Typically blue during the day. The sky looks blue because sunlight scattering by Earth's atmosphere scatters shorter (blue) wavelengths more than longer (red). At sunrise and sunset, the light passes through more air, so more blue is scattered out and the sky takes on red/orange/pink hues. It can appear gray on cloudy days, and dark/black at night. In space, without atmosphere, the sky is black. If you want, tell me your location or time and I can describe the current color.",
      "type": "text",
    },
  ],
  "id": "msg_transformed",
  "model": "gpt-5-nano-2025-08-07",
  "role": "assistant",
  "stop_reason": "end_turn",
  "type": "message",
  "usage": {
    "cache_read_input_tokens": 0,
    "input_tokens": 12,
    "output_tokens": 752,
  },
}
`;

exports[`anthropic → chat-completions > simpleRequest > request 1`] = `
{
  "max_completion_tokens": 20000,
  "messages": [
    {
      "content": "What is the capital of France?",
      "role": "user",
    },
  ],
  "model": "gpt-5-nano",
}
`;

exports[`anthropic → chat-completions > simpleRequest > response 1`] = `
{
  "content": [
    {
      "text": "Paris.",
      "type": "text",
    },
  ],
  "id": "msg_transformed",
  "model": "gpt-5-nano-2025-08-07",
  "role": "assistant",
  "stop_reason": "end_turn",
  "type": "message",
  "usage": {
    "cache_read_input_tokens": 0,
    "input_tokens": 13,
    "output_tokens": 203,
  },
}
`;

exports[`anthropic → chat-completions > systemMessageArrayContent > request 1`] = `
{
  "max_completion_tokens": 300,
  "messages": [
    {
      "content": [
        {
          "text": "You are a helpful data analyst. The default data source is project_logs with id abc-123.",
          "type": "text",
        },
      ],
      "role": "system",
    },
    {
      "content": "What errors occurred recently?",
      "role": "user",
    },
  ],
  "model": "gpt-5-nano",
}
`;

exports[`anthropic → chat-completions > systemMessageArrayContent > response 1`] = `
{
  "content": [
    {
      "text": "",
      "type": "text",
    },
  ],
  "id": "msg_transformed",
  "model": "gpt-5-nano-2025-08-07",
  "role": "assistant",
  "stop_reason": "max_tokens",
  "type": "message",
  "usage": {
    "cache_read_input_tokens": 0,
    "input_tokens": 11,
    "output_tokens": 300,
  },
}
`;

exports[`anthropic → chat-completions > toolCallRequest > request 1`] = `
{
  "max_completion_tokens": 20000,
  "messages": [
    {
      "content": "What's the weather like in San Francisco?",
      "role": "user",
    },
  ],
  "model": "gpt-5-nano",
  "tool_choice": "auto",
  "tools": [
    {
      "function": {
        "description": "Get the current weather for a location",
        "name": "get_weather",
        "parameters": {
          "properties": {
            "location": {
              "description": "The city and state, e.g. San Francisco, CA",
              "type": "string",
            },
          },
          "required": [
            "location",
          ],
          "type": "object",
        },
      },
      "type": "function",
    },
  ],
}
`;

exports[`anthropic → chat-completions > toolCallRequest > response 1`] = `
{
  "content": [
    {
      "id": "call_a3mN6ADjJKbiKIuOVc0tY4C9",
      "input": {
        "location": "San Francisco, CA",
      },
      "name": "get_weather",
      "type": "tool_use",
    },
  ],
  "id": "msg_transformed",
  "model": "gpt-5-nano-2025-08-07",
  "role": "assistant",
  "stop_reason": "tool_use",
  "type": "message",
  "usage": {
    "cache_read_input_tokens": 0,
    "input_tokens": 148,
    "output_tokens": 218,
  },
}
`;

exports[`anthropic → responses > complexReasoningRequest > request 1`] = `
{
  "input": [
    {
      "content": "There is a digital clock, with minutes and hours in the form of 00:00. The clock shows all times from 00:00 to 23:59 and repeating. Imagine you had a list of all these times. Which digit(s) is the most common and which is the rarest? Can you find their percentage?",
      "role": "user",
    },
  ],
  "max_output_tokens": 20000,
  "model": "gpt-5-nano",
}
`;

exports[`anthropic → responses > complexReasoningRequest > response 1`] = `
{
  "content": [
    {
      "thinking": "",
      "type": "thinking",
    },
    {
      "text": "There are 24 × 60 = 1440 times, each represented as four digits HHMM, so there are 5760 digits in total.

Count by position:
- H1 (first hour digit): 0 appears 600 times, 1 appears 600 times, 2 appears 240 times.
- H2 (hour units): digits 0–3 appear 180 times each, digits 4–9 appear 120 times each.
- M1 (minutes tens): digits 0–5 appear 240 times each.
- M2 (minutes units): digits 0–9 appear 144 times each.

Total counts per digit (sum of the four positions):
- 0: 1164
- 1: 1164
- 2: 804
- 3: 564
- 4: 504
- 5: 504
- 6: 264
- 7: 264
- 8: 264
- 9: 264

Most common digits: 0 and 1, each 1164 times, which is 1164/5760 = 97/480 ≈ 20.21% each.

Rarest digits: 6, 7, 8, and 9, each 264 times, which is 264/5760 = 11/240 ≈ 4.58% each.

(For reference, 2 occurs 804 times (~13.96%) and 3 occurs 564 times (~9.79%).)",
      "type": "text",
    },
  ],
  "id": "msg_transformed",
  "model": "gpt-5-nano-2025-08-07",
  "role": "assistant",
  "stop_reason": "end_turn",
  "type": "message",
  "usage": {
    "cache_read_input_tokens": 0,
    "input_tokens": 74,
    "output_tokens": 11642,
  },
}
`;

exports[`anthropic → responses > multimodalRequest > request 1`] = `
{
  "input": [
    {
      "content": [
        {
          "text": "What do you see in this image?",
          "type": "input_text",
        },
        {
          "image_url": "data:image/jpeg;base64,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",
          "type": "input_image",
        },
      ],
      "role": "user",
    },
  ],
  "max_output_tokens": 300,
  "model": "gpt-5-nano",
}
`;

exports[`anthropic → responses > multimodalRequest > response 1`] = `
{
  "content": [
    {
      "thinking": "",
      "type": "thinking",
    },
  ],
  "id": "msg_transformed",
  "model": "gpt-5-nano-2025-08-07",
  "role": "assistant",
  "stop_reason": "max_tokens",
  "type": "message",
  "usage": {
    "cache_read_input_tokens": 0,
    "input_tokens": 98,
    "output_tokens": 256,
  },
}
`;

exports[`anthropic → responses > reasoningRequest > request 1`] = `
{
  "input": [
    {
      "content": "Solve this step by step: If a train travels 60 mph for 2 hours, then 80 mph for 1 hour, what's the average speed?",
      "role": "user",
    },
  ],
  "max_output_tokens": 20000,
  "model": "gpt-5-nano",
}
`;

exports[`anthropic → responses > reasoningRequest > response 1`] = `
{
  "content": [
    {
      "thinking": "",
      "type": "thinking",
    },
    {
      "text": "Step 1: Compute distance for each leg
- Leg 1: 60 mph × 2 h = 120 miles
- Leg 2: 80 mph × 1 h = 80 miles

Step 2: Total distance and total time
- Total distance = 120 + 80 = 200 miles
- Total time = 2 + 1 = 3 hours

Step 3: Average speed
- Average speed = total distance / total time = 200 / 3 mph = 66 2/3 mph ≈ 66.7 mph

Answer: 66 2/3 mph (about 66.7 mph).",
      "type": "text",
    },
  ],
  "id": "msg_transformed",
  "model": "gpt-5-nano-2025-08-07",
  "role": "assistant",
  "stop_reason": "end_turn",
  "type": "message",
  "usage": {
    "cache_read_input_tokens": 0,
    "input_tokens": 38,
    "output_tokens": 619,
  },
}
`;

exports[`anthropic → responses > reasoningRequestTruncated > request 1`] = `
{
  "input": [
    {
      "content": "Solve this step by step: If a train travels 60 mph for 2 hours, then 80 mph for 1 hour, what's the average speed?",
      "role": "user",
    },
  ],
  "max_output_tokens": 100,
  "model": "gpt-5-nano",
}
`;

exports[`anthropic → responses > reasoningRequestTruncated > response 1`] = `
{
  "content": [
    {
      "thinking": "",
      "type": "thinking",
    },
  ],
  "id": "msg_transformed",
  "model": "gpt-5-nano-2025-08-07",
  "role": "assistant",
  "stop_reason": "max_tokens",
  "type": "message",
  "usage": {
    "cache_read_input_tokens": 0,
    "input_tokens": 38,
    "output_tokens": 64,
  },
}
`;

exports[`anthropic → responses > reasoningWithOutput > request 1`] = `
{
  "input": [
    {
      "content": "What color is the sky?",
      "role": "user",
    },
  ],
  "max_output_tokens": 20000,
  "model": "gpt-5-nano",
}
`;

exports[`anthropic → responses > reasoningWithOutput > response 1`] = `
{
  "content": [
    {
      "thinking": "",
      "type": "thinking",
    },
    {
      "text": "Typically blue during the day. The sky’s color comes from sunlight scattering in the atmosphere. It can change:

- Clear daytime: blue
- Sunrise/sunset: red/orange/pink
- Cloudy/overcast: gray
- Night: dark/black (with stars)
- Other conditions: greenish around severe storms, yellow/brown if there’s a lot of dust or pollution

If you tell me the time and location, I can describe what the sky would look like then.",
      "type": "text",
    },
  ],
  "id": "msg_transformed",
  "model": "gpt-5-nano-2025-08-07",
  "role": "assistant",
  "stop_reason": "end_turn",
  "type": "message",
  "usage": {
    "cache_read_input_tokens": 0,
    "input_tokens": 12,
    "output_tokens": 528,
  },
}
`;

exports[`anthropic → responses > simpleRequest > request 1`] = `
{
  "input": [
    {
      "content": "What is the capital of France?",
      "role": "user",
    },
  ],
  "max_output_tokens": 20000,
  "model": "gpt-5-nano",
}
`;

exports[`anthropic → responses > simpleRequest > response 1`] = `
{
  "content": [
    {
      "thinking": "",
      "type": "thinking",
    },
    {
      "text": "Paris.",
      "type": "text",
    },
  ],
  "id": "msg_transformed",
  "model": "gpt-5-nano-2025-08-07",
  "role": "assistant",
  "stop_reason": "end_turn",
  "type": "message",
  "usage": {
    "cache_read_input_tokens": 0,
    "input_tokens": 13,
    "output_tokens": 155,
  },
}
`;

exports[`anthropic → responses > systemMessageArrayContent > request 1`] = `
{
  "input": [
    {
      "content": [
        {
          "text": "You are a helpful data analyst. The default data source is project_logs with id abc-123.",
          "type": "input_text",
        },
      ],
      "role": "system",
    },
    {
      "content": "What errors occurred recently?",
      "role": "user",
    },
  ],
  "max_output_tokens": 300,
  "model": "gpt-5-nano",
}
`;

exports[`anthropic → responses > systemMessageArrayContent > response 1`] = `
{
  "content": [
    {
      "thinking": "",
      "type": "thinking",
    },
  ],
  "id": "msg_transformed",
  "model": "gpt-5-nano-2025-08-07",
  "role": "assistant",
  "stop_reason": "max_tokens",
  "type": "message",
  "usage": {
    "cache_read_input_tokens": 0,
    "input_tokens": 11,
    "output_tokens": 256,
  },
}
`;

exports[`anthropic → responses > toolCallRequest > request 1`] = `
{
  "input": [
    {
      "content": "What's the weather like in San Francisco?",
      "role": "user",
    },
  ],
  "max_output_tokens": 20000,
  "model": "gpt-5-nano",
  "tool_choice": "auto",
  "tools": [
    {
      "description": "Get the current weather for a location",
      "name": "get_weather",
      "parameters": {
        "properties": {
          "location": {
            "description": "The city and state, e.g. San Francisco, CA",
            "type": "string",
          },
        },
        "required": [
          "location",
        ],
        "type": "object",
      },
      "type": "function",
    },
  ],
}
`;

exports[`anthropic → responses > toolCallRequest > response 1`] = `
{
  "content": [
    {
      "thinking": "",
      "type": "thinking",
    },
    {
      "id": "call_VJRqLXE6cVsKg12vyEBKK0Sm",
      "input": {
        "location": "San Francisco, CA",
      },
      "name": "get_weather",
      "type": "tool_use",
    },
  ],
  "id": "msg_transformed",
  "model": "gpt-5-nano-2025-08-07",
  "role": "assistant",
  "stop_reason": "tool_use",
  "type": "message",
  "usage": {
    "cache_read_input_tokens": 0,
    "input_tokens": 66,
    "output_tokens": 169,
  },
}
`;

exports[`chat-completions → anthropic > complexReasoningRequest > request 1`] = `
{
  "max_tokens": 20000,
  "messages": [
    {
      "content": "There is a digital clock, with minutes and hours in the form of 00:00. The clock shows all times from 00:00 to 23:59 and repeating. Imagine you had a list of all these times. Which digit(s) is the most common and which is the rarest? Can you find their percentage?",
      "role": "user",
    },
  ],
  "model": "claude-sonnet-4-5-20250929",
}
`;

exports[`chat-completions → anthropic > complexReasoningRequest > response 1`] = `
{
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "message": {
        "annotations": [],
        "content": "I need to count how often each digit (0-9) appears across all times from 00:00 to 23:59.

Let me break this down by position:

**Hours (00 to 23):**
- First digit of hours: 0 (00-09), 1 (10-19), 2 (20-23)
  - 0 appears: 10 times (00-09)
  - 1 appears: 10 times (10-19)
  - 2 appears: 4 times (20-23)

- Second digit of hours: 0-9 for 00-19, then 0-3 for 20-23
  - 0 appears: 3 times (00, 10, 20)
  - 1 appears: 3 times (01, 11, 21)
  - 2 appears: 3 times (02, 12, 22)
  - 3 appears: 3 times (03, 13, 23)
  - 4 appears: 2 times (04, 14)
  - 5 appears: 2 times (05, 15)
  - 6 appears: 2 times (06, 16)
  - 7 appears: 2 times (07, 17)
  - 8 appears: 2 times (08, 18)
  - 9 appears: 2 times (09, 19)

**Minutes (00 to 59):**
- First digit of minutes: 0-5, each appearing 10 times
  - 0, 1, 2, 3, 4, 5 each appear: 10 times

- Second digit of minutes: 0-9, each appearing 6 times (once for each tens digit 0-5)
  - 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 each appear: 6 times

Now I'll total up for each digit across all 1440 minutes in a day (24 × 60):

**Digit 0:**
- Hours first: 10 × 60 = 600
- Hours second: 3 × 60 = 180
- Minutes first: 10 × 24 = 240
- Minutes second: 6 × 24 = 144
- **Total: 1164**

**Digit 1:**
- Hours first: 10 × 60 = 600
- Hours second: 3 × 60 = 180
- Minutes first: 10 × 24 = 240
- Minutes second: 6 × 24 = 144
- **Total: 1164**

**Digit 2:**
- Hours first: 4 × 60 = 240
- Hours second: 3 × 60 = 180
- Minutes first: 10 × 24 = 240
- Minutes second: 6 × 24 = 144
- **Total: 804**

**Digit 3:**
- Hours first: 0 × 60 = 0
- Hours second: 3 × 60 = 180
- Minutes first: 10 × 24 = 240
- Minutes second: 6 × 24 = 144
- **Total: 564**

**Digit 4:**
- Hours first: 0 × 60 = 0
- Hours second: 2 × 60 = 120
- Minutes first: 10 × 24 = 240
- Minutes second: 6 × 24 = 144
- **Total: 504**

**Digit 5:**
- Hours first: 0 × 60 = 0
- Hours second: 2 × 60 = 120
- Minutes first: 10 × 24 = 240
- Minutes second: 6 × 24 = 144
- **Total: 504**

**Digits 6, 7, 8, 9:**
- Hours first: 0 × 60 = 0
- Hours second: 2 × 60 = 120
- Minutes first: 0 × 24 = 0
- Minutes second: 6 × 24 = 144
- **Total each: 264**

**Results:**
- Total digit positions: 1440 × 4 = 5760
- **Most common:** 0 and 1 (tied) with 1164 occurrences each = **20.21%**
- **Least common:** 6, 7, 8, and 9 (tied) with 264 occurrences each = **4.58%**",
        "role": "assistant",
      },
    },
  ],
  "created": 0,
  "id": "chatcmpl-transformed",
  "model": "claude-sonnet-4-20250514",
  "object": "chat.completion",
  "usage": {
    "completion_tokens": 1136,
    "prompt_tokens": 80,
    "prompt_tokens_details": {
      "cached_tokens": 0,
    },
    "total_tokens": 1216,
  },
}
`;

exports[`chat-completions → anthropic > frequencyPenaltyParam > request 1`] = `
{
  "max_tokens": 4096,
  "messages": [
    {
      "content": "Say ok.",
      "role": "user",
    },
  ],
  "model": "claude-sonnet-4-5-20250929",
}
`;

exports[`chat-completions → anthropic > frequencyPenaltyParam > response 1`] = `
{
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "message": {
        "annotations": [],
        "content": "ok",
        "role": "assistant",
      },
    },
  ],
  "created": 0,
  "id": "chatcmpl-transformed",
  "model": "claude-sonnet-4-20250514",
  "object": "chat.completion",
  "usage": {
    "completion_tokens": 4,
    "prompt_tokens": 10,
    "prompt_tokens_details": {
      "cached_tokens": 0,
    },
    "total_tokens": 14,
  },
}
`;

exports[`chat-completions → anthropic > instructionsParam > request 1`] = `
{
  "max_tokens": 4096,
  "messages": [
    {
      "content": "Hi",
      "role": "user",
    },
  ],
  "model": "claude-sonnet-4-5-20250929",
  "system": "Always say ok.",
}
`;

exports[`chat-completions → anthropic > instructionsParam > response 1`] = `
{
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "message": {
        "annotations": [],
        "content": "Ok! Hello there! How can I help you today?",
        "role": "assistant",
      },
    },
  ],
  "created": 0,
  "id": "chatcmpl-transformed",
  "model": "claude-sonnet-4-20250514",
  "object": "chat.completion",
  "usage": {
    "completion_tokens": 15,
    "prompt_tokens": 12,
    "prompt_tokens_details": {
      "cached_tokens": 0,
    },
    "total_tokens": 27,
  },
}
`;

exports[`chat-completions → anthropic > logitBiasParam > request 1`] = `
{
  "max_tokens": 4096,
  "messages": [
    {
      "content": "Say hello.",
      "role": "user",
    },
  ],
  "model": "claude-sonnet-4-5-20250929",
}
`;

exports[`chat-completions → anthropic > logitBiasParam > response 1`] = `
{
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "message": {
        "annotations": [],
        "content": "Hello! It's nice to meet you. How are you doing today?",
        "role": "assistant",
      },
    },
  ],
  "created": 0,
  "id": "chatcmpl-transformed",
  "model": "claude-sonnet-4-20250514",
  "object": "chat.completion",
  "usage": {
    "completion_tokens": 18,
    "prompt_tokens": 10,
    "prompt_tokens_details": {
      "cached_tokens": 0,
    },
    "total_tokens": 28,
  },
}
`;

exports[`chat-completions → anthropic > logprobsParam > request 1`] = `
{
  "max_tokens": 4096,
  "messages": [
    {
      "content": "What is 2 + 2?",
      "role": "user",
    },
  ],
  "model": "claude-sonnet-4-5-20250929",
}
`;

exports[`chat-completions → anthropic > logprobsParam > response 1`] = `
{
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "message": {
        "annotations": [],
        "content": "2 + 2 = 4",
        "role": "assistant",
      },
    },
  ],
  "created": 0,
  "id": "chatcmpl-transformed",
  "model": "claude-sonnet-4-20250514",
  "object": "chat.completion",
  "usage": {
    "completion_tokens": 13,
    "prompt_tokens": 16,
    "prompt_tokens_details": {
      "cached_tokens": 0,
    },
    "total_tokens": 29,
  },
}
`;

exports[`chat-completions → anthropic > maxCompletionTokensParam > request 1`] = `
{
  "max_tokens": 500,
  "messages": [
    {
      "content": "Say ok.",
      "role": "user",
    },
  ],
  "model": "claude-sonnet-4-5-20250929",
}
`;

exports[`chat-completions → anthropic > maxCompletionTokensParam > response 1`] = `
{
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "message": {
        "annotations": [],
        "content": "ok",
        "role": "assistant",
      },
    },
  ],
  "created": 0,
  "id": "chatcmpl-transformed",
  "model": "claude-sonnet-4-20250514",
  "object": "chat.completion",
  "usage": {
    "completion_tokens": 4,
    "prompt_tokens": 10,
    "prompt_tokens_details": {
      "cached_tokens": 0,
    },
    "total_tokens": 14,
  },
}
`;

exports[`chat-completions → anthropic > metadataParam > request 1`] = `
{
  "max_tokens": 4096,
  "messages": [
    {
      "content": "Say ok.",
      "role": "user",
    },
  ],
  "model": "claude-sonnet-4-5-20250929",
}
`;

exports[`chat-completions → anthropic > metadataParam > response 1`] = `
{
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "message": {
        "annotations": [],
        "content": "ok",
        "role": "assistant",
      },
    },
  ],
  "created": 0,
  "id": "chatcmpl-transformed",
  "model": "claude-sonnet-4-20250514",
  "object": "chat.completion",
  "usage": {
    "completion_tokens": 4,
    "prompt_tokens": 10,
    "prompt_tokens_details": {
      "cached_tokens": 0,
    },
    "total_tokens": 14,
  },
}
`;

exports[`chat-completions → anthropic > multimodalRequest > request 1`] = `
{
  "max_tokens": 300,
  "messages": [
    {
      "content": [
        {
          "text": "What do you see in this image?",
          "type": "text",
        },
        {
          "source": {
            "type": "url",
            "url": "https://t3.ftcdn.net/jpg/02/36/99/22/360_F_236992283_sNOxCVQeFLd5pdqaKGh8DRGMZy7P4XKm.jpg",
          },
          "type": "image",
        },
      ],
      "role": "user",
    },
  ],
  "model": "claude-sonnet-4-5-20250929",
}
`;

exports[`chat-completions → anthropic > multimodalRequest > response 1`] = `
{
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "message": {
        "annotations": [],
        "content": "I see an adorable young tabby kitten lying on its side on what appears to be a wooden floor. The kitten has beautiful striped markings in shades of brown and gray, with striking yellow-green eyes that are looking directly at the camera. Its head is tilted at a charming angle, and you can see its pink nose and small whiskers. The kitten appears to be in a playful, relaxed pose. In the background, there's a white wall and what looks like wooden furniture or shelving that's slightly out of focus. The lighting creates a warm, cozy atmosphere that perfectly captures this sweet moment with the kitten.",
        "role": "assistant",
      },
    },
  ],
  "created": 0,
  "id": "chatcmpl-transformed",
  "model": "claude-sonnet-4-20250514",
  "object": "chat.completion",
  "usage": {
    "completion_tokens": 140,
    "prompt_tokens": 278,
    "prompt_tokens_details": {
      "cached_tokens": 0,
    },
    "total_tokens": 418,
  },
}
`;

exports[`chat-completions → anthropic > nMultipleCompletionsParam > request 1`] = `
{
  "max_tokens": 4096,
  "messages": [
    {
      "content": "Say a word.",
      "role": "user",
    },
  ],
  "model": "claude-sonnet-4-5-20250929",
}
`;

exports[`chat-completions → anthropic > nMultipleCompletionsParam > response 1`] = `
{
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "message": {
        "annotations": [],
        "content": "Hello.",
        "role": "assistant",
      },
    },
  ],
  "created": 0,
  "id": "chatcmpl-transformed",
  "model": "claude-sonnet-4-20250514",
  "object": "chat.completion",
  "usage": {
    "completion_tokens": 5,
    "prompt_tokens": 11,
    "prompt_tokens_details": {
      "cached_tokens": 0,
    },
    "total_tokens": 16,
  },
}
`;

exports[`chat-completions → anthropic > parallelToolCallsDisabledParam > request 1`] = `
{
  "max_tokens": 4096,
  "messages": [
    {
      "content": "Weather in NYC and LA?",
      "role": "user",
    },
  ],
  "model": "claude-sonnet-4-5-20250929",
  "tool_choice": {
    "disable_parallel_tool_use": true,
    "type": "auto",
  },
  "tools": [
    {
      "description": "Get weather",
      "input_schema": {
        "additionalProperties": false,
        "properties": {
          "location": {
            "type": "string",
          },
        },
        "required": [
          "location",
        ],
        "type": "object",
      },
      "name": "get_weather",
      "strict": true,
    },
  ],
}
`;

exports[`chat-completions → anthropic > parallelToolCallsDisabledParam > response 1`] = `
{
  "choices": [
    {
      "finish_reason": "tool_calls",
      "index": 0,
      "message": {
        "annotations": [],
        "role": "assistant",
        "tool_calls": [
          {
            "function": {
              "arguments": "{"location":"NYC"}",
              "name": "get_weather",
            },
            "id": "toolu_01VyVdLXgyvkkBago1wtYnDh",
            "type": "function",
          },
        ],
      },
    },
  ],
  "created": 0,
  "id": "chatcmpl-transformed",
  "model": "claude-sonnet-4-5-20250929",
  "object": "chat.completion",
  "usage": {
    "completion_tokens": 44,
    "prompt_tokens": 358,
    "prompt_tokens_details": {
      "cached_tokens": 0,
    },
    "total_tokens": 402,
  },
}
`;

exports[`chat-completions → anthropic > predictionParam > request 1`] = `
{
  "max_tokens": 4096,
  "messages": [
    {
      "content": "Update this function to add error handling:

function divide(a, b) {
  return a / b;
}",
      "role": "user",
    },
  ],
  "model": "claude-sonnet-4-5-20250929",
}
`;

exports[`chat-completions → anthropic > predictionParam > response 1`] = `
{
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "message": {
        "annotations": [],
        "content": "Here's the updated function with comprehensive error handling:

\`\`\`javascript
function divide(a, b) {
  // Check if both parameters are provided
  if (arguments.length < 2) {
    throw new Error('Both dividend and divisor are required');
  }
  
  // Check if both parameters are numbers
  if (typeof a !== 'number' || typeof b !== 'number') {
    throw new TypeError('Both arguments must be numbers');
  }
  
  // Check for NaN values
  if (isNaN(a) || isNaN(b)) {
    throw new Error('Arguments cannot be NaN');
  }
  
  // Check for division by zero
  if (b === 0) {
    throw new Error('Division by zero is not allowed');
  }
  
  return a / b;
}

// Example usage with try-catch:
try {
  console.log(divide(10, 2));    // 5
  console.log(divide(15, 3));    // 5
  console.log(divide(10, 0));    // Throws error
} catch (error) {
  console.error('Error:', error.message);
}
\`\`\`

**Alternative version with validation helper:**

\`\`\`javascript
function divide(a, b) {
  // Validation helper function
  function validateInput(value, paramName) {
    if (typeof value !== 'number') {
      throw new TypeError(\`\${paramName} must be a number\`);
    }
    if (isNaN(value)) {
      throw new Error(\`\${paramName} cannot be NaN\`);
    }
  }
  
  validateInput(a, 'Dividend');
  validateInput(b, 'Divisor');
  
  if (b === 0) {
    throw new Error('Division by zero is not allowed');
  }
  
  return a / b;
}
\`\`\`

**Key error handling additions:**

1. **Parameter validation** - Ensures both parameters are provided
2. **Type checking** - Verifies both arguments are numbers
3. **NaN validation** - Prevents invalid number operations
4. **Division by zero** - Prevents mathematical errors
5. **Descriptive error messages** - Makes debugging easier

The function now throws appropriate errors instead of returning unexpected values like \`NaN\` or \`Infinity\`.",
        "role": "assistant",
      },
    },
  ],
  "created": 0,
  "id": "chatcmpl-transformed",
  "model": "claude-sonnet-4-20250514",
  "object": "chat.completion",
  "usage": {
    "completion_tokens": 556,
    "prompt_tokens": 33,
    "prompt_tokens_details": {
      "cached_tokens": 0,
    },
    "total_tokens": 589,
  },
}
`;

exports[`chat-completions → anthropic > presencePenaltyParam > request 1`] = `
{
  "max_tokens": 4096,
  "messages": [
    {
      "content": "Say ok.",
      "role": "user",
    },
  ],
  "model": "claude-sonnet-4-5-20250929",
}
`;

exports[`chat-completions → anthropic > presencePenaltyParam > response 1`] = `
{
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "message": {
        "annotations": [],
        "content": "ok",
        "role": "assistant",
      },
    },
  ],
  "created": 0,
  "id": "chatcmpl-transformed",
  "model": "claude-sonnet-4-20250514",
  "object": "chat.completion",
  "usage": {
    "completion_tokens": 4,
    "prompt_tokens": 10,
    "prompt_tokens_details": {
      "cached_tokens": 0,
    },
    "total_tokens": 14,
  },
}
`;

exports[`chat-completions → anthropic > promptCacheKeyParam > request 1`] = `
{
  "max_tokens": 4096,
  "messages": [
    {
      "content": "Say ok.",
      "role": "user",
    },
  ],
  "model": "claude-sonnet-4-5-20250929",
}
`;

exports[`chat-completions → anthropic > promptCacheKeyParam > response 1`] = `
{
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "message": {
        "annotations": [],
        "content": "ok",
        "role": "assistant",
      },
    },
  ],
  "created": 0,
  "id": "chatcmpl-transformed",
  "model": "claude-sonnet-4-20250514",
  "object": "chat.completion",
  "usage": {
    "completion_tokens": 4,
    "prompt_tokens": 10,
    "prompt_tokens_details": {
      "cached_tokens": 0,
    },
    "total_tokens": 14,
  },
}
`;

exports[`chat-completions → anthropic > reasoningEffortLowParam > request 1`] = `
{
  "max_tokens": 4096,
  "messages": [
    {
      "content": "What is 2+2?",
      "role": "user",
    },
  ],
  "model": "claude-opus-4-6",
  "thinking": {
    "budget_tokens": 1024,
    "type": "enabled",
  },
}
`;

exports[`chat-completions → anthropic > reasoningEffortLowParam > response 1`] = `
{
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "message": {
        "annotations": [],
        "content": "2+2 = **4**",
        "reasoning": "4",
        "reasoning_signature": "EqkBCkYICxgCKkDo5w3BcOFDM2J7MsIKxgUfuba9NpwDavusotnNesPeZa7anZZRQjr0ND/Y4T9kgQgbRz4ipY8/DiooFD5PtwvCEgy1hlYQhGq5oP/pJ5waDD8zyZjJCk2MD2paFSIwHToLXMRKvKF83V+EvlScjQnoExEZemTiKGs6s0LAY6PyyEBCCoq6NDEMJMkmZaTFKhEpejqNqcBVQ00FkfWfconNyRgB",
        "role": "assistant",
      },
    },
  ],
  "created": 0,
  "id": "chatcmpl-transformed",
  "model": "claude-opus-4-6",
  "object": "chat.completion",
  "usage": {
    "completion_tokens": 20,
    "prompt_tokens": 43,
    "prompt_tokens_details": {
      "cached_tokens": 0,
    },
    "total_tokens": 63,
  },
}
`;

exports[`chat-completions → anthropic > reasoningRequest > request 1`] = `
{
  "max_tokens": 4096,
  "messages": [
    {
      "content": "Solve this step by step: If a train travels 60 mph for 2 hours, then 80 mph for 1 hour, what's the average speed?",
      "role": "user",
    },
  ],
  "model": "claude-sonnet-4-5-20250929",
}
`;

exports[`chat-completions → anthropic > reasoningRequest > response 1`] = `
{
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "message": {
        "annotations": [],
        "content": "I'll solve this step by step using the formula: Average speed = Total distance ÷ Total time

**Step 1: Calculate distance for each segment**

Segment 1: 60 mph for 2 hours
- Distance = speed × time = 60 × 2 = 120 miles

Segment 2: 80 mph for 1 hour  
- Distance = speed × time = 80 × 1 = 80 miles

**Step 2: Find totals**

Total distance = 120 + 80 = 200 miles
Total time = 2 + 1 = 3 hours

**Step 3: Calculate average speed**

Average speed = Total distance ÷ Total time
Average speed = 200 miles ÷ 3 hours = 66.67 mph

**Answer: The average speed is 66.67 mph (or 66⅔ mph)**

Note: This is different from simply averaging the two speeds (60 + 80)/2 = 70 mph, because the train spent more time at the slower speed.",
        "role": "assistant",
      },
    },
  ],
  "created": 0,
  "id": "chatcmpl-transformed",
  "model": "claude-sonnet-4-20250514",
  "object": "chat.completion",
  "usage": {
    "completion_tokens": 257,
    "prompt_tokens": 45,
    "prompt_tokens_details": {
      "cached_tokens": 0,
    },
    "total_tokens": 302,
  },
}
`;

exports[`chat-completions → anthropic > reasoningRequestTruncated > request 1`] = `
{
  "max_tokens": 100,
  "messages": [
    {
      "content": "Solve this step by step: If a train travels 60 mph for 2 hours, then 80 mph for 1 hour, what's the average speed?",
      "role": "user",
    },
  ],
  "model": "claude-sonnet-4-5-20250929",
}
`;

exports[`chat-completions → anthropic > reasoningRequestTruncated > response 1`] = `
{
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "message": {
        "annotations": [],
        "content": "I'll solve this step by step using the formula: Average speed = Total distance ÷ Total time

**Step 1: Calculate distance for each segment**

Segment 1: 60 mph for 2 hours
- Distance = speed × time = 60 × 2 = 120 miles

Segment 2: 80 mph for 1 hour  
- Distance = speed × time = 80 × 1 ",
        "role": "assistant",
      },
    },
  ],
  "created": 0,
  "id": "chatcmpl-transformed",
  "model": "claude-sonnet-4-20250514",
  "object": "chat.completion",
  "usage": {
    "completion_tokens": 100,
    "prompt_tokens": 45,
    "prompt_tokens_details": {
      "cached_tokens": 0,
    },
    "total_tokens": 145,
  },
}
`;

exports[`chat-completions → anthropic > reasoningSummaryParam > request 1`] = `
{
  "max_tokens": 4096,
  "messages": [
    {
      "content": "What is 2+2?",
      "role": "user",
    },
  ],
  "model": "claude-opus-4-6",
  "thinking": {
    "budget_tokens": 2048,
    "type": "enabled",
  },
}
`;

exports[`chat-completions → anthropic > reasoningSummaryParam > response 1`] = `
{
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "message": {
        "annotations": [],
        "content": "2 + 2 = **4**",
        "reasoning": "4",
        "reasoning_signature": "EqkBCkYICxgCKkDo5w3BcOFDM2J7MsIKxgUfuba9NpwDavusotnNesPeZa7anZZRQjr0ND/Y4T9kgQgbRz4ipY8/DiooFD5PtwvCEgxNeQ+pto9joPeH73MaDA9tTUpGztalgdSaaiIwUoRvdORYKB3aDndfIO3NukKYHZCWyiFJ9mh9SxxvpTljnKXsski8zzK1VTvR5lZtKhE2T/D3aq9M6qMOOlqKb/HpoxgB",
        "role": "assistant",
      },
    },
  ],
  "created": 0,
  "id": "chatcmpl-transformed",
  "model": "claude-opus-4-6",
  "object": "chat.completion",
  "usage": {
    "completion_tokens": 22,
    "prompt_tokens": 43,
    "prompt_tokens_details": {
      "cached_tokens": 0,
    },
    "total_tokens": 65,
  },
}
`;

exports[`chat-completions → anthropic > reasoningWithOutput > request 1`] = `
{
  "max_tokens": 4096,
  "messages": [
    {
      "content": "What color is the sky?",
      "role": "user",
    },
  ],
  "model": "claude-sonnet-4-5-20250929",
}
`;

exports[`chat-completions → anthropic > reasoningWithOutput > response 1`] = `
{
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "message": {
        "annotations": [],
        "content": "The sky appears blue during a clear day. This blue color is caused by a phenomenon called Rayleigh scattering, where molecules in Earth's atmosphere scatter blue light from the sun more than other colors.

Of course, the sky can appear different colors depending on conditions - it might look gray during overcast weather, or display beautiful reds, oranges, and pinks during sunrise or sunset.",
        "role": "assistant",
      },
    },
  ],
  "created": 0,
  "id": "chatcmpl-transformed",
  "model": "claude-sonnet-4-20250514",
  "object": "chat.completion",
  "usage": {
    "completion_tokens": 86,
    "prompt_tokens": 13,
    "prompt_tokens_details": {
      "cached_tokens": 0,
    },
    "total_tokens": 99,
  },
}
`;

exports[`chat-completions → anthropic > safetyIdentifierParam > request 1`] = `
{
  "max_tokens": 4096,
  "messages": [
    {
      "content": "Say ok.",
      "role": "user",
    },
  ],
  "model": "claude-sonnet-4-5-20250929",
}
`;

exports[`chat-completions → anthropic > safetyIdentifierParam > response 1`] = `
{
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "message": {
        "annotations": [],
        "content": "ok.",
        "role": "assistant",
      },
    },
  ],
  "created": 0,
  "id": "chatcmpl-transformed",
  "model": "claude-sonnet-4-20250514",
  "object": "chat.completion",
  "usage": {
    "completion_tokens": 5,
    "prompt_tokens": 10,
    "prompt_tokens_details": {
      "cached_tokens": 0,
    },
    "total_tokens": 15,
  },
}
`;

exports[`chat-completions → anthropic > seedParam > request 1`] = `
{
  "max_tokens": 4096,
  "messages": [
    {
      "content": "Pick a number.",
      "role": "user",
    },
  ],
  "model": "claude-sonnet-4-5-20250929",
}
`;

exports[`chat-completions → anthropic > seedParam > response 1`] = `
{
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "message": {
        "annotations": [],
        "content": "42

(A classic choice - it's the "Answer to the Ultimate Question of Life, the Universe, and Everything" according to Douglas Adams!)",
        "role": "assistant",
      },
    },
  ],
  "created": 0,
  "id": "chatcmpl-transformed",
  "model": "claude-sonnet-4-20250514",
  "object": "chat.completion",
  "usage": {
    "completion_tokens": 34,
    "prompt_tokens": 11,
    "prompt_tokens_details": {
      "cached_tokens": 0,
    },
    "total_tokens": 45,
  },
}
`;

exports[`chat-completions → anthropic > serviceTierParam > request 1`] = `
{
  "max_tokens": 4096,
  "messages": [
    {
      "content": "Say ok.",
      "role": "user",
    },
  ],
  "model": "claude-sonnet-4-5-20250929",
  "service_tier": "auto",
}
`;

exports[`chat-completions → anthropic > serviceTierParam > response 1`] = `
{
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "message": {
        "annotations": [],
        "content": "ok",
        "role": "assistant",
      },
    },
  ],
  "created": 0,
  "id": "chatcmpl-transformed",
  "model": "claude-sonnet-4-20250514",
  "object": "chat.completion",
  "usage": {
    "completion_tokens": 4,
    "prompt_tokens": 10,
    "prompt_tokens_details": {
      "cached_tokens": 0,
    },
    "total_tokens": 14,
  },
}
`;

exports[`chat-completions → anthropic > simpleRequest > request 1`] = `
{
  "max_tokens": 4096,
  "messages": [
    {
      "content": "What is the capital of France?",
      "role": "user",
    },
  ],
  "model": "claude-sonnet-4-5-20250929",
  "thinking": {
    "budget_tokens": 1024,
    "type": "enabled",
  },
}
`;

exports[`chat-completions → anthropic > simpleRequest > response 1`] = `
{
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "message": {
        "annotations": [],
        "content": "The capital of France is Paris.",
        "reasoning": "This is a straightforward factual question. The capital of France is Paris. This is basic geographical knowledge that I can provide confidently.",
        "reasoning_signature": "ErkCCkYICxgCKkB/VSMzHr1UoQiyNS0z7cJQM6BUFmFfI2emnP7YJgW/lhBPOtjvgUAaq5tXWH9FJCIzCXCs/hw0sKY+2KAvpcLJEgy7Nh1ybvk1zdrdliYaDA9DnbQuJa5XiIDFLiIwI3UpxlJrF5Hf/K+I1BBcmXs0llgTNDWTMPUjXqhj4068w4q6ScMMI/+IlkrDh98EKqABi5/fmhsiopylBjnTvYwgiHstHv/G2jH+bestbnXSKUVvaIK3DNtViAFoZQLnpzpF3PbMx7cCDvLEqV6Qnnkx9As1xUWIYoMLDE8MyTyWKaOKTBu8JO9lKNDyeX6BO0KiusBzfIk1PCEwfZCe8mqRX1+YHBjJJ/odyKu6yHlzw6Zqd0uCFMP3PatkEuSyOkAqCX34KuuucMgLxEB5IvMfYBgB",
        "role": "assistant",
      },
    },
  ],
  "created": 0,
  "id": "chatcmpl-transformed",
  "model": "claude-sonnet-4-20250514",
  "object": "chat.completion",
  "usage": {
    "completion_tokens": 46,
    "prompt_tokens": 43,
    "prompt_tokens_details": {
      "cached_tokens": 0,
    },
    "total_tokens": 89,
  },
}
`;

exports[`chat-completions → anthropic > stopSequencesParam > request 1`] = `
{
  "max_tokens": 4096,
  "messages": [
    {
      "content": "Count from 1 to 20.",
      "role": "user",
    },
  ],
  "model": "claude-sonnet-4-5-20250929",
  "stop_sequences": [
    "10",
    "ten",
  ],
}
`;

exports[`chat-completions → anthropic > stopSequencesParam > response 1`] = `
{
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "message": {
        "annotations": [],
        "content": "1, 2, 3, 4, 5, 6, 7, 8, 9, ",
        "role": "assistant",
      },
    },
  ],
  "created": 0,
  "id": "chatcmpl-transformed",
  "model": "claude-sonnet-4-20250514",
  "object": "chat.completion",
  "usage": {
    "completion_tokens": 29,
    "prompt_tokens": 16,
    "prompt_tokens_details": {
      "cached_tokens": 0,
    },
    "total_tokens": 45,
  },
}
`;

exports[`chat-completions → anthropic > storeDisabledParam > request 1`] = `
{
  "max_tokens": 4096,
  "messages": [
    {
      "content": "Say ok.",
      "role": "user",
    },
  ],
  "model": "claude-sonnet-4-5-20250929",
}
`;

exports[`chat-completions → anthropic > storeDisabledParam > response 1`] = `
{
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "message": {
        "annotations": [],
        "content": "ok.",
        "role": "assistant",
      },
    },
  ],
  "created": 0,
  "id": "chatcmpl-transformed",
  "model": "claude-sonnet-4-20250514",
  "object": "chat.completion",
  "usage": {
    "completion_tokens": 5,
    "prompt_tokens": 10,
    "prompt_tokens_details": {
      "cached_tokens": 0,
    },
    "total_tokens": 15,
  },
}
`;

exports[`chat-completions → anthropic > systemMessageArrayContent > request 1`] = `
{
  "max_tokens": 300,
  "messages": [
    {
      "content": "What errors occurred recently?",
      "role": "user",
    },
  ],
  "model": "claude-sonnet-4-5-20250929",
  "system": "You are a helpful data analyst. The default data source is project_logs with id abc-123.",
}
`;

exports[`chat-completions → anthropic > systemMessageArrayContent > response 1`] = `
{
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "message": {
        "annotations": [],
        "content": "I'll help you find recent errors from the project logs. Let me query the data to identify error events.

\`\`\`sql
SELECT 
    timestamp,
    level,
    message,
    source,
    error_code,
    user_id
FROM project_logs 
WHERE level IN ('ERROR', 'FATAL', 'CRITICAL')
    AND timestamp >= DATETIME_SUB(CURRENT_DATETIME(), INTERVAL 24 HOURS)
ORDER BY timestamp DESC
LIMIT 20;
\`\`\`

This query will show you:
- The most recent errors from the last 24 hours
- Error severity levels (ERROR, FATAL, CRITICAL)
- Timestamps, messages, and source information
- Any associated error codes and user IDs

Would you like me to:
1. Extend the time range (e.g., last week)?
2. Filter by specific error types or sources?
3. Group the errors by frequency or type?
4. Look for error patterns or trends?

Let me know what specific aspects of the recent errors you'd like to explore further!",
        "role": "assistant",
      },
    },
  ],
  "created": 0,
  "id": "chatcmpl-transformed",
  "model": "claude-sonnet-4-20250514",
  "object": "chat.completion",
  "usage": {
    "completion_tokens": 246,
    "prompt_tokens": 33,
    "prompt_tokens_details": {
      "cached_tokens": 0,
    },
    "total_tokens": 279,
  },
}
`;

exports[`chat-completions → anthropic > temperatureParam > request 1`] = `
{
  "max_tokens": 4096,
  "messages": [
    {
      "content": "Say hi.",
      "role": "user",
    },
  ],
  "model": "claude-sonnet-4-5-20250929",
  "temperature": 0.7,
}
`;

exports[`chat-completions → anthropic > temperatureParam > response 1`] = `
{
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "message": {
        "annotations": [],
        "content": "Hi there! How are you doing today?",
        "role": "assistant",
      },
    },
  ],
  "created": 0,
  "id": "chatcmpl-transformed",
  "model": "claude-sonnet-4-20250514",
  "object": "chat.completion",
  "usage": {
    "completion_tokens": 12,
    "prompt_tokens": 10,
    "prompt_tokens_details": {
      "cached_tokens": 0,
    },
    "total_tokens": 22,
  },
}
`;

exports[`chat-completions → anthropic > textFormatJsonObjectParam > request 1`] = `
{
  "max_tokens": 4096,
  "messages": [
    {
      "content": "Return {"status": "ok"} as JSON.",
      "role": "user",
    },
  ],
  "model": "claude-sonnet-4-5-20250929",
  "output_config": {
    "format": {
      "schema": {
        "additionalProperties": false,
        "type": "object",
      },
      "type": "json_schema",
    },
  },
}
`;

exports[`chat-completions → anthropic > textFormatJsonObjectParam > response 1`] = `
{
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "message": {
        "annotations": [],
        "content": "{}",
        "role": "assistant",
      },
    },
  ],
  "created": 0,
  "id": "chatcmpl-transformed",
  "model": "claude-sonnet-4-5-20250929",
  "object": "chat.completion",
  "usage": {
    "completion_tokens": 4,
    "prompt_tokens": 119,
    "prompt_tokens_details": {
      "cached_tokens": 0,
    },
    "total_tokens": 123,
  },
}
`;

exports[`chat-completions → anthropic > textFormatJsonSchemaParam > request 1`] = `
{
  "max_tokens": 4096,
  "messages": [
    {
      "content": "Extract: John is 25.",
      "role": "user",
    },
  ],
  "model": "claude-sonnet-4-5-20250929",
  "output_config": {
    "format": {
      "schema": {
        "additionalProperties": false,
        "properties": {
          "age": {
            "type": "number",
          },
          "name": {
            "type": "string",
          },
        },
        "required": [
          "name",
          "age",
        ],
        "type": "object",
      },
      "type": "json_schema",
    },
  },
}
`;

exports[`chat-completions → anthropic > textFormatJsonSchemaParam > response 1`] = `
{
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "message": {
        "annotations": [],
        "content": "{"age":25,"name":"John"}",
        "role": "assistant",
      },
    },
  ],
  "created": 0,
  "id": "chatcmpl-transformed",
  "model": "claude-sonnet-4-5-20250929",
  "object": "chat.completion",
  "usage": {
    "completion_tokens": 12,
    "prompt_tokens": 177,
    "prompt_tokens_details": {
      "cached_tokens": 0,
    },
    "total_tokens": 189,
  },
}
`;

exports[`chat-completions → anthropic > textFormatJsonSchemaWithDescriptionParam > request 1`] = `
{
  "max_tokens": 4096,
  "messages": [
    {
      "content": "Extract: John is 25.",
      "role": "user",
    },
  ],
  "model": "claude-sonnet-4-5-20250929",
  "output_config": {
    "format": {
      "schema": {
        "additionalProperties": false,
        "properties": {
          "age": {
            "type": "number",
          },
          "name": {
            "type": "string",
          },
        },
        "required": [
          "name",
          "age",
        ],
        "type": "object",
      },
      "type": "json_schema",
    },
  },
}
`;

exports[`chat-completions → anthropic > textFormatJsonSchemaWithDescriptionParam > response 1`] = `
{
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "message": {
        "annotations": [],
        "content": "{"age":25,"name":"John"}",
        "role": "assistant",
      },
    },
  ],
  "created": 0,
  "id": "chatcmpl-transformed",
  "model": "claude-sonnet-4-5-20250929",
  "object": "chat.completion",
  "usage": {
    "completion_tokens": 12,
    "prompt_tokens": 177,
    "prompt_tokens_details": {
      "cached_tokens": 0,
    },
    "total_tokens": 189,
  },
}
`;

exports[`chat-completions → anthropic > textFormatTextParam > request 1`] = `
{
  "max_tokens": 4096,
  "messages": [
    {
      "content": "Say hello.",
      "role": "user",
    },
  ],
  "model": "claude-sonnet-4-5-20250929",
}
`;

exports[`chat-completions → anthropic > textFormatTextParam > response 1`] = `
{
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "message": {
        "annotations": [],
        "content": "Hello! How are you doing today?",
        "role": "assistant",
      },
    },
  ],
  "created": 0,
  "id": "chatcmpl-transformed",
  "model": "claude-sonnet-4-20250514",
  "object": "chat.completion",
  "usage": {
    "completion_tokens": 11,
    "prompt_tokens": 10,
    "prompt_tokens_details": {
      "cached_tokens": 0,
    },
    "total_tokens": 21,
  },
}
`;

exports[`chat-completions → anthropic > toolCallRequest > request 1`] = `
{
  "max_tokens": 4096,
  "messages": [
    {
      "content": "What's the weather like in San Francisco?",
      "role": "user",
    },
  ],
  "model": "claude-sonnet-4-5-20250929",
  "tool_choice": {
    "type": "auto",
  },
  "tools": [
    {
      "description": "Get the current weather for a location",
      "input_schema": {
        "properties": {
          "location": {
            "description": "The city and state, e.g. San Francisco, CA",
            "type": "string",
          },
        },
        "required": [
          "location",
        ],
        "type": "object",
      },
      "name": "get_weather",
    },
  ],
}
`;

exports[`chat-completions → anthropic > toolCallRequest > response 1`] = `
{
  "choices": [
    {
      "finish_reason": "tool_calls",
      "index": 0,
      "message": {
        "annotations": [],
        "content": "I'll check the current weather in San Francisco for you.",
        "role": "assistant",
        "tool_calls": [
          {
            "function": {
              "arguments": "{"location":"San Francisco, CA"}",
              "name": "get_weather",
            },
            "id": "toolu_01PqaAfxSMw4i3arxmVVAscE",
            "type": "function",
          },
        ],
      },
    },
  ],
  "created": 0,
  "id": "chatcmpl-transformed",
  "model": "claude-sonnet-4-20250514",
  "object": "chat.completion",
  "usage": {
    "completion_tokens": 69,
    "prompt_tokens": 402,
    "prompt_tokens_details": {
      "cached_tokens": 0,
    },
    "total_tokens": 471,
  },
}
`;

exports[`chat-completions → anthropic > toolChoiceRequiredParam > request 1`] = `
{
  "max_tokens": 4096,
  "messages": [
    {
      "content": "Tokyo weather",
      "role": "user",
    },
  ],
  "model": "claude-sonnet-4-5-20250929",
  "tool_choice": {
    "name": "get_weather",
    "type": "tool",
  },
  "tools": [
    {
      "description": "Get weather",
      "input_schema": {
        "additionalProperties": false,
        "properties": {
          "location": {
            "type": "string",
          },
        },
        "required": [
          "location",
        ],
        "type": "object",
      },
      "name": "get_weather",
      "strict": true,
    },
  ],
}
`;

exports[`chat-completions → anthropic > toolChoiceRequiredParam > response 1`] = `
{
  "choices": [
    {
      "finish_reason": "tool_calls",
      "index": 0,
      "message": {
        "annotations": [],
        "role": "assistant",
        "tool_calls": [
          {
            "function": {
              "arguments": "{"location":"Tokyo"}",
              "name": "get_weather",
            },
            "id": "toolu_014tEQdRC4Y4vWxHL3S2Jdmw",
            "type": "function",
          },
        ],
      },
    },
  ],
  "created": 0,
  "id": "chatcmpl-transformed",
  "model": "claude-sonnet-4-5-20250929",
  "object": "chat.completion",
  "usage": {
    "completion_tokens": 33,
    "prompt_tokens": 659,
    "prompt_tokens_details": {
      "cached_tokens": 0,
    },
    "total_tokens": 692,
  },
}
`;

exports[`chat-completions → anthropic > topPParam > request 1`] = `
{
  "max_tokens": 4096,
  "messages": [
    {
      "content": "Say hi.",
      "role": "user",
    },
  ],
  "model": "claude-sonnet-4-5-20250929",
  "top_p": 0.9,
}
`;

exports[`chat-completions → anthropic > topPParam > response 1`] = `
{
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "message": {
        "annotations": [],
        "content": "Hi! How are you doing today?",
        "role": "assistant",
      },
    },
  ],
  "created": 0,
  "id": "chatcmpl-transformed",
  "model": "claude-sonnet-4-20250514",
  "object": "chat.completion",
  "usage": {
    "completion_tokens": 11,
    "prompt_tokens": 10,
    "prompt_tokens_details": {
      "cached_tokens": 0,
    },
    "total_tokens": 21,
  },
}
`;

exports[`chat-completions → google > complexReasoningRequest > request 1`] = `
{
  "contents": [
    {
      "parts": [
        {
          "text": "There is a digital clock, with minutes and hours in the form of 00:00. The clock shows all times from 00:00 to 23:59 and repeating. Imagine you had a list of all these times. Which digit(s) is the most common and which is the rarest? Can you find their percentage?",
        },
      ],
      "role": "user",
    },
  ],
  "generationConfig": {
    "maxOutputTokens": 20000,
    "responseSchema": null,
  },
  "model": "gemini-2.5-flash",
}
`;

exports[`chat-completions → google > complexReasoningRequest > response 1`] = `
{
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "message": {
        "annotations": [],
        "content": "Let's break this down by counting the occurrences of each digit from 0 to 9 across all times from 00:00 to 23:59.

First, let's determine the total number of digits displayed:
*   There are 24 hours (00 to 23).
*   There are 60 minutes (00 to 59).
*   Total number of unique time displays = 24 * 60 = 1440 times.
*   Each time display has 4 digits (e.g., 00:00, 12:34).
*   Total number of digits shown = 1440 * 4 = 5760 digits.

Now, let's count the occurrences of each digit systematically. We can do this by considering each digit position (tens of hours, units of hours, tens of minutes, units of minutes).

**1. Tens of Hours (H1_):**
*   Digit 0 appears for hours 00-09 (10 hours).
*   Digit 1 appears for hours 10-19 (10 hours).
*   Digit 2 appears for hours 20-23 (4 hours).
*   Each of these digits appears for 60 minutes.
    *   '0': 10 hours * 60 minutes = 600 times
    *   '1': 10 hours * 60 minutes = 600 times
    *   '2': 4 hours * 60 minutes = 240 times
    *   Digits 3-9: 0 times

**2. Units of Hours (_H2):**
*   For each hour (00-23), we look at its units digit. This digit appears for 60 minutes.
    *   Digit '0' (from 00, 10, 20): 3 times * 60 minutes = 180 times
    *   Digit '1' (from 01, 11, 21): 3 times * 60 minutes = 180 times
    *   Digit '2' (from 02, 12, 22): 3 times * 60 minutes = 180 times
    *   Digit '3' (from 03, 13, 23): 3 times * 60 minutes = 180 times
    *   Digits '4' through '9' (e.g., 04, 14 for '4'): 2 times each (since hours go up to 23, we don't have 24, 25, etc.) * 60 minutes = 120 times each

**3. Tens of Minutes (M1_):**
*   For each minute (00-59), we look at its tens digit. This digit appears for 24 hours.
    *   Digit '0' (from 00-09): 10 minutes * 24 hours = 240 times
    *   Digit '1' (from 10-19): 10 minutes * 24 hours = 240 times
    *   Digit '2' (from 20-29): 10 minutes * 24 hours = 240 times
    *   Digit '3' (from 30-39): 10 minutes * 24 hours = 240 times
    *   Digit '4' (from 40-49): 10 minutes * 24 hours = 240 times
    *   Digit '5' (from 50-59): 10 minutes * 24 hours = 240 times
    *   Digits 6-9: 0 times

**4. Units of Minutes (_M2):**
*   For each minute (00-59), we look at its units digit. This digit appears for 24 hours.
    *   Digits '0' through '9' (e.g., 00, 01...09, 10, 11...19, etc.): Each digit appears 6 times in the units place of minutes (e.g., 0, 10, 20, 30, 40, 50 for '0').
    *   6 times * 24 hours = 144 times for each digit (0-9).

---

**Total Counts for Each Digit:**

*   **Digit 0:** 600 (H1) + 180 (H2) + 240 (M1) + 144 (M2) = **1164**
*   **Digit 1:** 600 (H1) + 180 (H2) + 240 (M1) + 144 (M2) = **1164**
*   **Digit 2:** 240 (H1) + 180 (H2) + 240 (M1) + 144 (M2) = **804**
*   **Digit 3:** 0 (H1) + 180 (H2) + 240 (M1) + 144 (M2) = **564**
*   **Digit 4:** 0 (H1) + 120 (H2) + 240 (M1) + 144 (M2) = **504**
*   **Digit 5:** 0 (H1) + 120 (H2) + 240 (M1) + 144 (M2) = **504**
*   **Digit 6:** 0 (H1) + 120 (H2) + 0 (M1) + 144 (M2) = **264**
*   **Digit 7:** 0 (H1) + 120 (H2) + 0 (M1) + 144 (M2) = **264**
*   **Digit 8:** 0 (H1) + 120 (H2) + 0 (M1) + 144 (M2) = **264**
*   **Digit 9:** 0 (H1) + 120 (H2) + 0 (M1) + 144 (M2) = **264**

*(Self-check: Sum of counts = 1164*2 + 804 + 564 + 504*2 + 264*4 = 2328 + 804 + 564 + 1008 + 1056 = 5760. This matches the total number of digits displayed.)*

---

**Summary:**

*   **Most Common Digits:**
    *   The digits **0** and **1** are the most common, each appearing **1164** times.
    *   Percentage: (1164 / 5760) * 100% = **20.21%** (rounded to two decimal places).

*   **Rarest Digits:**
    *   The digits **6, 7, 8,** and **9** are the rarest, each appearing **264** times.
    *   Percentage: (264 / 5760) * 100% = **4.58%** (rounded to two decimal places).",
        "role": "assistant",
      },
    },
  ],
  "created": 0,
  "id": "chatcmpl-transformed",
  "model": "gemini-2.5-flash",
  "object": "chat.completion",
  "usage": {
    "completion_tokens": 4983,
    "completion_tokens_details": {
      "reasoning_tokens": 3235,
    },
    "prompt_tokens": 75,
    "total_tokens": 5058,
  },
}
`;

exports[`chat-completions → google > frequencyPenaltyParam > request 1`] = `
{
  "contents": [
    {
      "parts": [
        {
          "text": "Say ok.",
        },
      ],
      "role": "user",
    },
  ],
  "model": "gemini-2.5-flash",
}
`;

exports[`chat-completions → google > frequencyPenaltyParam > response 1`] = `
{
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "message": {
        "annotations": [],
        "content": "Ok.",
        "role": "assistant",
      },
    },
  ],
  "created": 0,
  "id": "chatcmpl-transformed",
  "model": "gemini-2.5-flash",
  "object": "chat.completion",
  "usage": {
    "completion_tokens": 16,
    "completion_tokens_details": {
      "reasoning_tokens": 14,
    },
    "prompt_tokens": 4,
    "total_tokens": 20,
  },
}
`;

exports[`chat-completions → google > instructionsParam > request 1`] = `
{
  "contents": [
    {
      "parts": [
        {
          "text": "Hi",
        },
      ],
      "role": "user",
    },
  ],
  "model": "gemini-2.5-flash",
  "systemInstruction": {
    "parts": [
      {
        "text": "Always say ok.",
      },
    ],
  },
}
`;

exports[`chat-completions → google > instructionsParam > response 1`] = `
{
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "message": {
        "annotations": [],
        "content": "Ok. Hi.",
        "role": "assistant",
      },
    },
  ],
  "created": 0,
  "id": "chatcmpl-transformed",
  "model": "gemini-2.5-flash",
  "object": "chat.completion",
  "usage": {
    "completion_tokens": 4,
    "prompt_tokens": 6,
    "total_tokens": 10,
  },
}
`;

exports[`chat-completions → google > logitBiasParam > request 1`] = `
{
  "contents": [
    {
      "parts": [
        {
          "text": "Say hello.",
        },
      ],
      "role": "user",
    },
  ],
  "model": "gemini-2.5-flash",
}
`;

exports[`chat-completions → google > logitBiasParam > response 1`] = `
{
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "message": {
        "annotations": [],
        "content": "Hello!",
        "role": "assistant",
      },
    },
  ],
  "created": 0,
  "id": "chatcmpl-transformed",
  "model": "gemini-2.5-flash",
  "object": "chat.completion",
  "usage": {
    "completion_tokens": 19,
    "completion_tokens_details": {
      "reasoning_tokens": 17,
    },
    "prompt_tokens": 4,
    "total_tokens": 23,
  },
}
`;

exports[`chat-completions → google > logprobsParam > request 1`] = `
{
  "contents": [
    {
      "parts": [
        {
          "text": "What is 2 + 2?",
        },
      ],
      "role": "user",
    },
  ],
  "model": "gemini-2.5-flash",
}
`;

exports[`chat-completions → google > logprobsParam > response 1`] = `
{
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "message": {
        "annotations": [],
        "content": "2 + 2 = 4",
        "role": "assistant",
      },
    },
  ],
  "created": 0,
  "id": "chatcmpl-transformed",
  "model": "gemini-2.5-flash",
  "object": "chat.completion",
  "usage": {
    "completion_tokens": 27,
    "completion_tokens_details": {
      "reasoning_tokens": 20,
    },
    "prompt_tokens": 9,
    "total_tokens": 36,
  },
}
`;

exports[`chat-completions → google > maxCompletionTokensParam > request 1`] = `
{
  "contents": [
    {
      "parts": [
        {
          "text": "Say ok.",
        },
      ],
      "role": "user",
    },
  ],
  "generationConfig": {
    "maxOutputTokens": 500,
    "responseSchema": null,
  },
  "model": "gemini-2.5-flash",
}
`;

exports[`chat-completions → google > maxCompletionTokensParam > response 1`] = `
{
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "message": {
        "annotations": [],
        "content": "ok",
        "role": "assistant",
      },
    },
  ],
  "created": 0,
  "id": "chatcmpl-transformed",
  "model": "gemini-2.5-flash",
  "object": "chat.completion",
  "usage": {
    "completion_tokens": 31,
    "completion_tokens_details": {
      "reasoning_tokens": 30,
    },
    "prompt_tokens": 4,
    "total_tokens": 35,
  },
}
`;

exports[`chat-completions → google > metadataParam > request 1`] = `
{
  "contents": [
    {
      "parts": [
        {
          "text": "Say ok.",
        },
      ],
      "role": "user",
    },
  ],
  "model": "gemini-2.5-flash",
}
`;

exports[`chat-completions → google > metadataParam > response 1`] = `
{
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "message": {
        "annotations": [],
        "content": "ok.",
        "role": "assistant",
      },
    },
  ],
  "created": 0,
  "id": "chatcmpl-transformed",
  "model": "gemini-2.5-flash",
  "object": "chat.completion",
  "usage": {
    "completion_tokens": 17,
    "completion_tokens_details": {
      "reasoning_tokens": 15,
    },
    "prompt_tokens": 4,
    "total_tokens": 21,
  },
}
`;

exports[`chat-completions → google > multimodalRequest > request 1`] = `
{
  "contents": [
    {
      "parts": [
        {
          "text": "What do you see in this image?",
        },
        {
          "fileData": {
            "fileUri": "https://t3.ftcdn.net/jpg/02/36/99/22/360_F_236992283_sNOxCVQeFLd5pdqaKGh8DRGMZy7P4XKm.jpg",
          },
        },
      ],
      "role": "user",
    },
  ],
  "generationConfig": {
    "maxOutputTokens": 300,
    "responseSchema": null,
  },
  "model": "gemini-2.5-flash",
}
`;

exports[`chat-completions → google > multimodalRequest > response 1`] = `
{
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "message": {
        "annotations": [],
        "content": "This image features a charming tabby cat lying on a light",
        "role": "assistant",
      },
    },
  ],
  "created": 0,
  "id": "chatcmpl-transformed",
  "model": "gemini-2.5-flash",
  "object": "chat.completion",
  "usage": {
    "completion_tokens": 296,
    "completion_tokens_details": {
      "reasoning_tokens": 285,
    },
    "prompt_tokens": 267,
    "total_tokens": 563,
  },
}
`;

exports[`chat-completions → google > nMultipleCompletionsParam > request 1`] = `
{
  "contents": [
    {
      "parts": [
        {
          "text": "Say a word.",
        },
      ],
      "role": "user",
    },
  ],
  "model": "gemini-2.5-flash",
}
`;

exports[`chat-completions → google > nMultipleCompletionsParam > response 1`] = `
{
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "message": {
        "annotations": [],
        "content": "Hello.",
        "role": "assistant",
      },
    },
  ],
  "created": 0,
  "id": "chatcmpl-transformed",
  "model": "gemini-2.5-flash",
  "object": "chat.completion",
  "usage": {
    "completion_tokens": 28,
    "completion_tokens_details": {
      "reasoning_tokens": 26,
    },
    "prompt_tokens": 5,
    "total_tokens": 33,
  },
}
`;

exports[`chat-completions → google > parallelToolCallsDisabledParam > request 1`] = `
{
  "contents": [
    {
      "parts": [
        {
          "text": "Weather in NYC and LA?",
        },
      ],
      "role": "user",
    },
  ],
  "model": "gemini-2.5-flash",
  "tools": [
    {
      "functionDeclarations": [
        {
          "description": "Get weather",
          "name": "get_weather",
          "parameters": {
            "items": null,
            "properties": {
              "location": {
                "items": null,
                "type": "STRING",
              },
            },
            "required": [
              "location",
            ],
            "type": "OBJECT",
          },
          "response": null,
        },
      ],
    },
  ],
}
`;

exports[`chat-completions → google > parallelToolCallsDisabledParam > response 1`] = `
{
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "message": {
        "annotations": [],
        "role": "assistant",
        "tool_calls": [
          {
            "function": {
              "arguments": "{"location":"NYC"}",
              "name": "get_weather",
            },
            "id": "",
            "type": "function",
          },
          {
            "function": {
              "arguments": "{"location":"LA"}",
              "name": "get_weather",
            },
            "id": "",
            "type": "function",
          },
        ],
      },
    },
  ],
  "created": 0,
  "id": "chatcmpl-transformed",
  "model": "gemini-2.5-flash",
  "object": "chat.completion",
  "usage": {
    "completion_tokens": 101,
    "completion_tokens_details": {
      "reasoning_tokens": 71,
    },
    "prompt_tokens": 41,
    "total_tokens": 142,
  },
}
`;

exports[`chat-completions → google > predictionParam > request 1`] = `
{
  "contents": [
    {
      "parts": [
        {
          "text": "Update this function to add error handling:

function divide(a, b) {
  return a / b;
}",
        },
      ],
      "role": "user",
    },
  ],
  "model": "gemini-2.5-flash",
}
`;

exports[`chat-completions → google > predictionParam > response 1`] = `
{
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "message": {
        "annotations": [],
        "content": "There are several ways to add error handling, depending on how you want to signal the error. The most idiomatic JavaScript approach for a function like this is to **throw an error** when invalid inputs are provided or an impossible operation (like division by zero) is attempted.

Here are a few options, with the first being the most common and recommended for this scenario:

---

### Option 1: Throwing Errors (Recommended)

This approach stops the execution of the function and signals an error that must be caught by the calling code using a \`try...catch\` block. This is best for truly exceptional conditions that prevent the function from returning a valid result.

\`\`\`javascript
function divide(a, b) {
  // 1. Check if inputs are valid numbers
  //    - typeof checks if they are of the 'number' type.
  //    - isNaN checks if they are 'Not a Number' (e.g., Number("hello")).
  //      Note: typeof NaN is 'number', so isNaN is important.
  if (typeof a !== 'number' || typeof b !== 'number' || isNaN(a) || isNaN(b)) {
    throw new Error("Invalid input: Both arguments must be valid numbers.");
  }

  // 2. Check for division by zero
  if (b === 0) {
    throw new Error("Division by zero is not allowed.");
  }

  // If all checks pass, perform the division
  return a / b;
}

// --- How to use it with error handling ---
console.log("--- Using divide with error handling (try...catch) ---");

// Valid cases
try {
  console.log("10 / 2 =", divide(10, 2)); // Expected: 5
} catch (error) {
  console.error("Error:", error.message);
}

try {
  console.log("7 / 3 =", divide(7, 3));   // Expected: 2.333...
} catch (error) {
  console.error("Error:", error.message);
}

// Error cases
try {
  console.log("10 / 0 =", divide(10, 0)); // This will throw an error
} catch (error) {
  console.error("Error:", error.message); // Expected: Error: Division by zero is not allowed.
}

try {
  console.log("'hello' / 2 =", divide("hello", 2)); // This will throw an error
} catch (error) {
  console.error("Error:", error.message); // Expected: Error: Invalid input: Both arguments must be valid numbers.
}

try {
  console.log("5 / null =", divide(5, null)); // null becomes 0, still results in div by zero
} catch (error) {
  console.error("Error:", error.message); // Expected: Error: Division by zero is not allowed.
}

try {
  console.log("5 / NaN =", divide(5, NaN)); // This will throw an error due to NaN input
} catch (error) {
  console.error("Error:", error.message); // Expected: Error: Invalid input: Both arguments must be valid numbers.
}
\`\`\`

---

### Option 2: Returning an Object with Status (Alternative)

This approach avoids throwing exceptions, which some developers prefer for control flow. Instead, it returns a structured object indicating success or failure along with the result or an error message.

\`\`\`javascript
function divideWithObjectReturn(a, b) {
  if (typeof a !== 'number' || typeof b !== 'number' || isNaN(a) || isNaN(b)) {
    return { success: false, error: "Invalid input: Both arguments must be valid numbers." };
  }

  if (b === 0) {
    return { success: false, error: "Division by zero is not allowed." };
  }

  return { success: true, result: a / b };
}

// --- How to use it ---
console.log("\\n--- Using divideWithObjectReturn ---");

let res1 = divideWithObjectReturn(10, 2);
if (res1.success) {
  console.log("10 / 2 =", res1.result); // Expected: 5
} else {
  console.error("Error:", res1.error);
}

let res2 = divideWithObjectReturn(10, 0);
if (res2.success) {
  console.log("10 / 0 =", res2.result);
} else {
  console.error("Error:", res2.error); // Expected: Error: Division by zero is not allowed.
}

let res3 = divideWithObjectReturn("apple", 2);
if (res3.success) {
  console.log("'apple' / 2 =", res3.result);
} else {
  console.error("Error:", res3.error); // Expected: Error: Invalid input: Both arguments must be valid numbers.
}
\`\`\`

---

### Option 3: Returning Special Values (Less Recommended for Errors)

You *could* return \`null\`, \`undefined\`, or even \`NaN\` (though \`NaN\` is already the natural result for \`number / non-number\`). This is generally **less recommended for error handling** because it can be ambiguous (e.g., \`null\` might be a valid result in other contexts) and doesn't provide a clear error message. The caller *must* explicitly check for these special values.

\`\`\`javascript
function divideWithSpecialValue(a, b) {
  if (typeof a !== 'number' || typeof b !== 'number' || isNaN(a) || isNaN(b)) {
    console.error("Error: Invalid input. Both arguments must be valid numbers.");
    return NaN; // Or null, or undefined
  }

  if (b === 0) {
    console.error("Error: Division by zero is not allowed.");
    return NaN; // Or null, or undefined
  }

  return a / b;
}

// --- How to use it ---
console.log("\\n--- Using divideWithSpecialValue ---");

let val1 = divideWithSpecialValue(10, 2);
if (!isNaN(val1)) { // Check for NaN
  console.log("10 / 2 =", val1); // Expected: 5
}

let val2 = divideWithSpecialValue(10, 0);
if (!isNaN(val2)) {
  console.log("10 / 0 =", val2);
} // Console will show error, but the variable gets NaN

let val3 = divideWithSpecialValue("grape", 2);
if (!isNaN(val3)) {
  console.log("'grape' / 2 =", val3);
} // Console will show error, but the variable gets NaN
\`\`\`

---

### Which option to choose?

*   **For robust, clear error handling that prevents invalid states:** **Option 1 (Throwing Errors)** is generally preferred in JavaScript for synchronous functions when an unrecoverable problem occurs. It forces the calling code to consider the error.
*   **For API functions where you want to avoid exceptions as part of normal control flow:** **Option 2 (Returning an Object)** is a good alternative.
*   **Option 3 (Returning Special Values)** is typically discouraged for error handling because it's less explicit and can lead to silent failures or hard-to-debug issues.",
        "role": "assistant",
      },
    },
  ],
  "created": 0,
  "id": "chatcmpl-transformed",
  "model": "gemini-2.5-flash",
  "object": "chat.completion",
  "usage": {
    "completion_tokens": 3246,
    "completion_tokens_details": {
      "reasoning_tokens": 1573,
    },
    "prompt_tokens": 27,
    "total_tokens": 3273,
  },
}
`;

exports[`chat-completions → google > presencePenaltyParam > request 1`] = `
{
  "contents": [
    {
      "parts": [
        {
          "text": "Say ok.",
        },
      ],
      "role": "user",
    },
  ],
  "model": "gemini-2.5-flash",
}
`;

exports[`chat-completions → google > presencePenaltyParam > response 1`] = `
{
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "message": {
        "annotations": [],
        "content": "ok",
        "role": "assistant",
      },
    },
  ],
  "created": 0,
  "id": "chatcmpl-transformed",
  "model": "gemini-2.5-flash",
  "object": "chat.completion",
  "usage": {
    "completion_tokens": 18,
    "completion_tokens_details": {
      "reasoning_tokens": 17,
    },
    "prompt_tokens": 4,
    "total_tokens": 22,
  },
}
`;

exports[`chat-completions → google > promptCacheKeyParam > request 1`] = `
{
  "contents": [
    {
      "parts": [
        {
          "text": "Say ok.",
        },
      ],
      "role": "user",
    },
  ],
  "model": "gemini-2.5-flash",
}
`;

exports[`chat-completions → google > promptCacheKeyParam > response 1`] = `
{
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "message": {
        "annotations": [],
        "content": "ok.",
        "role": "assistant",
      },
    },
  ],
  "created": 0,
  "id": "chatcmpl-transformed",
  "model": "gemini-2.5-flash",
  "object": "chat.completion",
  "usage": {
    "completion_tokens": 25,
    "completion_tokens_details": {
      "reasoning_tokens": 23,
    },
    "prompt_tokens": 4,
    "total_tokens": 29,
  },
}
`;

exports[`chat-completions → google > reasoningEffortLowParam > request 1`] = `
{
  "contents": [
    {
      "parts": [
        {
          "text": "What is 2+2?",
        },
      ],
      "role": "user",
    },
  ],
  "generationConfig": {
    "responseSchema": null,
    "thinkingConfig": {
      "includeThoughts": true,
      "thinkingBudget": 1024,
    },
  },
  "model": "gemini-2.5-flash",
}
`;

exports[`chat-completions → google > reasoningEffortLowParam > response 1`] = `
{
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "message": {
        "annotations": [],
        "content": "Here's a possible summary:

**Addressing the Fundamentals**

Alright, a straightforward arithmetic query. No need to overcomplicate things here. The goal is simply to provide the correct answer as clearly and concisely as possible. I'll get straight to the solution, assuming they're looking for a simple, direct response.
2 + 2 = 4",
        "role": "assistant",
      },
    },
  ],
  "created": 0,
  "id": "chatcmpl-transformed",
  "model": "gemini-2.5-flash",
  "object": "chat.completion",
  "usage": {
    "completion_tokens": 25,
    "completion_tokens_details": {
      "reasoning_tokens": 17,
    },
    "prompt_tokens": 8,
    "total_tokens": 33,
  },
}
`;

exports[`chat-completions → google > reasoningRequest > request 1`] = `
{
  "contents": [
    {
      "parts": [
        {
          "text": "Solve this step by step: If a train travels 60 mph for 2 hours, then 80 mph for 1 hour, what's the average speed?",
        },
      ],
      "role": "user",
    },
  ],
  "model": "gemini-2.5-flash",
}
`;

exports[`chat-completions → google > reasoningRequest > response 1`] = `
{
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "message": {
        "annotations": [],
        "content": "To find the average speed, we need to calculate the **total distance traveled** and the **total time taken**, then divide the total distance by the total time.

Here's a step-by-step breakdown:

**Step 1: Calculate the distance traveled in the first part of the journey.**
*   Speed = 60 mph
*   Time = 2 hours
*   Distance = Speed × Time
*   Distance₁ = 60 mph × 2 hours = 120 miles

**Step 2: Calculate the distance traveled in the second part of the journey.**
*   Speed = 80 mph
*   Time = 1 hour
*   Distance = Speed × Time
*   Distance₂ = 80 mph × 1 hour = 80 miles

**Step 3: Calculate the total distance traveled.**
*   Total Distance = Distance₁ + Distance₂
*   Total Distance = 120 miles + 80 miles = 200 miles

**Step 4: Calculate the total time taken.**
*   Total Time = Time₁ + Time₂
*   Total Time = 2 hours + 1 hour = 3 hours

**Step 5: Calculate the average speed.**
*   Average Speed = Total Distance / Total Time
*   Average Speed = 200 miles / 3 hours

**Step 6: State the final answer.**
*   Average Speed = 66.666... mph
*   Rounded to two decimal places, the average speed is **66.67 mph**.
*   Exactly, the average speed is **66 and 2/3 mph**.",
        "role": "assistant",
      },
    },
  ],
  "created": 0,
  "id": "chatcmpl-transformed",
  "model": "gemini-2.5-flash",
  "object": "chat.completion",
  "usage": {
    "completion_tokens": 923,
    "completion_tokens_details": {
      "reasoning_tokens": 565,
    },
    "prompt_tokens": 37,
    "total_tokens": 960,
  },
}
`;

exports[`chat-completions → google > reasoningRequestTruncated > request 1`] = `
{
  "contents": [
    {
      "parts": [
        {
          "text": "Solve this step by step: If a train travels 60 mph for 2 hours, then 80 mph for 1 hour, what's the average speed?",
        },
      ],
      "role": "user",
    },
  ],
  "generationConfig": {
    "maxOutputTokens": 100,
    "responseSchema": null,
  },
  "model": "gemini-2.5-flash",
}
`;

exports[`chat-completions → google > reasoningRequestTruncated > response 1`] = `
{
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "message": {
        "annotations": [],
        "content": "Let's break",
        "role": "assistant",
      },
    },
  ],
  "created": 0,
  "id": "chatcmpl-transformed",
  "model": "gemini-2.5-flash",
  "object": "chat.completion",
  "usage": {
    "completion_tokens": 96,
    "completion_tokens_details": {
      "reasoning_tokens": 92,
    },
    "prompt_tokens": 37,
    "total_tokens": 133,
  },
}
`;

exports[`chat-completions → google > reasoningSummaryParam > request 1`] = `
{
  "contents": [
    {
      "parts": [
        {
          "text": "What is 2+2?",
        },
      ],
      "role": "user",
    },
  ],
  "generationConfig": {
    "responseSchema": null,
    "thinkingConfig": {
      "includeThoughts": true,
      "thinkingBudget": 2048,
    },
  },
  "model": "gemini-2.5-flash",
}
`;

exports[`chat-completions → google > reasoningSummaryParam > response 1`] = `
{
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "message": {
        "annotations": [],
        "content": "**My Immediate Response to the Query**

Okay, so the user's just given me "What is 2+2?". Right. No need to overthink this. First, I need to analyze the request – it's a straightforward arithmetic query. There's no hidden complexity here, no nuanced interpretation required. Straightforward. Next, I need to retrieve the fundamental fact. It's an instant recall: 2 plus 2 equals 4. It's practically ingrained. Finally, I need to formulate the response, presenting the answer in a clear and direct manner. No embellishment needed.
2+2 = 4",
        "role": "assistant",
      },
    },
  ],
  "created": 0,
  "id": "chatcmpl-transformed",
  "model": "gemini-2.5-flash",
  "object": "chat.completion",
  "usage": {
    "completion_tokens": 69,
    "completion_tokens_details": {
      "reasoning_tokens": 62,
    },
    "prompt_tokens": 8,
    "total_tokens": 77,
  },
}
`;

exports[`chat-completions → google > reasoningWithOutput > request 1`] = `
{
  "contents": [
    {
      "parts": [
        {
          "text": "What color is the sky?",
        },
      ],
      "role": "user",
    },
  ],
  "model": "gemini-2.5-flash",
}
`;

exports[`chat-completions → google > reasoningWithOutput > response 1`] = `
{
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "message": {
        "annotations": [],
        "content": "The sky is most commonly **blue**.

Here's why, and when it can be other colors:

1.  **Blue:** This is the most common color during the day. It's due to a phenomenon called **Rayleigh scattering**. Sunlight (which contains all colors) enters Earth's atmosphere. Blue and violet light have shorter wavelengths and are scattered more efficiently by the tiny molecules of nitrogen and oxygen in the atmosphere than the longer wavelengths (like red and yellow). Because blue light is scattered in all directions, it makes the sky appear blue to our eyes. Our eyes are also more sensitive to blue than violet.

2.  **Red, Orange, Pink, Purple:** At **sunrise and sunset**, the sky often takes on these warm hues. This happens because the sun's light has to travel through much more of the atmosphere to reach our eyes. By the time it gets to us, most of the blue and violet light has been scattered away, allowing the longer wavelengths (red, orange, yellow) to pass through more directly. Dust and pollution can enhance these effects.

3.  **Grey or White:** When it's **overcast or cloudy**, the sky often looks grey or white. Clouds are made of water droplets and ice crystals, which are much larger than the gas molecules in the atmosphere. These larger particles scatter all wavelengths of light more or less equally, resulting in a white or grey appearance. Thicker clouds appear darker grey as less light passes through them.

4.  **Black:** At **night**, the sky appears black (with stars). This is because the side of Earth you are on is facing away from the sun, so there's no sunlight to be scattered by the atmosphere.

5.  **Other Variations:**
    *   **Yellow/Brownish:** Can be due to haze, dust, or heavy pollution.
    *   **Greenish:** Very rarely, sometimes associated with severe thunderstorms (though this is more common with the lighting *within* the storm).

So, while **blue** is the most frequent answer, the sky's color is a dynamic and beautiful display influenced by the time of day, weather, and atmospheric conditions.",
        "role": "assistant",
      },
    },
  ],
  "created": 0,
  "id": "chatcmpl-transformed",
  "model": "gemini-2.5-flash",
  "object": "chat.completion",
  "usage": {
    "completion_tokens": 1165,
    "completion_tokens_details": {
      "reasoning_tokens": 712,
    },
    "prompt_tokens": 7,
    "total_tokens": 1172,
  },
}
`;

exports[`chat-completions → google > safetyIdentifierParam > request 1`] = `
{
  "contents": [
    {
      "parts": [
        {
          "text": "Say ok.",
        },
      ],
      "role": "user",
    },
  ],
  "model": "gemini-2.5-flash",
}
`;

exports[`chat-completions → google > safetyIdentifierParam > response 1`] = `
{
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "message": {
        "annotations": [],
        "content": "ok",
        "role": "assistant",
      },
    },
  ],
  "created": 0,
  "id": "chatcmpl-transformed",
  "model": "gemini-2.5-flash",
  "object": "chat.completion",
  "usage": {
    "completion_tokens": 18,
    "completion_tokens_details": {
      "reasoning_tokens": 17,
    },
    "prompt_tokens": 4,
    "total_tokens": 22,
  },
}
`;

exports[`chat-completions → google > seedParam > request 1`] = `
{
  "contents": [
    {
      "parts": [
        {
          "text": "Pick a number.",
        },
      ],
      "role": "user",
    },
  ],
  "model": "gemini-2.5-flash",
}
`;

exports[`chat-completions → google > seedParam > response 1`] = `
{
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "message": {
        "annotations": [],
        "content": "7",
        "role": "assistant",
      },
    },
  ],
  "created": 0,
  "id": "chatcmpl-transformed",
  "model": "gemini-2.5-flash",
  "object": "chat.completion",
  "usage": {
    "completion_tokens": 530,
    "completion_tokens_details": {
      "reasoning_tokens": 529,
    },
    "prompt_tokens": 5,
    "total_tokens": 535,
  },
}
`;

exports[`chat-completions → google > serviceTierParam > request 1`] = `
{
  "contents": [
    {
      "parts": [
        {
          "text": "Say ok.",
        },
      ],
      "role": "user",
    },
  ],
  "model": "gemini-2.5-flash",
}
`;

exports[`chat-completions → google > serviceTierParam > response 1`] = `
{
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "message": {
        "annotations": [],
        "content": "ok",
        "role": "assistant",
      },
    },
  ],
  "created": 0,
  "id": "chatcmpl-transformed",
  "model": "gemini-2.5-flash",
  "object": "chat.completion",
  "usage": {
    "completion_tokens": 19,
    "completion_tokens_details": {
      "reasoning_tokens": 18,
    },
    "prompt_tokens": 4,
    "total_tokens": 23,
  },
}
`;

exports[`chat-completions → google > simpleRequest > request 1`] = `
{
  "contents": [
    {
      "parts": [
        {
          "text": "What is the capital of France?",
        },
      ],
      "role": "user",
    },
  ],
  "generationConfig": {
    "responseSchema": null,
    "thinkingConfig": {
      "includeThoughts": true,
      "thinkingBudget": 1024,
    },
  },
  "model": "gemini-2.5-flash",
}
`;

exports[`chat-completions → google > simpleRequest > response 1`] = `
{
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "message": {
        "annotations": [],
        "content": "Okay, here's the summary of the thought process, as if I'm having these thoughts:

**Addressing the Direct Inquiry**

Alright, a clear and concise question has been presented. It's a matter of fact, and the expectation is a direct and accurate response. My primary focus is to ensure the information provided is correct and relevant to the user's specific inquiry. No room for ambiguity here; precision is key. I'll need to recall the relevant data or knowledge and communicate it in a straightforward manner. My expertise is relied upon here, so accuracy is of paramount importance. Let's get this right.
The capital of France is **Paris**.",
        "role": "assistant",
      },
    },
  ],
  "created": 0,
  "id": "chatcmpl-transformed",
  "model": "gemini-2.5-flash",
  "object": "chat.completion",
  "usage": {
    "completion_tokens": 25,
    "completion_tokens_details": {
      "reasoning_tokens": 17,
    },
    "prompt_tokens": 8,
    "total_tokens": 33,
  },
}
`;

exports[`chat-completions → google > stopSequencesParam > request 1`] = `
{
  "contents": [
    {
      "parts": [
        {
          "text": "Count from 1 to 20.",
        },
      ],
      "role": "user",
    },
  ],
  "generationConfig": {
    "responseSchema": null,
    "stopSequences": [
      "10",
      "ten",
    ],
  },
  "model": "gemini-2.5-flash",
}
`;

exports[`chat-completions → google > stopSequencesParam > response 1`] = `
{
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "message": {
        "annotations": [],
        "content": "1, 2, 3, 4, 5, 6, 7, 8, 9, ",
        "role": "assistant",
      },
    },
  ],
  "created": 0,
  "id": "chatcmpl-transformed",
  "model": "gemini-2.5-flash",
  "object": "chat.completion",
  "usage": {
    "completion_tokens": 50,
    "completion_tokens_details": {
      "reasoning_tokens": 24,
    },
    "prompt_tokens": 10,
    "total_tokens": 60,
  },
}
`;

exports[`chat-completions → google > storeDisabledParam > request 1`] = `
{
  "contents": [
    {
      "parts": [
        {
          "text": "Say ok.",
        },
      ],
      "role": "user",
    },
  ],
  "model": "gemini-2.5-flash",
}
`;

exports[`chat-completions → google > storeDisabledParam > response 1`] = `
{
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "message": {
        "annotations": [],
        "content": "ok.",
        "role": "assistant",
      },
    },
  ],
  "created": 0,
  "id": "chatcmpl-transformed",
  "model": "gemini-2.5-flash",
  "object": "chat.completion",
  "usage": {
    "completion_tokens": 29,
    "completion_tokens_details": {
      "reasoning_tokens": 27,
    },
    "prompt_tokens": 4,
    "total_tokens": 33,
  },
}
`;

exports[`chat-completions → google > systemMessageArrayContent > request 1`] = `
{
  "contents": [
    {
      "parts": [
        {
          "text": "What errors occurred recently?",
        },
      ],
      "role": "user",
    },
  ],
  "generationConfig": {
    "maxOutputTokens": 300,
    "responseSchema": null,
  },
  "model": "gemini-2.5-flash",
  "systemInstruction": {
    "parts": [
      {
        "text": "You are a helpful data analyst. The default data source is project_logs with id abc-123.",
      },
    ],
  },
}
`;

exports[`chat-completions → google > systemMessageArrayContent > response 1`] = `
{
  "choices": [
    {
      "finish_reason": "length",
      "index": 0,
      "message": {
        "annotations": [],
        "content": "To find recent errors, I'll query the \`project_logs\` data source and look for entries with an error or critical log level.

\`\`\`sql
SELECT
  timestamp,
  level,
  message,
  service,
  trace_id
FROM
  project_logs
WHERE
  level IN ('error', 'critical')
ORDER BY
  timestamp DESC
LIMIT 20;
\`\`\`

This query will retrieve the 20 most recent log entries that have a level of",
        "role": "assistant",
      },
    },
  ],
  "created": 0,
  "id": "chatcmpl-transformed",
  "model": "gemini-2.5-flash",
  "object": "chat.completion",
  "usage": {
    "completion_tokens": 296,
    "completion_tokens_details": {
      "reasoning_tokens": 189,
    },
    "prompt_tokens": 29,
    "total_tokens": 325,
  },
}
`;

exports[`chat-completions → google > temperatureParam > request 1`] = `
{
  "contents": [
    {
      "parts": [
        {
          "text": "Say hi.",
        },
      ],
      "role": "user",
    },
  ],
  "generationConfig": {
    "responseSchema": null,
    "temperature": 0.7,
  },
  "model": "gemini-2.5-flash",
}
`;

exports[`chat-completions → google > temperatureParam > response 1`] = `
{
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "message": {
        "annotations": [],
        "content": "Hi there!",
        "role": "assistant",
      },
    },
  ],
  "created": 0,
  "id": "chatcmpl-transformed",
  "model": "gemini-2.5-flash",
  "object": "chat.completion",
  "usage": {
    "completion_tokens": 18,
    "completion_tokens_details": {
      "reasoning_tokens": 15,
    },
    "prompt_tokens": 4,
    "total_tokens": 22,
  },
}
`;

exports[`chat-completions → google > textFormatJsonObjectParam > request 1`] = `
{
  "contents": [
    {
      "parts": [
        {
          "text": "Return {"status": "ok"} as JSON.",
        },
      ],
      "role": "user",
    },
  ],
  "generationConfig": {
    "responseMimeType": "application/json",
    "responseSchema": null,
  },
  "model": "gemini-2.5-flash",
}
`;

exports[`chat-completions → google > textFormatJsonObjectParam > response 1`] = `
{
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "message": {
        "annotations": [],
        "content": "{"status": "ok"}",
        "role": "assistant",
      },
    },
  ],
  "created": 0,
  "id": "chatcmpl-transformed",
  "model": "gemini-2.5-flash",
  "object": "chat.completion",
  "usage": {
    "completion_tokens": 29,
    "completion_tokens_details": {
      "reasoning_tokens": 23,
    },
    "prompt_tokens": 11,
    "total_tokens": 40,
  },
}
`;

exports[`chat-completions → google > textFormatJsonSchemaParam > request 1`] = `
{
  "contents": [
    {
      "parts": [
        {
          "text": "Extract: John is 25.",
        },
      ],
      "role": "user",
    },
  ],
  "generationConfig": {
    "responseMimeType": "application/json",
    "responseSchema": {
      "items": null,
      "properties": {
        "age": {
          "items": null,
          "type": "NUMBER",
        },
        "name": {
          "items": null,
          "type": "STRING",
        },
      },
      "required": [
        "name",
        "age",
      ],
      "type": "OBJECT",
    },
  },
  "model": "gemini-2.5-flash",
}
`;

exports[`chat-completions → google > textFormatJsonSchemaParam > response 1`] = `
{
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "message": {
        "annotations": [],
        "content": "{"name": "John", "age": 25}",
        "role": "assistant",
      },
    },
  ],
  "created": 0,
  "id": "chatcmpl-transformed",
  "model": "gemini-2.5-flash",
  "object": "chat.completion",
  "usage": {
    "completion_tokens": 114,
    "completion_tokens_details": {
      "reasoning_tokens": 101,
    },
    "prompt_tokens": 9,
    "total_tokens": 123,
  },
}
`;

exports[`chat-completions → google > textFormatJsonSchemaWithDescriptionParam > request 1`] = `
{
  "contents": [
    {
      "parts": [
        {
          "text": "Extract: John is 25.",
        },
      ],
      "role": "user",
    },
  ],
  "generationConfig": {
    "responseMimeType": "application/json",
    "responseSchema": {
      "items": null,
      "properties": {
        "age": {
          "items": null,
          "type": "NUMBER",
        },
        "name": {
          "items": null,
          "type": "STRING",
        },
      },
      "required": [
        "name",
        "age",
      ],
      "type": "OBJECT",
    },
  },
  "model": "gemini-2.5-flash",
}
`;

exports[`chat-completions → google > textFormatJsonSchemaWithDescriptionParam > response 1`] = `
{
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "message": {
        "annotations": [],
        "content": "{"name":"John","age":25}",
        "role": "assistant",
      },
    },
  ],
  "created": 0,
  "id": "chatcmpl-transformed",
  "model": "gemini-2.5-flash",
  "object": "chat.completion",
  "usage": {
    "completion_tokens": 87,
    "completion_tokens_details": {
      "reasoning_tokens": 77,
    },
    "prompt_tokens": 9,
    "total_tokens": 96,
  },
}
`;

exports[`chat-completions → google > textFormatTextParam > request 1`] = `
{
  "contents": [
    {
      "parts": [
        {
          "text": "Say hello.",
        },
      ],
      "role": "user",
    },
  ],
  "generationConfig": {
    "responseMimeType": "text/plain",
    "responseSchema": null,
  },
  "model": "gemini-2.5-flash",
}
`;

exports[`chat-completions → google > textFormatTextParam > response 1`] = `
{
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "message": {
        "annotations": [],
        "content": "Hello!",
        "role": "assistant",
      },
    },
  ],
  "created": 0,
  "id": "chatcmpl-transformed",
  "model": "gemini-2.5-flash",
  "object": "chat.completion",
  "usage": {
    "completion_tokens": 17,
    "completion_tokens_details": {
      "reasoning_tokens": 15,
    },
    "prompt_tokens": 4,
    "total_tokens": 21,
  },
}
`;

exports[`chat-completions → google > toolCallRequest > request 1`] = `
{
  "contents": [
    {
      "parts": [
        {
          "text": "What's the weather like in San Francisco?",
        },
      ],
      "role": "user",
    },
  ],
  "model": "gemini-2.5-flash",
  "toolConfig": {
    "functionCallingConfig": {
      "mode": "AUTO",
    },
  },
  "tools": [
    {
      "functionDeclarations": [
        {
          "description": "Get the current weather for a location",
          "name": "get_weather",
          "parameters": {
            "items": null,
            "properties": {
              "location": {
                "description": "The city and state, e.g. San Francisco, CA",
                "items": null,
                "type": "STRING",
              },
            },
            "required": [
              "location",
            ],
            "type": "OBJECT",
          },
          "response": null,
        },
      ],
    },
  ],
}
`;

exports[`chat-completions → google > toolCallRequest > response 1`] = `
{
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "message": {
        "annotations": [],
        "role": "assistant",
        "tool_calls": [
          {
            "function": {
              "arguments": "{"location":"San Francisco, CA"}",
              "name": "get_weather",
            },
            "id": "",
            "type": "function",
          },
        ],
      },
    },
  ],
  "created": 0,
  "id": "chatcmpl-transformed",
  "model": "gemini-2.5-flash",
  "object": "chat.completion",
  "usage": {
    "completion_tokens": 94,
    "completion_tokens_details": {
      "reasoning_tokens": 76,
    },
    "prompt_tokens": 62,
    "total_tokens": 156,
  },
}
`;

exports[`chat-completions → google > toolChoiceRequiredParam > request 1`] = `
{
  "contents": [
    {
      "parts": [
        {
          "text": "Tokyo weather",
        },
      ],
      "role": "user",
    },
  ],
  "model": "gemini-2.5-flash",
  "toolConfig": {
    "functionCallingConfig": {
      "allowedFunctionNames": [
        "get_weather",
      ],
      "mode": "ANY",
    },
  },
  "tools": [
    {
      "functionDeclarations": [
        {
          "description": "Get weather",
          "name": "get_weather",
          "parameters": {
            "items": null,
            "properties": {
              "location": {
                "items": null,
                "type": "STRING",
              },
            },
            "required": [
              "location",
            ],
            "type": "OBJECT",
          },
          "response": null,
        },
      ],
    },
  ],
}
`;

exports[`chat-completions → google > toolChoiceRequiredParam > response 1`] = `
{
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "message": {
        "annotations": [],
        "role": "assistant",
        "tool_calls": [
          {
            "function": {
              "arguments": "{"location":"Tokyo"}",
              "name": "get_weather",
            },
            "id": "",
            "type": "function",
          },
        ],
      },
    },
  ],
  "created": 0,
  "id": "chatcmpl-transformed",
  "model": "gemini-2.5-flash",
  "object": "chat.completion",
  "usage": {
    "completion_tokens": 62,
    "completion_tokens_details": {
      "reasoning_tokens": 47,
    },
    "prompt_tokens": 37,
    "total_tokens": 99,
  },
}
`;

exports[`chat-completions → google > topPParam > request 1`] = `
{
  "contents": [
    {
      "parts": [
        {
          "text": "Say hi.",
        },
      ],
      "role": "user",
    },
  ],
  "generationConfig": {
    "responseSchema": null,
    "topP": 0.9,
  },
  "model": "gemini-2.5-flash",
}
`;

exports[`chat-completions → google > topPParam > response 1`] = `
{
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "message": {
        "annotations": [],
        "content": "Hi!",
        "role": "assistant",
      },
    },
  ],
  "created": 0,
  "id": "chatcmpl-transformed",
  "model": "gemini-2.5-flash",
  "object": "chat.completion",
  "usage": {
    "completion_tokens": 29,
    "completion_tokens_details": {
      "reasoning_tokens": 27,
    },
    "prompt_tokens": 4,
    "total_tokens": 33,
  },
}
`;

exports[`responses → anthropic > complexReasoningRequest > request 1`] = `
{
  "max_tokens": 20000,
  "messages": [
    {
      "content": "There is a digital clock, with minutes and hours in the form of 00:00. The clock shows all times from 00:00 to 23:59 and repeating. Imagine you had a list of all these times. Which digit(s) is the most common and which is the rarest? Can you find their percentage?",
      "role": "user",
    },
  ],
  "model": "claude-sonnet-4-5-20250929",
  "thinking": {
    "budget_tokens": 15000,
    "type": "enabled",
  },
}
`;

exports[`responses → anthropic > complexReasoningRequest > response 1`] = `
{
  "created_at": 0,
  "id": "resp_transformed",
  "model": "claude-sonnet-4-20250514",
  "object": "response",
  "output": [
    {
      "encrypted_content": "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",
      "summary": [
        {
          "text": "Let me think about this step by step. I need to count how many times each digit (0-9) appears in a 24-hour digital clock format (00:00 to 23:59).

The format is HH:MM where:
- HH ranges from 00 to 23 (hours)
- MM ranges from 00 to 59 (minutes)

Let me count each digit position separately:

**Hours - First digit (tens place):**
- 0: appears in 00:xx to 09:xx → 10 hours × 60 minutes = 600 times
- 1: appears in 10:xx to 19:xx → 10 hours × 60 minutes = 600 times  
- 2: appears in 20:xx to 23:xx → 4 hours × 60 minutes = 240 times
- 3,4,5,6,7,8,9: never appear in hours tens place → 0 times each

**Hours - Second digit (units place):**
- 0: appears in 00:xx, 10:xx, 20:xx → 3 hours × 60 minutes = 180 times
- 1: appears in 01:xx, 11:xx, 21:xx → 3 hours × 60 minutes = 180 times
- 2: appears in 02:xx, 12:xx, 22:xx → 3 hours × 60 minutes = 180 times
- 3: appears in 03:xx, 13:xx, 23:xx → 3 hours × 60 minutes = 180 times
- 4: appears in 04:xx, 14:xx → 2 hours × 60 minutes = 120 times
- 5: appears in 05:xx, 15:xx → 2 hours × 60 minutes = 120 times


- 6: appears in 06:xx, 16:xx → 2 hours × 60 minutes = 120 times
- 7: appears in 07:xx, 17:xx → 2 hours × 60 minutes = 120 times
- 8: appears in 08:xx, 18:xx → 2 hours × 60 minutes = 120 times
- 9: appears in 09:xx, 19:xx → 2 hours × 60 minutes = 120 times

**Minutes - First digit (tens place):**
- 0: appears in xx:0y where y = 0-9 → 24 hours × 10 occurrences = 240 times
- 1: appears in xx:1y where y = 0-9 → 24 hours × 10 occurrences = 240 times
- 2: appears in xx:2y where y = 0-9 → 24 hours × 10 occurrences = 240 times
- 3: appears in xx:3y where y = 0-9 → 24 hours × 10 occurrences = 240 times
- 4: appears in xx:4y where y = 0-9 → 24 hours × 10 occurrences = 240 times
- 5: appears in xx:5y where y = 0-9 → 24 hours × 10 occurrences = 240 times
- 6,7,8,9: never appear in minutes tens place → 0 times each in minutes tens place → 0 times each

For the units digit of minutes, digits 0-5 each appear 144 times (once per hour across 24 hours), while 6-9 never appear in that position. 0: appears 1,164 times total—600 times in the hours tens place, 180 in the hours units, 240 in the minutes tens, and 144 in the minutes units. Digit 1 also totals 1,164 with the same distribution across each position. Digit 2 appears 804 times (240 + 180 + 240 + 144), while digit 3 shows 0 occurrences in the hours tens place but maintains 180, 240, and 144 across the other positions.

Digit 4 appears 504 times—the hours tens contributes 0, hours units contributes 120, minutes tens contributes 240, and minutes units contributes 144. Digit 5 has the same frequency of 504. Digit 6 drops to 264 total appearances, with only the hours units (120) and minutes units (144) contributing. Digit 7 follows a similar pattern to the previous digits, with 0 in the hours tens and 120 in the hours units

, plus 144 in the minutes units, totaling 264. Digits 8 and 9 each appear 264 times as well, following the same distribution. The total count across all 24 hours and 60 minutes with 4 digits per display equals 5,760 digits, and summing all occurrences begins with 1,164 plus the contributions from the remaining digits.

The sum confirms the calculation: 1,164 + 804 + 564 + 504 + 504 + 264 + 264 + 264 + 264 = 5,760. Digits 0 and 1 are most frequent at 1,164 appearances each (roughly 20.2%), while 6, 7, 8, and 9 are least common at 264 appearances each (about 4.6%).",
          "type": "summary_text",
        },
      ],
      "type": "reasoning",
    },
    {
      "content": [
        {
          "text": "Looking at a 24-hour digital clock (00:00 to 23:59), I need to count how often each digit appears across all 1,440 possible times.

Let me break this down by position:

**Hours (first digit - tens place):**
- 0: appears 00:xx through 09:xx = 10 hours × 60 minutes = 600 times
- 1: appears 10:xx through 19:xx = 10 hours × 60 minutes = 600 times  
- 2: appears 20:xx through 23:xx = 4 hours × 60 minutes = 240 times
- 3-9: never appear = 0 times each

**Hours (second digit - units place):**
- 0-3: each appears 3 times per day (e.g., 0 appears in 00:xx, 10:xx, 20:xx) = 3 × 60 = 180 times each
- 4-9: each appears 2 times per day (e.g., 4 appears in 04:xx, 14:xx) = 2 × 60 = 120 times each

**Minutes (first digit - tens place):**
- 0-5: each appears in every hour for 10 minutes (x0-x9) = 24 × 10 = 240 times each
- 6-9: never appear = 0 times each

**Minutes (second digit - units place):**
- 0-9: each appears 6 times per hour (x0, x1, x2, x3, x4, x5) = 24 × 6 = 144 times each

**Total occurrences:**
- **0**: 600 + 180 + 240 + 144 = **1,164**
- **1**: 600 + 180 + 240 + 144 = **1,164**
- **2**: 240 + 180 + 240 + 144 = **804**
- **3**: 0 + 180 + 240 + 144 = **564**
- **4**: 0 + 120 + 240 + 144 = **504**
- **5**: 0 + 120 + 240 + 144 = **504**
- **6**: 0 + 120 + 0 + 144 = **264**
- **7**: 0 + 120 + 0 + 144 = **264**
- **8**: 0 + 120 + 0 + 144 = **264**
- **9**: 0 + 120 + 0 + 144 = **264**

Total digits: 24 × 60 × 4 = 5,760

**Results:**
- **Most common:** Digits **0 and 1** (tied)
  - 1,164 occurrences each = **20.21%**

- **Rarest:** Digits **6, 7, 8, and 9** (tied)  
  - 264 occurrences each = **4.58%**

The digits 0 and 1 dominate because they appear frequently in both hours (00-19) and minutes (00-19, x0-x1), while 6-9 are restricted since they can't appear in the tens place of minutes and have limited presence in hours.",
          "type": "output_text",
        },
      ],
      "role": "assistant",
      "status": "completed",
      "type": "message",
    },
  ],
  "output_text": "Looking at a 24-hour digital clock (00:00 to 23:59), I need to count how often each digit appears across all 1,440 possible times.

Let me break this down by position:

**Hours (first digit - tens place):**
- 0: appears 00:xx through 09:xx = 10 hours × 60 minutes = 600 times
- 1: appears 10:xx through 19:xx = 10 hours × 60 minutes = 600 times  
- 2: appears 20:xx through 23:xx = 4 hours × 60 minutes = 240 times
- 3-9: never appear = 0 times each

**Hours (second digit - units place):**
- 0-3: each appears 3 times per day (e.g., 0 appears in 00:xx, 10:xx, 20:xx) = 3 × 60 = 180 times each
- 4-9: each appears 2 times per day (e.g., 4 appears in 04:xx, 14:xx) = 2 × 60 = 120 times each

**Minutes (first digit - tens place):**
- 0-5: each appears in every hour for 10 minutes (x0-x9) = 24 × 10 = 240 times each
- 6-9: never appear = 0 times each

**Minutes (second digit - units place):**
- 0-9: each appears 6 times per hour (x0, x1, x2, x3, x4, x5) = 24 × 6 = 144 times each

**Total occurrences:**
- **0**: 600 + 180 + 240 + 144 = **1,164**
- **1**: 600 + 180 + 240 + 144 = **1,164**
- **2**: 240 + 180 + 240 + 144 = **804**
- **3**: 0 + 180 + 240 + 144 = **564**
- **4**: 0 + 120 + 240 + 144 = **504**
- **5**: 0 + 120 + 240 + 144 = **504**
- **6**: 0 + 120 + 0 + 144 = **264**
- **7**: 0 + 120 + 0 + 144 = **264**
- **8**: 0 + 120 + 0 + 144 = **264**
- **9**: 0 + 120 + 0 + 144 = **264**

Total digits: 24 × 60 × 4 = 5,760

**Results:**
- **Most common:** Digits **0 and 1** (tied)
  - 1,164 occurrences each = **20.21%**

- **Rarest:** Digits **6, 7, 8, and 9** (tied)  
  - 264 occurrences each = **4.58%**

The digits 0 and 1 dominate because they appear frequently in both hours (00-19) and minutes (00-19, x0-x1), while 6-9 are restricted since they can't appear in the tens place of minutes and have limited presence in hours.",
  "parallel_tool_calls": false,
  "status": "completed",
  "tool_choice": "none",
  "tools": [],
  "usage": {
    "input_tokens": 109,
    "input_tokens_details": {
      "cached_tokens": 0,
    },
    "output_tokens": 2889,
    "output_tokens_details": {
      "reasoning_tokens": 0,
    },
    "total_tokens": 2998,
  },
}
`;

exports[`responses → anthropic > multimodalRequest > request 1`] = `
{
  "max_tokens": 300,
  "messages": [
    {
      "content": [
        {
          "text": "What do you see in this image?",
          "type": "text",
        },
        {
          "source": {
            "type": "url",
            "url": "https://t3.ftcdn.net/jpg/02/36/99/22/360_F_236992283_sNOxCVQeFLd5pdqaKGh8DRGMZy7P4XKm.jpg",
          },
          "type": "image",
        },
      ],
      "role": "user",
    },
  ],
  "model": "claude-sonnet-4-5-20250929",
}
`;

exports[`responses → anthropic > multimodalRequest > response 1`] = `
{
  "created_at": 0,
  "id": "resp_transformed",
  "model": "claude-sonnet-4-20250514",
  "object": "response",
  "output": [
    {
      "content": [
        {
          "text": "I see an adorable tabby kitten lying on its side on what appears to be a wooden floor. The kitten has beautiful striped markings in brown and gray, with distinctive large yellow-green eyes that are looking directly at the camera. Its head is tilted in a very cute, curious pose. The kitten appears to be quite young, with soft fur and the typical playful posture of a young cat. In the blurred background, I can see what looks like furniture or shelving. The lighting creates a warm, cozy atmosphere that really highlights the kitten's sweet expression and beautiful markings.",
          "type": "output_text",
        },
      ],
      "role": "assistant",
      "status": "completed",
      "type": "message",
    },
  ],
  "output_text": "I see an adorable tabby kitten lying on its side on what appears to be a wooden floor. The kitten has beautiful striped markings in brown and gray, with distinctive large yellow-green eyes that are looking directly at the camera. Its head is tilted in a very cute, curious pose. The kitten appears to be quite young, with soft fur and the typical playful posture of a young cat. In the blurred background, I can see what looks like furniture or shelving. The lighting creates a warm, cozy atmosphere that really highlights the kitten's sweet expression and beautiful markings.",
  "parallel_tool_calls": false,
  "status": "completed",
  "tool_choice": "none",
  "tools": [],
  "usage": {
    "input_tokens": 278,
    "input_tokens_details": {
      "cached_tokens": 0,
    },
    "output_tokens": 131,
    "output_tokens_details": {
      "reasoning_tokens": 0,
    },
    "total_tokens": 409,
  },
}
`;

exports[`responses → anthropic > reasoningRequest > request 1`] = `
{
  "max_tokens": 4096,
  "messages": [
    {
      "content": "Solve this step by step: If a train travels 60 mph for 2 hours, then 80 mph for 1 hour, what's the average speed?",
      "role": "user",
    },
  ],
  "model": "claude-sonnet-4-5-20250929",
  "thinking": {
    "budget_tokens": 3072,
    "type": "enabled",
  },
}
`;

exports[`responses → anthropic > reasoningRequest > response 1`] = `
{
  "created_at": 0,
  "id": "resp_transformed",
  "model": "claude-sonnet-4-20250514",
  "object": "response",
  "output": [
    {
      "encrypted_content": "Eo0GCkYICxgCKkCWf5Li7DwaRpTlXZCfNw43LgmK9ISm7pa+HJwOBIujpZp0rVwyqs4pp9tyLYcmHMcDn+3snF7mmekHzpIxPnkpEgzmJ2TOpmD7L2HwIH0aDE3GPAjq0ucjYgh3IiIwuHKY7BkarOdihXcA0/3Sd3wOLI6SS2OFQNYJfx+UYpJ3LNOh/Rdj6E3eBJTodUWqKvQEb2v8j7bjyzZT0Y6NCQCDlnmVx2vZDWScj//tuqA6385lL4OhjWyV9QPkzJDmL3aojSR+Jm1N9OFy5tPEHZ3P5OAF4ITS2pSTzxtQgMG5CdTD/GwLneAFoY0UBmDdareTfcoohR4YrPbbWEjR059NfcTzimPwNVI/YcGNLDj6GUPmhPcQlaz1z+rEnLOYwDb+Vv28xnuNMQgrjl3sbcsgrqOBRfkv8EAQqRv8ITZMkZgv5CrS4SOsnjDzYo3Ii91W4IXtsm7lOT3aJhZgLAyriP1dUa7dYByz5U1uqk18GEZMyd907UOtNRZCw+HdnOr5Saf06KemTjVvxaTQdMDurfKCPAVWICGhgLwHlIYv41y5hpyYfaKUB9X4x/j0Op8u72x+s0kqDY+JOpnhyx0CN8Cn0xyiepq0rfi76eBuJvs0k0mEb9TIlCHiSGfYHF7w73pM6NWOd5CHXD4tcxcuyGOjUn4CBb/HrQNGT+7zRQxUsq65XN6kDeWYxV6PhChu6JWuU35FI9Fh1IvEjJVxGcVkJQNQM7Gz7/ZdH19AScmZy79ysQV1A09l72sesM0FwGy3LY+Gr6N9YxjaKRcmJa8Za2qocxR9EDYl6ZS4tIwjbm1+l5bfvwfxiJZznAKxalB+hWR5T9Ifktqny114HuJy/s1lv3LrD06I0D2vF+CboOpYgzHvanjRGVIIRZw8KqQOSoolqAW561kRVFnR+Ra7KVoLqZkpYKwIVXwRG4hKUPViQ6oe43LDRS0rO/7aFYpc1lMMDdIiLxTQdr/Z98NgRV3aAiYCNysgOuVA5u+NplUsezolBViAfPWqLRuwAqHcxRgB",
      "summary": [
        {
          "text": "To find the average speed, I need to use the formula:
Average speed = Total distance / Total time

Let me break this down step by step:

Step 1: Find the distance traveled in each segment
- First segment: 60 mph for 2 hours
  Distance = speed × time = 60 × 2 = 120 miles

- Second segment: 80 mph for 1 hour  
  Distance = speed × time = 80 × 1 = 80 miles

Step 2: Find total distance
Total distance = 120 + 80 = 200 miles

Step 3: Find total time
Total time = 2 hours + 1 hour = 3 hours

Step 4: Calculate average speed
Average speed = Total distance / Total time = 200 miles / 3 hours = 66.67 mph (rounded)",
          "type": "summary_text",
        },
      ],
      "type": "reasoning",
    },
    {
      "content": [
        {
          "text": "I'll solve this step-by-step using the average speed formula.

**Step 1: Calculate distance for each segment**

First segment:
- Speed = 60 mph
- Time = 2 hours
- Distance = 60 mph × 2 hours = 120 miles

Second segment:
- Speed = 80 mph  
- Time = 1 hour
- Distance = 80 mph × 1 hour = 80 miles

**Step 2: Find totals**

Total distance = 120 miles + 80 miles = 200 miles
Total time = 2 hours + 1 hour = 3 hours

**Step 3: Calculate average speed**

Average speed = Total distance ÷ Total time
Average speed = 200 miles ÷ 3 hours = 66.67 mph

**Answer: The average speed is 66.67 mph (or 66⅔ mph)**

Note: Average speed is not the same as the average of the speeds (which would be 70 mph). We must use total distance divided by total time.",
          "type": "output_text",
        },
      ],
      "role": "assistant",
      "status": "completed",
      "type": "message",
    },
  ],
  "output_text": "I'll solve this step-by-step using the average speed formula.

**Step 1: Calculate distance for each segment**

First segment:
- Speed = 60 mph
- Time = 2 hours
- Distance = 60 mph × 2 hours = 120 miles

Second segment:
- Speed = 80 mph  
- Time = 1 hour
- Distance = 80 mph × 1 hour = 80 miles

**Step 2: Find totals**

Total distance = 120 miles + 80 miles = 200 miles
Total time = 2 hours + 1 hour = 3 hours

**Step 3: Calculate average speed**

Average speed = Total distance ÷ Total time
Average speed = 200 miles ÷ 3 hours = 66.67 mph

**Answer: The average speed is 66.67 mph (or 66⅔ mph)**

Note: Average speed is not the same as the average of the speeds (which would be 70 mph). We must use total distance divided by total time.",
  "parallel_tool_calls": false,
  "status": "completed",
  "tool_choice": "none",
  "tools": [],
  "usage": {
    "input_tokens": 74,
    "input_tokens_details": {
      "cached_tokens": 0,
    },
    "output_tokens": 464,
    "output_tokens_details": {
      "reasoning_tokens": 0,
    },
    "total_tokens": 538,
  },
}
`;

exports[`responses → anthropic > reasoningRequestTruncated > request 1`] = `
{
  "max_tokens": 100,
  "messages": [
    {
      "content": "Solve this step by step: If a train travels 60 mph for 2 hours, then 80 mph for 1 hour, what's the average speed?",
      "role": "user",
    },
  ],
  "model": "claude-sonnet-4-5-20250929",
  "thinking": {
    "budget_tokens": 1024,
    "type": "enabled",
  },
}
`;

exports[`responses → anthropic > reasoningWithOutput > request 1`] = `
{
  "max_tokens": 4096,
  "messages": [
    {
      "content": "What color is the sky?",
      "role": "user",
    },
  ],
  "model": "claude-sonnet-4-5-20250929",
  "thinking": {
    "budget_tokens": 1024,
    "type": "enabled",
  },
}
`;

exports[`responses → anthropic > reasoningWithOutput > response 1`] = `
{
  "created_at": 0,
  "id": "resp_transformed",
  "model": "claude-sonnet-4-20250514",
  "object": "response",
  "output": [
    {
      "encrypted_content": "EpYGCkYICxgCKkDN0nKcZq8FjobVKFRb/xmfE/ZmkXPjejR+8xqPKeX6NMwzUgZBwYF732MyAKiER9EaUnbQDjpWFRkaIQd0aZeSEgwqn1/xoeOa7mMd7iAaDBBrJWYvm/rxe+qXdCIwl09l4kLNYU9hXlt2DplQnw/vXj7+4nkQr9QfDtGPHSfB8qT7N/EvX2u1NNPCE/33Kv0EcrFjnsFD3It5CCbrEBch1E9YSCCqO3lO1toOZv+ZTxyJ+TM1ihlwUVbIYAMWNn0/4+m2Yav7NygZzUXqn23AVsA+dS5snO3DzoS5YMhRVlZD2BwqLcZ+wHB2oDHV32/JCLLS0FukolqHFK8zh/Nlr8NPj0EfY5eaSf7O0JzcwmbjKQh/LNuM4gFbOZHHsCQU53ehWJKIXUNzDZEA2Po/ZlLKCOMKwyPmZrHHKihckJNi2R0cNgb2VfL5yjnOOmyfPwnqlgQxxQB5fJjtIjnZSLo/gIU6ec+8JYriPU4oDAITptadCfTYxqc6sAw2arzkC+DksfWIfzJBU9FihHwvzi1a8QoAzWrn+yRT9CgKfkB8JKLA2LnwWFouMAGBfMuO3wLlmxtftdNjZXroL7jTv3WC6y3S1P0Yk1re+wR2OcNdiOUOgnKASW3ItCj+WD25dsnMOuCm4efKpziFtHEczXIzrs6prTmh6NaVUrQ1UfwTP8zAlpXbSwmBO0fT/GHRQifwk+WWqxclld7lmM9eEqYQ9gv0oXyuFBnG56sbFErHxE3qEOeXJESCTTAutERl9W47KDGfqcUzZ9CaOuKDvBajAgLWtbyXeNYB/tQeQ+Gs8It8mOimYpOIFAZ8fewxwG5uK5rH2qbTbZwR9Xu6+Hqu2t4zHB7Vmyk+m4zo+HTI7/sCibKUnzawqmLuRIpTzlKM8B8sMdV/p/2gps24E4FgpR2ZZqLLSnsn3mvxO6sJdOzo/JbnOZbw5ur0K9VZs6rIiPLHlVtkVmQ0rOhcF+N4afArXpW3/ZfdDlOrsWPJ6dTZJE83oaM75sABow5RSQBtQ4CcZt+M5r3oSRgB",
      "summary": [
        {
          "text": "This is a straightforward question about the color of the sky. The sky appears blue during the day under normal clear weather conditions. This is due to a phenomenon called Rayleigh scattering, where shorter blue wavelengths of light are scattered more by the molecules in Earth's atmosphere than longer wavelengths like red.

However, I should note that the sky can appear different colors depending on conditions:
- Blue during a clear day
- Various shades during sunrise/sunset (orange, red, pink, purple)
- Gray or white when cloudy
- Dark/black at night

I'll give the most common answer but acknowledge it can vary.",
          "type": "summary_text",
        },
      ],
      "type": "reasoning",
    },
    {
      "content": [
        {
          "text": "The sky is typically blue during the day when it's clear. This blue color is caused by the way sunlight interacts with particles in Earth's atmosphere - shorter blue wavelengths of light get scattered more than other colors.

However, the sky can appear different colors depending on conditions:
- Orange, red, or pink during sunrise and sunset
- Gray or white when cloudy
- Dark blue to black at night
- Sometimes purple, yellow, or other hues during certain weather conditions",
          "type": "output_text",
        },
      ],
      "role": "assistant",
      "status": "completed",
      "type": "message",
    },
  ],
  "output_text": "The sky is typically blue during the day when it's clear. This blue color is caused by the way sunlight interacts with particles in Earth's atmosphere - shorter blue wavelengths of light get scattered more than other colors.

However, the sky can appear different colors depending on conditions:
- Orange, red, or pink during sunrise and sunset
- Gray or white when cloudy
- Dark blue to black at night
- Sometimes purple, yellow, or other hues during certain weather conditions",
  "parallel_tool_calls": false,
  "status": "completed",
  "tool_choice": "none",
  "tools": [],
  "usage": {
    "input_tokens": 42,
    "input_tokens_details": {
      "cached_tokens": 0,
    },
    "output_tokens": 251,
    "output_tokens_details": {
      "reasoning_tokens": 0,
    },
    "total_tokens": 293,
  },
}
`;

exports[`responses → anthropic > simpleRequest > request 1`] = `
{
  "max_tokens": 4096,
  "messages": [
    {
      "content": "What is the capital of France?",
      "role": "user",
    },
  ],
  "model": "claude-sonnet-4-5-20250929",
  "thinking": {
    "budget_tokens": 1024,
    "type": "enabled",
  },
}
`;

exports[`responses → anthropic > simpleRequest > response 1`] = `
{
  "created_at": 0,
  "id": "resp_transformed",
  "model": "claude-sonnet-4-20250514",
  "object": "response",
  "output": [
    {
      "encrypted_content": "EsoCCkYICxgCKkD5zM+jgIUOjDIU1NKWmzpNdQCwQNYUkunavnh72prMHBnjZcKGxtNT7MGMpcPg0oPpsj6mhkPR6WqafUiIZ5oXEgxZ3jOspYjQZ1/H2BkaDD2yEjUiKzYpFeL8hCIwsUxcqKLB15jz7steuNJ1I3E6zTBnL8mffUALE2O5kHsEMr66BT58XjJnu+2UDbhOKrEBTltQkF5iDAOchP5zay+8PZkvWQuoGKO2q9IMRvP/69sAXngSnbbp/kMpIfXmVRSC187MAB1RmURe0zzeQAcQz5hTyAOl5sAi00X6pYOgtz1YaDtkO/MSDwMWqIEQwB/kBj9Nat9WXXMH674G9gLcmJij5MumEuvPYcZ6NqfY8hQ0y/tO/Pxhp6gzgthGzQse1EzWI1Shh1LAaoFDRWCHbl/4Rcb4rpPGx0Xon5Qtnv67GAE=",
      "summary": [
        {
          "text": "This is a straightforward factual question about geography. The capital of France is Paris. This is basic, well-established knowledge that I can answer directly.",
          "type": "summary_text",
        },
      ],
      "type": "reasoning",
    },
    {
      "content": [
        {
          "text": "The capital of France is Paris.",
          "type": "output_text",
        },
      ],
      "role": "assistant",
      "status": "completed",
      "type": "message",
    },
  ],
  "output_text": "The capital of France is Paris.",
  "parallel_tool_calls": false,
  "status": "completed",
  "tool_choice": "none",
  "tools": [],
  "usage": {
    "input_tokens": 43,
    "input_tokens_details": {
      "cached_tokens": 0,
    },
    "output_tokens": 50,
    "output_tokens_details": {
      "reasoning_tokens": 0,
    },
    "total_tokens": 93,
  },
}
`;

exports[`responses → anthropic > systemMessageArrayContent > request 1`] = `
{
  "max_tokens": 300,
  "messages": [
    {
      "content": "What errors occurred recently?",
      "role": "user",
    },
  ],
  "model": "claude-sonnet-4-5-20250929",
  "system": "You are a helpful data analyst. The default data source is project_logs with id abc-123.",
}
`;

exports[`responses → anthropic > systemMessageArrayContent > response 1`] = `
{
  "created_at": 0,
  "id": "resp_transformed",
  "model": "claude-sonnet-4-20250514",
  "object": "response",
  "output": [
    {
      "content": [
        {
          "text": "I'll help you find recent errors from the project logs. Let me query the data to identify error occurrences.

\`\`\`sql
SELECT 
    timestamp,
    level,
    message,
    source,
    error_code
FROM project_logs 
WHERE level IN ('ERROR', 'CRITICAL', 'FATAL')
    AND timestamp >= CURRENT_TIMESTAMP - INTERVAL '24 hours'
ORDER BY timestamp DESC
LIMIT 20;
\`\`\`

However, I notice I don't have direct access to your actual database to execute this query. To help you effectively, I would need you to either:

1. **Run this query yourself** and share the results, or
2. **Provide sample log data** for me to analyze

The query above will show you:
- Recent errors from the last 24 hours
- The timestamp when each error occurred
- Error severity level
- Error messages and codes
- The source component that generated the error

Would you like me to modify the query for a different time range, or can you share the results so I can help analyze the error patterns?",
          "type": "output_text",
        },
      ],
      "role": "assistant",
      "status": "completed",
      "type": "message",
    },
  ],
  "output_text": "I'll help you find recent errors from the project logs. Let me query the data to identify error occurrences.

\`\`\`sql
SELECT 
    timestamp,
    level,
    message,
    source,
    error_code
FROM project_logs 
WHERE level IN ('ERROR', 'CRITICAL', 'FATAL')
    AND timestamp >= CURRENT_TIMESTAMP - INTERVAL '24 hours'
ORDER BY timestamp DESC
LIMIT 20;
\`\`\`

However, I notice I don't have direct access to your actual database to execute this query. To help you effectively, I would need you to either:

1. **Run this query yourself** and share the results, or
2. **Provide sample log data** for me to analyze

The query above will show you:
- Recent errors from the last 24 hours
- The timestamp when each error occurred
- Error severity level
- Error messages and codes
- The source component that generated the error

Would you like me to modify the query for a different time range, or can you share the results so I can help analyze the error patterns?",
  "parallel_tool_calls": false,
  "status": "completed",
  "tool_choice": "none",
  "tools": [],
  "usage": {
    "input_tokens": 33,
    "input_tokens_details": {
      "cached_tokens": 0,
    },
    "output_tokens": 246,
    "output_tokens_details": {
      "reasoning_tokens": 0,
    },
    "total_tokens": 279,
  },
}
`;

exports[`responses → anthropic > toolCallRequest > request 1`] = `
{
  "max_tokens": 4096,
  "messages": [
    {
      "content": "What's the weather like in San Francisco?",
      "role": "user",
    },
  ],
  "model": "claude-sonnet-4-5-20250929",
  "tool_choice": {
    "type": "auto",
  },
  "tools": [
    {
      "description": "Get the current weather for a location",
      "input_schema": {
        "properties": {
          "location": {
            "description": "The city and state, e.g. San Francisco, CA",
            "type": "string",
          },
        },
        "required": [
          "location",
        ],
        "type": "object",
      },
      "name": "get_weather",
      "strict": false,
    },
  ],
}
`;

exports[`responses → anthropic > toolCallRequest > response 1`] = `
{
  "created_at": 0,
  "id": "resp_transformed",
  "model": "claude-sonnet-4-20250514",
  "object": "response",
  "output": [
    {
      "content": [
        {
          "text": "I'll check the current weather in San Francisco for you.",
          "type": "output_text",
        },
      ],
      "role": "assistant",
      "status": "completed",
      "type": "message",
    },
    {
      "arguments": "{"location":"San Francisco, CA"}",
      "call_id": "toolu_01FZCXngG3VBF2g2vvnzsh3T",
      "name": "get_weather",
      "status": "completed",
      "type": "function_call",
    },
  ],
  "output_text": "I'll check the current weather in San Francisco for you.",
  "parallel_tool_calls": false,
  "status": "completed",
  "tool_choice": "none",
  "tools": [],
  "usage": {
    "input_tokens": 402,
    "input_tokens_details": {
      "cached_tokens": 0,
    },
    "output_tokens": 69,
    "output_tokens_details": {
      "reasoning_tokens": 0,
    },
    "total_tokens": 471,
  },
}
`;
