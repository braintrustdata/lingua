{
  "issues": [
    "universal(1->2): added: params.tools[0].parameters",
    "universal(1->2): changed: messages.length (1 -> 0)",
    "universal(1->2): changed: params.top_logprobs (404 -> null)",
    "universal(1->2): changed: params.parallel_tool_calls (true -> null)",
    "universal(1->2): changed: params.response_format.json_schema.description (\"s.v?p,A?\" -> null)",
    "universal(1->2): changed: params.response_format.json_schema.name (\"? h.,0\" -> \"response\")",
    "universal(1->2): changed: params.presence_penalty (70.77216767454881 -> null)",
    "universal(1->2): changed: params.frequency_penalty (97.86646963809422 -> null)",
    "universal(1->2): changed: params.logprobs (false -> null)",
    "universal(1->2): changed: params.store (true -> null)",
    "universal(1->2): changed: params.reasoning.canonical (\"effort\" -> \"budget_tokens\")",
    "anthropic(1->2): lost: system",
    "chat(final): lost: tool_choice",
    "chat(final): lost: frequency_penalty",
    "chat(final): lost: presence_penalty",
    "chat(final): lost: stream_options",
    "chat(final): lost: parallel_tool_calls",
    "chat(final): lost: logit_bias",
    "chat(final): lost: store",
    "chat(final): lost: top_logprobs",
    "chat(final): lost: logprobs",
    "chat(final): lost: max_tokens",
    "chat(final): lost: n",
    "chat(final): lost: modalities",
    "chat(final): lost: response_format.json_schema.description",
    "chat(final): added: max_completion_tokens",
    "chat(final): added: tools[0].function.parameters",
    "chat(final): changed: response_format.json_schema.name (\"? h.,0\" -> \"response\")",
    "chat(final): changed: messages.length (1 -> 0)",
    "chat(final): changed: reasoning_effort (\"minimal\" -> \"low\")"
  ],
  "kind": "chat-anthropic-two-arm",
  "provider": "chat-completions"
}
