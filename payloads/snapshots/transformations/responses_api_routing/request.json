{
  "model": "o1-pro",
  "max_tokens": 1024,
  "temperature": 0.5,
  "messages": [
    {
      "role": "user",
      "content": "Solve this complex problem"
    }
  ]
}

