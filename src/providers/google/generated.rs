// Generated Google AI types from official protobuf files
// Essential types for Elmir Google AI integration

// This file is @generated by prost-build.
/// A collection of source attributions for a piece of content.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct CitationMetadata {
    /// Citations to sources for a specific response.
    #[prost(message, repeated, tag = "1")]
    pub citation_sources: ::prost::alloc::vec::Vec<CitationSource>,
}
/// A citation to a source for a portion of a specific response.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct CitationSource {
    /// Optional. Start of segment of the response that is attributed to this
    /// source.
    ///
    /// Index indicates the start of the segment, measured in bytes.
    #[prost(int32, optional, tag = "1")]
    pub start_index: ::core::option::Option<i32>,
    /// Optional. End of the attributed segment, exclusive.
    #[prost(int32, optional, tag = "2")]
    pub end_index: ::core::option::Option<i32>,
    /// Optional. URI that is attributed as a source for a portion of the text.
    #[prost(string, optional, tag = "3")]
    pub uri: ::core::option::Option<::prost::alloc::string::String>,
    /// Optional. License for the GitHub project that is attributed as a source for
    /// segment.
    ///
    /// License info is required for code citations.
    #[prost(string, optional, tag = "4")]
    pub license: ::core::option::Option<::prost::alloc::string::String>,
}
/// The base structured datatype containing multi-part content of a message.
///
/// A `Content` includes a `role` field designating the producer of the `Content`
/// and a `parts` field containing multi-part data that contains the content of
/// the message turn.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct Content {
    /// Ordered `Parts` that constitute a single message. Parts may have different
    /// MIME types.
    #[prost(message, repeated, tag = "1")]
    pub parts: ::prost::alloc::vec::Vec<Part>,
    /// Optional. The producer of the content. Must be either 'user' or 'model'.
    ///
    /// Useful to set for multi-turn conversations, otherwise can be left blank
    /// or unset.
    #[prost(string, tag = "2")]
    pub role: ::prost::alloc::string::String,
}
/// A datatype containing media that is part of a multi-part `Content` message.
///
/// A `Part` consists of data which has an associated datatype. A `Part` can only
/// contain one of the accepted types in `Part.data`.
///
/// A `Part` must have a fixed IANA MIME type identifying the type and subtype
/// of the media if the `inline_data` field is filled with raw bytes.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct Part {
    /// Optional. Indicates if the part is thought from the model.
    #[prost(bool, tag = "11")]
    pub thought: bool,
    /// Optional. An opaque signature for the thought so it can be reused in
    /// subsequent requests.
    #[prost(bytes = "vec", tag = "13")]
    pub thought_signature: ::prost::alloc::vec::Vec<u8>,
    #[prost(oneof = "part::Data", tags = "2, 3, 4, 5, 6, 9, 10")]
    pub data: ::core::option::Option<part::Data>,
    /// Controls extra preprocessing of data.
    #[prost(oneof = "part::Metadata", tags = "14")]
    pub metadata: ::core::option::Option<part::Metadata>,
}
/// Nested message and enum types in `Part`.
pub mod part {
    #[derive(Clone, PartialEq, ::prost::Oneof)]
    pub enum Data {
        /// Inline text.
        #[prost(string, tag = "2")]
        Text(::prost::alloc::string::String),
        /// Inline media bytes.
        #[prost(message, tag = "3")]
        InlineData(super::Blob),
        /// A predicted `FunctionCall` returned from the model that contains
        /// a string representing the `FunctionDeclaration.name` with the
        /// arguments and their values.
        #[prost(message, tag = "4")]
        FunctionCall(super::FunctionCall),
        /// The result output of a `FunctionCall` that contains a string
        /// representing the `FunctionDeclaration.name` and a structured JSON
        /// object containing any output from the function is used as context to
        /// the model.
        #[prost(message, tag = "5")]
        FunctionResponse(super::FunctionResponse),
        /// URI based data.
        #[prost(message, tag = "6")]
        FileData(super::FileData),
        /// Code generated by the model that is meant to be executed.
        #[prost(message, tag = "9")]
        ExecutableCode(super::ExecutableCode),
        /// Result of executing the `ExecutableCode`.
        #[prost(message, tag = "10")]
        CodeExecutionResult(super::CodeExecutionResult),
    }
    /// Controls extra preprocessing of data.
    #[derive(Clone, PartialEq, ::prost::Oneof)]
    pub enum Metadata {
        /// Optional. Video metadata. The metadata should only be specified while the
        /// video data is presented in inline_data or file_data.
        #[prost(message, tag = "14")]
        VideoMetadata(super::VideoMetadata),
    }
}
/// Raw media bytes.
///
/// Text should not be sent as raw bytes, use the 'text' field.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct Blob {
    /// The IANA standard MIME type of the source data.
    /// Examples:
    ///    - image/png
    ///    - image/jpeg
    /// If an unsupported MIME type is provided, an error will be returned. For a
    /// complete list of supported types, see [Supported file
    /// formats](<https://ai.google.dev/gemini-api/docs/prompting_with_media#supported_file_formats>).
    #[prost(string, tag = "1")]
    pub mime_type: ::prost::alloc::string::String,
    /// Raw bytes for media formats.
    #[prost(bytes = "vec", tag = "2")]
    pub data: ::prost::alloc::vec::Vec<u8>,
}
/// URI based data.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct FileData {
    /// Optional. The IANA standard MIME type of the source data.
    #[prost(string, tag = "1")]
    pub mime_type: ::prost::alloc::string::String,
    /// Required. URI.
    #[prost(string, tag = "2")]
    pub file_uri: ::prost::alloc::string::String,
}
/// Metadata describes the input video content.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct VideoMetadata {
    /// Optional. The start offset of the video.
    #[prost(message, optional, tag = "1")]
    pub start_offset: ::core::option::Option<::prost_types::Duration>,
    /// Optional. The end offset of the video.
    #[prost(message, optional, tag = "2")]
    pub end_offset: ::core::option::Option<::prost_types::Duration>,
    /// Optional. The frame rate of the video sent to the model. If not specified,
    /// the default value will be 1.0. The fps range is (0.0, 24.0].
    #[prost(double, tag = "3")]
    pub fps: f64,
}
/// Code generated by the model that is meant to be executed, and the result
/// returned to the model.
///
/// Only generated when using the `CodeExecution` tool, in which the code will
/// be automatically executed, and a corresponding `CodeExecutionResult` will
/// also be generated.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ExecutableCode {
    /// Required. Programming language of the `code`.
    #[prost(enumeration = "executable_code::Language", tag = "1")]
    pub language: i32,
    /// Required. The code to be executed.
    #[prost(string, tag = "2")]
    pub code: ::prost::alloc::string::String,
}
/// Nested message and enum types in `ExecutableCode`.
pub mod executable_code {
    /// Supported programming languages for the generated code.
    #[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord, ::prost::Enumeration)]
    #[repr(i32)]
    pub enum Language {
        /// Unspecified language. This value should not be used.
        Unspecified = 0,
        /// Python >= 3.10, with numpy and simpy available.
        Python = 1,
    }
    impl Language {
        /// String value of the enum field names used in the ProtoBuf definition.
        ///
        /// The values are not transformed in any way and thus are considered stable
        /// (if the ProtoBuf definition does not change) and safe for programmatic use.
        pub fn as_str_name(&self) -> &'static str {
            match self {
                Self::Unspecified => "LANGUAGE_UNSPECIFIED",
                Self::Python => "PYTHON",
            }
        }
        /// Creates an enum from field names used in the ProtoBuf definition.
        pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
            match value {
                "LANGUAGE_UNSPECIFIED" => Some(Self::Unspecified),
                "PYTHON" => Some(Self::Python),
                _ => None,
            }
        }
    }
}
/// Result of executing the `ExecutableCode`.
///
/// Only generated when using the `CodeExecution`, and always follows a `part`
/// containing the `ExecutableCode`.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct CodeExecutionResult {
    /// Required. Outcome of the code execution.
    #[prost(enumeration = "code_execution_result::Outcome", tag = "1")]
    pub outcome: i32,
    /// Optional. Contains stdout when code execution is successful, stderr or
    /// other description otherwise.
    #[prost(string, tag = "2")]
    pub output: ::prost::alloc::string::String,
}
/// Nested message and enum types in `CodeExecutionResult`.
pub mod code_execution_result {
    /// Enumeration of possible outcomes of the code execution.
    #[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord, ::prost::Enumeration)]
    #[repr(i32)]
    pub enum Outcome {
        /// Unspecified status. This value should not be used.
        Unspecified = 0,
        /// Code execution completed successfully.
        Ok = 1,
        /// Code execution finished but with a failure. `stderr` should contain the
        /// reason.
        Failed = 2,
        /// Code execution ran for too long, and was cancelled. There may or may not
        /// be a partial output present.
        DeadlineExceeded = 3,
    }
    impl Outcome {
        /// String value of the enum field names used in the ProtoBuf definition.
        ///
        /// The values are not transformed in any way and thus are considered stable
        /// (if the ProtoBuf definition does not change) and safe for programmatic use.
        pub fn as_str_name(&self) -> &'static str {
            match self {
                Self::Unspecified => "OUTCOME_UNSPECIFIED",
                Self::Ok => "OUTCOME_OK",
                Self::Failed => "OUTCOME_FAILED",
                Self::DeadlineExceeded => "OUTCOME_DEADLINE_EXCEEDED",
            }
        }
        /// Creates an enum from field names used in the ProtoBuf definition.
        pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
            match value {
                "OUTCOME_UNSPECIFIED" => Some(Self::Unspecified),
                "OUTCOME_OK" => Some(Self::Ok),
                "OUTCOME_FAILED" => Some(Self::Failed),
                "OUTCOME_DEADLINE_EXCEEDED" => Some(Self::DeadlineExceeded),
                _ => None,
            }
        }
    }
}
/// Tool details that the model may use to generate response.
///
/// A `Tool` is a piece of code that enables the system to interact with
/// external systems to perform an action, or set of actions, outside of
/// knowledge and scope of the model.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct Tool {
    /// Optional. A list of `FunctionDeclarations` available to the model that can
    /// be used for function calling.
    ///
    /// The model or system does not execute the function. Instead the defined
    /// function may be returned as a
    /// [FunctionCall][google.ai.generativelanguage.v1beta.Part.function_call] with
    /// arguments to the client side for execution. The model may decide to call a
    /// subset of these functions by populating
    /// [FunctionCall][google.ai.generativelanguage.v1beta.Part.function_call] in
    /// the response. The next conversation turn may contain a
    /// [FunctionResponse][google.ai.generativelanguage.v1beta.Part.function_response]
    /// with the [Content.role][google.ai.generativelanguage.v1beta.Content.role]
    /// "function" generation context for the next model turn.
    #[prost(message, repeated, tag = "1")]
    pub function_declarations: ::prost::alloc::vec::Vec<FunctionDeclaration>,
    /// Optional. Retrieval tool that is powered by Google search.
    #[prost(message, optional, tag = "2")]
    pub google_search_retrieval: ::core::option::Option<GoogleSearchRetrieval>,
    /// Optional. Enables the model to execute code as part of generation.
    #[prost(message, optional, tag = "3")]
    pub code_execution: ::core::option::Option<CodeExecution>,
    /// Optional. GoogleSearch tool type.
    /// Tool to support Google Search in Model. Powered by Google.
    #[prost(message, optional, tag = "4")]
    pub google_search: ::core::option::Option<tool::GoogleSearch>,
    /// Optional. Tool to support URL context retrieval.
    #[prost(message, optional, tag = "8")]
    pub url_context: ::core::option::Option<UrlContext>,
}
/// Nested message and enum types in `Tool`.
pub mod tool {
    /// GoogleSearch tool type.
    /// Tool to support Google Search in Model. Powered by Google.
    #[derive(Clone, PartialEq, ::prost::Message)]
    pub struct GoogleSearch {
        /// Optional. Filter search results to a specific time range.
        /// If customers set a start time, they must set an end time (and vice
        /// versa).
        #[prost(message, optional, tag = "2")]
        pub time_range_filter: ::core::option::Option<TimeRangeFilter>,
    }

    /// Simple placeholder for TimeRangeFilter until google.type module is properly included
    #[derive(Clone, PartialEq, ::prost::Message)]
    pub struct TimeRangeFilter {
        #[prost(string, optional, tag = "1")]
        pub start_time: ::core::option::Option<::prost::alloc::string::String>,
        #[prost(string, optional, tag = "2")]
        pub end_time: ::core::option::Option<::prost::alloc::string::String>,
    }
}
/// Tool to support URL context retrieval.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct UrlContext {}
/// Tool to retrieve public web data for grounding, powered by Google.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct GoogleSearchRetrieval {
    /// Specifies the dynamic retrieval configuration for the given source.
    #[prost(message, optional, tag = "1")]
    pub dynamic_retrieval_config: ::core::option::Option<DynamicRetrievalConfig>,
}
/// Describes the options to customize dynamic retrieval.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct DynamicRetrievalConfig {
    /// The mode of the predictor to be used in dynamic retrieval.
    #[prost(enumeration = "dynamic_retrieval_config::Mode", tag = "1")]
    pub mode: i32,
    /// The threshold to be used in dynamic retrieval.
    /// If not set, a system default value is used.
    #[prost(float, optional, tag = "2")]
    pub dynamic_threshold: ::core::option::Option<f32>,
}
/// Nested message and enum types in `DynamicRetrievalConfig`.
pub mod dynamic_retrieval_config {
    /// The mode of the predictor to be used in dynamic retrieval.
    #[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord, ::prost::Enumeration)]
    #[repr(i32)]
    pub enum Mode {
        /// Always trigger retrieval.
        Unspecified = 0,
        /// Run retrieval only when system decides it is necessary.
        Dynamic = 1,
    }
    impl Mode {
        /// String value of the enum field names used in the ProtoBuf definition.
        ///
        /// The values are not transformed in any way and thus are considered stable
        /// (if the ProtoBuf definition does not change) and safe for programmatic use.
        pub fn as_str_name(&self) -> &'static str {
            match self {
                Self::Unspecified => "MODE_UNSPECIFIED",
                Self::Dynamic => "MODE_DYNAMIC",
            }
        }
        /// Creates an enum from field names used in the ProtoBuf definition.
        pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
            match value {
                "MODE_UNSPECIFIED" => Some(Self::Unspecified),
                "MODE_DYNAMIC" => Some(Self::Dynamic),
                _ => None,
            }
        }
    }
}
/// Tool that executes code generated by the model, and automatically returns
/// the result to the model.
///
/// See also `ExecutableCode` and `CodeExecutionResult` which are only generated
/// when using this tool.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct CodeExecution {}
/// The Tool configuration containing parameters for specifying `Tool` use
/// in the request.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ToolConfig {
    /// Optional. Function calling config.
    #[prost(message, optional, tag = "1")]
    pub function_calling_config: ::core::option::Option<FunctionCallingConfig>,
}
/// Configuration for specifying function calling behavior.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct FunctionCallingConfig {
    /// Optional. Specifies the mode in which function calling should execute. If
    /// unspecified, the default value will be set to AUTO.
    #[prost(enumeration = "function_calling_config::Mode", tag = "1")]
    pub mode: i32,
    /// Optional. A set of function names that, when provided, limits the functions
    /// the model will call.
    ///
    /// This should only be set when the Mode is ANY. Function names
    /// should match \[FunctionDeclaration.name\]. With mode set to ANY, model will
    /// predict a function call from the set of function names provided.
    #[prost(string, repeated, tag = "2")]
    pub allowed_function_names: ::prost::alloc::vec::Vec<::prost::alloc::string::String>,
}
/// Nested message and enum types in `FunctionCallingConfig`.
pub mod function_calling_config {
    /// Defines the execution behavior for function calling by defining the
    /// execution mode.
    #[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord, ::prost::Enumeration)]
    #[repr(i32)]
    pub enum Mode {
        /// Unspecified function calling mode. This value should not be used.
        Unspecified = 0,
        /// Default model behavior, model decides to predict either a function call
        /// or a natural language response.
        Auto = 1,
        /// Model is constrained to always predicting a function call only.
        /// If "allowed_function_names" are set, the predicted function call will be
        /// limited to any one of "allowed_function_names", else the predicted
        /// function call will be any one of the provided "function_declarations".
        Any = 2,
        /// Model will not predict any function call. Model behavior is same as when
        /// not passing any function declarations.
        None = 3,
        /// Model decides to predict either a function call
        /// or a natural language response, but will validate function calls with
        /// constrained decoding.
        Validated = 4,
    }
    impl Mode {
        /// String value of the enum field names used in the ProtoBuf definition.
        ///
        /// The values are not transformed in any way and thus are considered stable
        /// (if the ProtoBuf definition does not change) and safe for programmatic use.
        pub fn as_str_name(&self) -> &'static str {
            match self {
                Self::Unspecified => "MODE_UNSPECIFIED",
                Self::Auto => "AUTO",
                Self::Any => "ANY",
                Self::None => "NONE",
                Self::Validated => "VALIDATED",
            }
        }
        /// Creates an enum from field names used in the ProtoBuf definition.
        pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
            match value {
                "MODE_UNSPECIFIED" => Some(Self::Unspecified),
                "AUTO" => Some(Self::Auto),
                "ANY" => Some(Self::Any),
                "NONE" => Some(Self::None),
                "VALIDATED" => Some(Self::Validated),
                _ => None,
            }
        }
    }
}
/// Structured representation of a function declaration as defined by the
/// [OpenAPI 3.03 specification](<https://spec.openapis.org/oas/v3.0.3>). Included
/// in this declaration are the function name and parameters. This
/// FunctionDeclaration is a representation of a block of code that can be used
/// as a `Tool` by the model and executed by the client.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct FunctionDeclaration {
    /// Required. The name of the function.
    /// Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum
    /// length of 63.
    #[prost(string, tag = "1")]
    pub name: ::prost::alloc::string::String,
    /// Required. A brief description of the function.
    #[prost(string, tag = "2")]
    pub description: ::prost::alloc::string::String,
    /// Optional. Describes the parameters to this function. Reflects the Open
    /// API 3.03 Parameter Object string Key: the name of the parameter. Parameter
    /// names are case sensitive. Schema Value: the Schema defining the type used
    /// for the parameter.
    #[prost(message, optional, tag = "3")]
    pub parameters: ::core::option::Option<Schema>,
    /// Optional. Describes the parameters to the function in JSON Schema format.
    /// The schema must describe an object where the properties are the parameters
    /// to the function. For example:
    ///
    /// ```
    /// {
    ///    "type": "object",
    ///    "properties": {
    ///      "name": { "type": "string" },
    ///      "age": { "type": "integer" }
    ///    },
    ///    "additionalProperties": false,
    ///    "required": \["name", "age"\],
    ///    "propertyOrdering": \["name", "age"\]
    /// }
    /// ```
    ///
    /// This field is mutually exclusive with `parameters`.
    #[prost(message, optional, tag = "6")]
    pub parameters_json_schema: ::core::option::Option<::prost_types::Value>,
    /// Optional. Describes the output from this function in JSON Schema format.
    /// Reflects the Open API 3.03 Response Object. The Schema defines the type
    /// used for the response value of the function.
    #[prost(message, optional, tag = "4")]
    pub response: ::core::option::Option<Schema>,
    /// Optional. Describes the output from this function in JSON Schema format.
    /// The value specified by the schema is the response value of the function.
    ///
    /// This field is mutually exclusive with `response`.
    #[prost(message, optional, tag = "7")]
    pub response_json_schema: ::core::option::Option<::prost_types::Value>,
    /// Optional. Specifies the function Behavior.
    /// Currently only supported by the BidiGenerateContent method.
    #[prost(enumeration = "function_declaration::Behavior", tag = "5")]
    pub behavior: i32,
}
/// Nested message and enum types in `FunctionDeclaration`.
pub mod function_declaration {
    /// Defines the function behavior. Defaults to `BLOCKING`.
    #[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord, ::prost::Enumeration)]
    #[repr(i32)]
    pub enum Behavior {
        /// This value is unused.
        Unspecified = 0,
        /// If set, the system will wait to receive the function response before
        /// continuing the conversation.
        Blocking = 1,
        /// If set, the system will not wait to receive the function response.
        /// Instead, it will attempt to handle function responses as they become
        /// available while maintaining the conversation between the user and the
        /// model.
        NonBlocking = 2,
    }
    impl Behavior {
        /// String value of the enum field names used in the ProtoBuf definition.
        ///
        /// The values are not transformed in any way and thus are considered stable
        /// (if the ProtoBuf definition does not change) and safe for programmatic use.
        pub fn as_str_name(&self) -> &'static str {
            match self {
                Self::Unspecified => "UNSPECIFIED",
                Self::Blocking => "BLOCKING",
                Self::NonBlocking => "NON_BLOCKING",
            }
        }
        /// Creates an enum from field names used in the ProtoBuf definition.
        pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
            match value {
                "UNSPECIFIED" => Some(Self::Unspecified),
                "BLOCKING" => Some(Self::Blocking),
                "NON_BLOCKING" => Some(Self::NonBlocking),
                _ => None,
            }
        }
    }
}
/// A predicted `FunctionCall` returned from the model that contains
/// a string representing the `FunctionDeclaration.name` with the
/// arguments and their values.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct FunctionCall {
    /// Optional. The unique id of the function call. If populated, the client to
    /// execute the `function_call` and return the response with the matching `id`.
    #[prost(string, tag = "3")]
    pub id: ::prost::alloc::string::String,
    /// Required. The name of the function to call.
    /// Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum
    /// length of 63.
    #[prost(string, tag = "1")]
    pub name: ::prost::alloc::string::String,
    /// Optional. The function parameters and values in JSON object format.
    #[prost(message, optional, tag = "2")]
    pub args: ::core::option::Option<::prost_types::Struct>,
}
/// The result output from a `FunctionCall` that contains a string
/// representing the `FunctionDeclaration.name` and a structured JSON
/// object containing any output from the function is used as context to
/// the model. This should contain the result of a`FunctionCall` made
/// based on model prediction.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct FunctionResponse {
    /// Optional. The id of the function call this response is for. Populated by
    /// the client to match the corresponding function call `id`.
    #[prost(string, tag = "3")]
    pub id: ::prost::alloc::string::String,
    /// Required. The name of the function to call.
    /// Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum
    /// length of 63.
    #[prost(string, tag = "1")]
    pub name: ::prost::alloc::string::String,
    /// Required. The function response in JSON object format.
    #[prost(message, optional, tag = "2")]
    pub response: ::core::option::Option<::prost_types::Struct>,
    /// Optional. Signals that function call continues, and more responses will be
    /// returned, turning the function call into a generator.
    /// Is only applicable to NON_BLOCKING function calls, is ignored otherwise.
    /// If set to false, future responses will not be considered.
    /// It is allowed to return empty `response` with `will_continue=False` to
    /// signal that the function call is finished. This may still trigger the model
    /// generation. To avoid triggering the generation and finish the function
    /// call, additionally set `scheduling` to `SILENT`.
    #[prost(bool, tag = "4")]
    pub will_continue: bool,
    /// Optional. Specifies how the response should be scheduled in the
    /// conversation. Only applicable to NON_BLOCKING function calls, is ignored
    /// otherwise. Defaults to WHEN_IDLE.
    #[prost(enumeration = "function_response::Scheduling", optional, tag = "5")]
    pub scheduling: ::core::option::Option<i32>,
}
/// Nested message and enum types in `FunctionResponse`.
pub mod function_response {
    /// Specifies how the response should be scheduled in the conversation.
    #[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord, ::prost::Enumeration)]
    #[repr(i32)]
    pub enum Scheduling {
        /// This value is unused.
        Unspecified = 0,
        /// Only add the result to the conversation context, do not interrupt or
        /// trigger generation.
        Silent = 1,
        /// Add the result to the conversation context, and prompt to generate output
        /// without interrupting ongoing generation.
        WhenIdle = 2,
        /// Add the result to the conversation context, interrupt ongoing generation
        /// and prompt to generate output.
        Interrupt = 3,
    }
    impl Scheduling {
        /// String value of the enum field names used in the ProtoBuf definition.
        ///
        /// The values are not transformed in any way and thus are considered stable
        /// (if the ProtoBuf definition does not change) and safe for programmatic use.
        pub fn as_str_name(&self) -> &'static str {
            match self {
                Self::Unspecified => "SCHEDULING_UNSPECIFIED",
                Self::Silent => "SILENT",
                Self::WhenIdle => "WHEN_IDLE",
                Self::Interrupt => "INTERRUPT",
            }
        }
        /// Creates an enum from field names used in the ProtoBuf definition.
        pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
            match value {
                "SCHEDULING_UNSPECIFIED" => Some(Self::Unspecified),
                "SILENT" => Some(Self::Silent),
                "WHEN_IDLE" => Some(Self::WhenIdle),
                "INTERRUPT" => Some(Self::Interrupt),
                _ => None,
            }
        }
    }
}
/// The `Schema` object allows the definition of input and output data types.
/// These types can be objects, but also primitives and arrays.
/// Represents a select subset of an [OpenAPI 3.0 schema
/// object](<https://spec.openapis.org/oas/v3.0.3#schema>).
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct Schema {
    /// Required. Data type.
    #[prost(enumeration = "Type", tag = "1")]
    pub r#type: i32,
    /// Optional. The format of the data. This is used only for primitive
    /// datatypes. Supported formats:
    ///   for NUMBER type: float, double
    ///   for INTEGER type: int32, int64
    ///   for STRING type: enum, date-time
    #[prost(string, tag = "2")]
    pub format: ::prost::alloc::string::String,
    /// Optional. The title of the schema.
    #[prost(string, tag = "24")]
    pub title: ::prost::alloc::string::String,
    /// Optional. A brief description of the parameter. This could contain examples
    /// of use. Parameter description may be formatted as Markdown.
    #[prost(string, tag = "3")]
    pub description: ::prost::alloc::string::String,
    /// Optional. Indicates if the value may be null.
    #[prost(bool, tag = "4")]
    pub nullable: bool,
    /// Optional. Possible values of the element of Type.STRING with enum format.
    /// For example we can define an Enum Direction as :
    /// {type:STRING, format:enum, enum:\["EAST", NORTH", "SOUTH", "WEST"\]}
    #[prost(string, repeated, tag = "5")]
    pub r#enum: ::prost::alloc::vec::Vec<::prost::alloc::string::String>,
    /// Optional. Schema of the elements of Type.ARRAY.
    #[prost(message, optional, boxed, tag = "6")]
    pub items: ::core::option::Option<::prost::alloc::boxed::Box<Schema>>,
    /// Optional. Maximum number of the elements for Type.ARRAY.
    #[prost(int64, tag = "21")]
    pub max_items: i64,
    /// Optional. Minimum number of the elements for Type.ARRAY.
    #[prost(int64, tag = "22")]
    pub min_items: i64,
    /// Optional. Properties of Type.OBJECT.
    #[prost(map = "string, message", tag = "7")]
    pub properties: ::std::collections::HashMap<::prost::alloc::string::String, Schema>,
    /// Optional. Required properties of Type.OBJECT.
    #[prost(string, repeated, tag = "8")]
    pub required: ::prost::alloc::vec::Vec<::prost::alloc::string::String>,
    /// Optional. Minimum number of the properties for Type.OBJECT.
    #[prost(int64, tag = "9")]
    pub min_properties: i64,
    /// Optional. Maximum number of the properties for Type.OBJECT.
    #[prost(int64, tag = "10")]
    pub max_properties: i64,
    /// Optional. SCHEMA FIELDS FOR TYPE INTEGER and NUMBER
    /// Minimum value of the Type.INTEGER and Type.NUMBER
    #[prost(double, optional, tag = "11")]
    pub minimum: ::core::option::Option<f64>,
    /// Optional. Maximum value of the Type.INTEGER and Type.NUMBER
    #[prost(double, optional, tag = "12")]
    pub maximum: ::core::option::Option<f64>,
    /// Optional. SCHEMA FIELDS FOR TYPE STRING
    /// Minimum length of the Type.STRING
    #[prost(int64, tag = "13")]
    pub min_length: i64,
    /// Optional. Maximum length of the Type.STRING
    #[prost(int64, tag = "14")]
    pub max_length: i64,
    /// Optional. Pattern of the Type.STRING to restrict a string to a regular
    /// expression.
    #[prost(string, tag = "15")]
    pub pattern: ::prost::alloc::string::String,
    /// Optional. Example of the object. Will only populated when the object is the
    /// root.
    #[prost(message, optional, tag = "16")]
    pub example: ::core::option::Option<::prost_types::Value>,
    /// Optional. The value should be validated against any (one or more) of the
    /// subschemas in the list.
    #[prost(message, repeated, tag = "18")]
    pub any_of: ::prost::alloc::vec::Vec<Schema>,
    /// Optional. The order of the properties.
    /// Not a standard field in open api spec. Used to determine the order of the
    /// properties in the response.
    #[prost(string, repeated, tag = "23")]
    pub property_ordering: ::prost::alloc::vec::Vec<::prost::alloc::string::String>,
    /// Optional. Default value of the field. Per JSON Schema, this field is
    /// intended for documentation generators and doesn't affect validation. Thus
    /// it's included here and ignored so that developers who send schemas with a
    /// `default` field don't get unknown-field errors.
    #[prost(message, optional, tag = "25")]
    pub default: ::core::option::Option<::prost_types::Value>,
}
/// Passage included inline with a grounding configuration.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct GroundingPassage {
    /// Identifier for the passage for attributing this passage in grounded
    /// answers.
    #[prost(string, tag = "1")]
    pub id: ::prost::alloc::string::String,
    /// Content of the passage.
    #[prost(message, optional, tag = "2")]
    pub content: ::core::option::Option<Content>,
}
/// A repeated list of passages.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct GroundingPassages {
    /// List of passages.
    #[prost(message, repeated, tag = "1")]
    pub passages: ::prost::alloc::vec::Vec<GroundingPassage>,
}
/// Represents token counting info for a single modality.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ModalityTokenCount {
    /// The modality associated with this token count.
    #[prost(enumeration = "Modality", tag = "1")]
    pub modality: i32,
    /// Number of tokens.
    #[prost(int32, tag = "2")]
    pub token_count: i32,
}
/// Type contains the list of OpenAPI data types as defined by
/// <https://spec.openapis.org/oas/v3.0.3#data-types>
#[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord, ::prost::Enumeration)]
#[repr(i32)]
pub enum Type {
    /// Not specified, should not be used.
    Unspecified = 0,
    /// String type.
    String = 1,
    /// Number type.
    Number = 2,
    /// Integer type.
    Integer = 3,
    /// Boolean type.
    Boolean = 4,
    /// Array type.
    Array = 5,
    /// Object type.
    Object = 6,
    /// Null type.
    Null = 7,
}
impl Type {
    /// String value of the enum field names used in the ProtoBuf definition.
    ///
    /// The values are not transformed in any way and thus are considered stable
    /// (if the ProtoBuf definition does not change) and safe for programmatic use.
    pub fn as_str_name(&self) -> &'static str {
        match self {
            Self::Unspecified => "TYPE_UNSPECIFIED",
            Self::String => "STRING",
            Self::Number => "NUMBER",
            Self::Integer => "INTEGER",
            Self::Boolean => "BOOLEAN",
            Self::Array => "ARRAY",
            Self::Object => "OBJECT",
            Self::Null => "NULL",
        }
    }
    /// Creates an enum from field names used in the ProtoBuf definition.
    pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
        match value {
            "TYPE_UNSPECIFIED" => Some(Self::Unspecified),
            "STRING" => Some(Self::String),
            "NUMBER" => Some(Self::Number),
            "INTEGER" => Some(Self::Integer),
            "BOOLEAN" => Some(Self::Boolean),
            "ARRAY" => Some(Self::Array),
            "OBJECT" => Some(Self::Object),
            "NULL" => Some(Self::Null),
            _ => None,
        }
    }
}
/// Content Part modality
#[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord, ::prost::Enumeration)]
#[repr(i32)]
pub enum Modality {
    /// Unspecified modality.
    Unspecified = 0,
    /// Plain text.
    Text = 1,
    /// Image.
    Image = 2,
    /// Video.
    Video = 3,
    /// Audio.
    Audio = 4,
    /// Document, e.g. PDF.
    Document = 5,
}
impl Modality {
    /// String value of the enum field names used in the ProtoBuf definition.
    ///
    /// The values are not transformed in any way and thus are considered stable
    /// (if the ProtoBuf definition does not change) and safe for programmatic use.
    pub fn as_str_name(&self) -> &'static str {
        match self {
            Self::Unspecified => "MODALITY_UNSPECIFIED",
            Self::Text => "TEXT",
            Self::Image => "IMAGE",
            Self::Video => "VIDEO",
            Self::Audio => "AUDIO",
            Self::Document => "DOCUMENT",
        }
    }
    /// Creates an enum from field names used in the ProtoBuf definition.
    pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
        match value {
            "MODALITY_UNSPECIFIED" => Some(Self::Unspecified),
            "TEXT" => Some(Self::Text),
            "IMAGE" => Some(Self::Image),
            "VIDEO" => Some(Self::Video),
            "AUDIO" => Some(Self::Audio),
            "DOCUMENT" => Some(Self::Document),
            _ => None,
        }
    }
}
/// A `Corpus` is a collection of `Document`s.
/// A project can create up to 5 corpora.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct Corpus {
    /// Immutable. Identifier. The `Corpus` resource name. The ID (name excluding
    /// the "corpora/" prefix) can contain up to 40 characters that are lowercase
    /// alphanumeric or dashes
    /// (-). The ID cannot start or end with a dash. If the name is empty on
    /// create, a unique name will be derived from `display_name` along with a 12
    /// character random suffix.
    /// Example: `corpora/my-awesome-corpora-123a456b789c`
    #[prost(string, tag = "1")]
    pub name: ::prost::alloc::string::String,
    /// Optional. The human-readable display name for the `Corpus`. The display
    /// name must be no more than 512 characters in length, including spaces.
    /// Example: "Docs on Semantic Retriever"
    #[prost(string, tag = "2")]
    pub display_name: ::prost::alloc::string::String,
    /// Output only. The Timestamp of when the `Corpus` was created.
    #[prost(message, optional, tag = "3")]
    pub create_time: ::core::option::Option<::prost_types::Timestamp>,
    /// Output only. The Timestamp of when the `Corpus` was last updated.
    #[prost(message, optional, tag = "4")]
    pub update_time: ::core::option::Option<::prost_types::Timestamp>,
}
/// A `Document` is a collection of `Chunk`s.
/// A `Corpus` can have a maximum of 10,000 `Document`s.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct Document {
    /// Immutable. Identifier. The `Document` resource name. The ID (name excluding
    /// the "corpora/*/documents/" prefix) can contain up to 40 characters that are
    /// lowercase alphanumeric or dashes (-). The ID cannot start or end with a
    /// dash. If the name is empty on create, a unique name will be derived from
    /// `display_name` along with a 12 character random suffix.
    /// Example: `corpora/{corpus_id}/documents/my-awesome-doc-123a456b789c`
    #[prost(string, tag = "1")]
    pub name: ::prost::alloc::string::String,
    /// Optional. The human-readable display name for the `Document`. The display
    /// name must be no more than 512 characters in length, including spaces.
    /// Example: "Semantic Retriever Documentation"
    #[prost(string, tag = "2")]
    pub display_name: ::prost::alloc::string::String,
    /// Optional. User provided custom metadata stored as key-value pairs used for
    /// querying. A `Document` can have a maximum of 20 `CustomMetadata`.
    #[prost(message, repeated, tag = "3")]
    pub custom_metadata: ::prost::alloc::vec::Vec<CustomMetadata>,
    /// Output only. The Timestamp of when the `Document` was last updated.
    #[prost(message, optional, tag = "4")]
    pub update_time: ::core::option::Option<::prost_types::Timestamp>,
    /// Output only. The Timestamp of when the `Document` was created.
    #[prost(message, optional, tag = "5")]
    pub create_time: ::core::option::Option<::prost_types::Timestamp>,
}
/// User provided string values assigned to a single metadata key.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct StringList {
    /// The string values of the metadata to store.
    #[prost(string, repeated, tag = "1")]
    pub values: ::prost::alloc::vec::Vec<::prost::alloc::string::String>,
}
/// User provided metadata stored as key-value pairs.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct CustomMetadata {
    /// Required. The key of the metadata to store.
    #[prost(string, tag = "1")]
    pub key: ::prost::alloc::string::String,
    #[prost(oneof = "custom_metadata::Value", tags = "2, 6, 7")]
    pub value: ::core::option::Option<custom_metadata::Value>,
}
/// Nested message and enum types in `CustomMetadata`.
pub mod custom_metadata {
    #[derive(Clone, PartialEq, ::prost::Oneof)]
    pub enum Value {
        /// The string value of the metadata to store.
        #[prost(string, tag = "2")]
        StringValue(::prost::alloc::string::String),
        /// The StringList value of the metadata to store.
        #[prost(message, tag = "6")]
        StringListValue(super::StringList),
        /// The numeric value of the metadata to store.
        #[prost(float, tag = "7")]
        NumericValue(f32),
    }
}
/// User provided filter to limit retrieval based on `Chunk` or `Document` level
/// metadata values.
/// Example (genre = drama OR genre = action):
///    key = "document.custom_metadata.genre"
///    conditions = [{string_value = "drama", operation = EQUAL},
///                  {string_value = "action", operation = EQUAL}]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct MetadataFilter {
    /// Required. The key of the metadata to filter on.
    #[prost(string, tag = "1")]
    pub key: ::prost::alloc::string::String,
    /// Required. The `Condition`s for the given key that will trigger this filter.
    /// Multiple `Condition`s are joined by logical ORs.
    #[prost(message, repeated, tag = "2")]
    pub conditions: ::prost::alloc::vec::Vec<Condition>,
}
/// Filter condition applicable to a single key.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct Condition {
    /// Required. Operator applied to the given key-value pair to trigger the
    /// condition.
    #[prost(enumeration = "condition::Operator", tag = "5")]
    pub operation: i32,
    /// The value type must be consistent with the value type defined in the field
    /// for the corresponding key. If the value types are not consistent, the
    /// result will be an empty set. When the `CustomMetadata` has a `StringList`
    /// value type, the filtering condition should use `string_value` paired with
    /// an INCLUDES/EXCLUDES operation, otherwise the result will also be an empty
    /// set.
    #[prost(oneof = "condition::Value", tags = "1, 6")]
    pub value: ::core::option::Option<condition::Value>,
}
/// Nested message and enum types in `Condition`.
pub mod condition {
    /// Defines the valid operators that can be applied to a key-value pair.
    #[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord, ::prost::Enumeration)]
    #[repr(i32)]
    pub enum Operator {
        /// The default value. This value is unused.
        Unspecified = 0,
        /// Supported by numeric.
        Less = 1,
        /// Supported by numeric.
        LessEqual = 2,
        /// Supported by numeric & string.
        Equal = 3,
        /// Supported by numeric.
        GreaterEqual = 4,
        /// Supported by numeric.
        Greater = 5,
        /// Supported by numeric & string.
        NotEqual = 6,
        /// Supported by string only when `CustomMetadata` value type for the given
        /// key has a `string_list_value`.
        Includes = 7,
        /// Supported by string only when `CustomMetadata` value type for the given
        /// key has a `string_list_value`.
        Excludes = 8,
    }
    impl Operator {
        /// String value of the enum field names used in the ProtoBuf definition.
        ///
        /// The values are not transformed in any way and thus are considered stable
        /// (if the ProtoBuf definition does not change) and safe for programmatic use.
        pub fn as_str_name(&self) -> &'static str {
            match self {
                Self::Unspecified => "OPERATOR_UNSPECIFIED",
                Self::Less => "LESS",
                Self::LessEqual => "LESS_EQUAL",
                Self::Equal => "EQUAL",
                Self::GreaterEqual => "GREATER_EQUAL",
                Self::Greater => "GREATER",
                Self::NotEqual => "NOT_EQUAL",
                Self::Includes => "INCLUDES",
                Self::Excludes => "EXCLUDES",
            }
        }
        /// Creates an enum from field names used in the ProtoBuf definition.
        pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
            match value {
                "OPERATOR_UNSPECIFIED" => Some(Self::Unspecified),
                "LESS" => Some(Self::Less),
                "LESS_EQUAL" => Some(Self::LessEqual),
                "EQUAL" => Some(Self::Equal),
                "GREATER_EQUAL" => Some(Self::GreaterEqual),
                "GREATER" => Some(Self::Greater),
                "NOT_EQUAL" => Some(Self::NotEqual),
                "INCLUDES" => Some(Self::Includes),
                "EXCLUDES" => Some(Self::Excludes),
                _ => None,
            }
        }
    }
    /// The value type must be consistent with the value type defined in the field
    /// for the corresponding key. If the value types are not consistent, the
    /// result will be an empty set. When the `CustomMetadata` has a `StringList`
    /// value type, the filtering condition should use `string_value` paired with
    /// an INCLUDES/EXCLUDES operation, otherwise the result will also be an empty
    /// set.
    #[derive(Clone, PartialEq, ::prost::Oneof)]
    pub enum Value {
        /// The string value to filter the metadata on.
        #[prost(string, tag = "1")]
        StringValue(::prost::alloc::string::String),
        /// The numeric value to filter the metadata on.
        #[prost(float, tag = "6")]
        NumericValue(f32),
    }
}
/// A `Chunk` is a subpart of a `Document` that is treated as an independent unit
/// for the purposes of vector representation and storage.
/// A `Corpus` can have a maximum of 1 million `Chunk`s.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct Chunk {
    /// Immutable. Identifier. The `Chunk` resource name. The ID (name excluding
    /// the "corpora/*/documents/*/chunks/" prefix) can contain up to 40 characters
    /// that are lowercase alphanumeric or dashes (-). The ID cannot start or end
    /// with a dash. If the name is empty on create, a random 12-character unique
    /// ID will be generated.
    /// Example: `corpora/{corpus_id}/documents/{document_id}/chunks/123a456b789c`
    #[prost(string, tag = "1")]
    pub name: ::prost::alloc::string::String,
    /// Required. The content for the `Chunk`, such as the text string.
    /// The maximum number of tokens per chunk is 2043.
    #[prost(message, optional, tag = "2")]
    pub data: ::core::option::Option<ChunkData>,
    /// Optional. User provided custom metadata stored as key-value pairs.
    /// The maximum number of `CustomMetadata` per chunk is 20.
    #[prost(message, repeated, tag = "3")]
    pub custom_metadata: ::prost::alloc::vec::Vec<CustomMetadata>,
    /// Output only. The Timestamp of when the `Chunk` was created.
    #[prost(message, optional, tag = "4")]
    pub create_time: ::core::option::Option<::prost_types::Timestamp>,
    /// Output only. The Timestamp of when the `Chunk` was last updated.
    #[prost(message, optional, tag = "5")]
    pub update_time: ::core::option::Option<::prost_types::Timestamp>,
    /// Output only. Current state of the `Chunk`.
    #[prost(enumeration = "chunk::State", tag = "6")]
    pub state: i32,
}
/// Nested message and enum types in `Chunk`.
pub mod chunk {
    /// States for the lifecycle of a `Chunk`.
    #[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord, ::prost::Enumeration)]
    #[repr(i32)]
    pub enum State {
        /// The default value. This value is used if the state is omitted.
        Unspecified = 0,
        /// `Chunk` is being processed (embedding and vector storage).
        PendingProcessing = 1,
        /// `Chunk` is processed and available for querying.
        Active = 2,
        /// `Chunk` failed processing.
        Failed = 10,
    }
    impl State {
        /// String value of the enum field names used in the ProtoBuf definition.
        ///
        /// The values are not transformed in any way and thus are considered stable
        /// (if the ProtoBuf definition does not change) and safe for programmatic use.
        pub fn as_str_name(&self) -> &'static str {
            match self {
                Self::Unspecified => "STATE_UNSPECIFIED",
                Self::PendingProcessing => "STATE_PENDING_PROCESSING",
                Self::Active => "STATE_ACTIVE",
                Self::Failed => "STATE_FAILED",
            }
        }
        /// Creates an enum from field names used in the ProtoBuf definition.
        pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
            match value {
                "STATE_UNSPECIFIED" => Some(Self::Unspecified),
                "STATE_PENDING_PROCESSING" => Some(Self::PendingProcessing),
                "STATE_ACTIVE" => Some(Self::Active),
                "STATE_FAILED" => Some(Self::Failed),
                _ => None,
            }
        }
    }
}
/// Extracted data that represents the `Chunk` content.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ChunkData {
    #[prost(oneof = "chunk_data::Data", tags = "1")]
    pub data: ::core::option::Option<chunk_data::Data>,
}
/// Nested message and enum types in `ChunkData`.
pub mod chunk_data {
    #[derive(Clone, PartialEq, ::prost::Oneof)]
    pub enum Data {
        /// The `Chunk` content as a string.
        /// The maximum number of tokens per chunk is 2043.
        #[prost(string, tag = "1")]
        StringValue(::prost::alloc::string::String),
    }
}
/// Content filtering metadata associated with processing a single request.
///
/// ContentFilter contains a reason and an optional supporting string. The reason
/// may be unspecified.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ContentFilter {
    /// The reason content was blocked during request processing.
    #[prost(enumeration = "content_filter::BlockedReason", tag = "1")]
    pub reason: i32,
    /// A string that describes the filtering behavior in more detail.
    #[prost(string, optional, tag = "2")]
    pub message: ::core::option::Option<::prost::alloc::string::String>,
}
/// Nested message and enum types in `ContentFilter`.
pub mod content_filter {
    /// A list of reasons why content may have been blocked.
    #[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord, ::prost::Enumeration)]
    #[repr(i32)]
    pub enum BlockedReason {
        /// A blocked reason was not specified.
        Unspecified = 0,
        /// Content was blocked by safety settings.
        Safety = 1,
        /// Content was blocked, but the reason is uncategorized.
        Other = 2,
    }
    impl BlockedReason {
        /// String value of the enum field names used in the ProtoBuf definition.
        ///
        /// The values are not transformed in any way and thus are considered stable
        /// (if the ProtoBuf definition does not change) and safe for programmatic use.
        pub fn as_str_name(&self) -> &'static str {
            match self {
                Self::Unspecified => "BLOCKED_REASON_UNSPECIFIED",
                Self::Safety => "SAFETY",
                Self::Other => "OTHER",
            }
        }
        /// Creates an enum from field names used in the ProtoBuf definition.
        pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
            match value {
                "BLOCKED_REASON_UNSPECIFIED" => Some(Self::Unspecified),
                "SAFETY" => Some(Self::Safety),
                "OTHER" => Some(Self::Other),
                _ => None,
            }
        }
    }
}
/// Safety feedback for an entire request.
///
/// This field is populated if content in the input and/or response is blocked
/// due to safety settings. SafetyFeedback may not exist for every HarmCategory.
/// Each SafetyFeedback will return the safety settings used by the request as
/// well as the lowest HarmProbability that should be allowed in order to return
/// a result.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct SafetyFeedback {
    /// Safety rating evaluated from content.
    #[prost(message, optional, tag = "1")]
    pub rating: ::core::option::Option<SafetyRating>,
    /// Safety settings applied to the request.
    #[prost(message, optional, tag = "2")]
    pub setting: ::core::option::Option<SafetySetting>,
}
/// Safety rating for a piece of content.
///
/// The safety rating contains the category of harm and the
/// harm probability level in that category for a piece of content.
/// Content is classified for safety across a number of
/// harm categories and the probability of the harm classification is included
/// here.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct SafetyRating {
    /// Required. The category for this rating.
    #[prost(enumeration = "HarmCategory", tag = "3")]
    pub category: i32,
    /// Required. The probability of harm for this content.
    #[prost(enumeration = "safety_rating::HarmProbability", tag = "4")]
    pub probability: i32,
    /// Was this content blocked because of this rating?
    #[prost(bool, tag = "5")]
    pub blocked: bool,
}
/// Nested message and enum types in `SafetyRating`.
pub mod safety_rating {
    /// The probability that a piece of content is harmful.
    ///
    /// The classification system gives the probability of the content being
    /// unsafe. This does not indicate the severity of harm for a piece of content.
    #[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord, ::prost::Enumeration)]
    #[repr(i32)]
    pub enum HarmProbability {
        /// Probability is unspecified.
        Unspecified = 0,
        /// Content has a negligible chance of being unsafe.
        Negligible = 1,
        /// Content has a low chance of being unsafe.
        Low = 2,
        /// Content has a medium chance of being unsafe.
        Medium = 3,
        /// Content has a high chance of being unsafe.
        High = 4,
    }
    impl HarmProbability {
        /// String value of the enum field names used in the ProtoBuf definition.
        ///
        /// The values are not transformed in any way and thus are considered stable
        /// (if the ProtoBuf definition does not change) and safe for programmatic use.
        pub fn as_str_name(&self) -> &'static str {
            match self {
                Self::Unspecified => "HARM_PROBABILITY_UNSPECIFIED",
                Self::Negligible => "NEGLIGIBLE",
                Self::Low => "LOW",
                Self::Medium => "MEDIUM",
                Self::High => "HIGH",
            }
        }
        /// Creates an enum from field names used in the ProtoBuf definition.
        pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
            match value {
                "HARM_PROBABILITY_UNSPECIFIED" => Some(Self::Unspecified),
                "NEGLIGIBLE" => Some(Self::Negligible),
                "LOW" => Some(Self::Low),
                "MEDIUM" => Some(Self::Medium),
                "HIGH" => Some(Self::High),
                _ => None,
            }
        }
    }
}
/// Safety setting, affecting the safety-blocking behavior.
///
/// Passing a safety setting for a category changes the allowed probability that
/// content is blocked.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct SafetySetting {
    /// Required. The category for this setting.
    #[prost(enumeration = "HarmCategory", tag = "3")]
    pub category: i32,
    /// Required. Controls the probability threshold at which harm is blocked.
    #[prost(enumeration = "safety_setting::HarmBlockThreshold", tag = "4")]
    pub threshold: i32,
}
/// Nested message and enum types in `SafetySetting`.
pub mod safety_setting {
    /// Block at and beyond a specified harm probability.
    #[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord, ::prost::Enumeration)]
    #[repr(i32)]
    pub enum HarmBlockThreshold {
        /// Threshold is unspecified.
        Unspecified = 0,
        /// Content with NEGLIGIBLE will be allowed.
        BlockLowAndAbove = 1,
        /// Content with NEGLIGIBLE and LOW will be allowed.
        BlockMediumAndAbove = 2,
        /// Content with NEGLIGIBLE, LOW, and MEDIUM will be allowed.
        BlockOnlyHigh = 3,
        /// All content will be allowed.
        BlockNone = 4,
        /// Turn off the safety filter.
        Off = 5,
    }
    impl HarmBlockThreshold {
        /// String value of the enum field names used in the ProtoBuf definition.
        ///
        /// The values are not transformed in any way and thus are considered stable
        /// (if the ProtoBuf definition does not change) and safe for programmatic use.
        pub fn as_str_name(&self) -> &'static str {
            match self {
                Self::Unspecified => "HARM_BLOCK_THRESHOLD_UNSPECIFIED",
                Self::BlockLowAndAbove => "BLOCK_LOW_AND_ABOVE",
                Self::BlockMediumAndAbove => "BLOCK_MEDIUM_AND_ABOVE",
                Self::BlockOnlyHigh => "BLOCK_ONLY_HIGH",
                Self::BlockNone => "BLOCK_NONE",
                Self::Off => "OFF",
            }
        }
        /// Creates an enum from field names used in the ProtoBuf definition.
        pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
            match value {
                "HARM_BLOCK_THRESHOLD_UNSPECIFIED" => Some(Self::Unspecified),
                "BLOCK_LOW_AND_ABOVE" => Some(Self::BlockLowAndAbove),
                "BLOCK_MEDIUM_AND_ABOVE" => Some(Self::BlockMediumAndAbove),
                "BLOCK_ONLY_HIGH" => Some(Self::BlockOnlyHigh),
                "BLOCK_NONE" => Some(Self::BlockNone),
                "OFF" => Some(Self::Off),
                _ => None,
            }
        }
    }
}
/// The category of a rating.
///
/// These categories cover various kinds of harms that developers
/// may wish to adjust.
#[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord, ::prost::Enumeration)]
#[repr(i32)]
pub enum HarmCategory {
    /// Category is unspecified.
    Unspecified = 0,
    /// **PaLM** - Negative or harmful comments targeting identity and/or protected
    /// attribute.
    Derogatory = 1,
    /// **PaLM** - Content that is rude, disrespectful, or profane.
    Toxicity = 2,
    /// **PaLM** - Describes scenarios depicting violence against an individual or
    /// group, or general descriptions of gore.
    Violence = 3,
    /// **PaLM** - Contains references to sexual acts or other lewd content.
    Sexual = 4,
    /// **PaLM** - Promotes unchecked medical advice.
    Medical = 5,
    /// **PaLM** - Dangerous content that promotes, facilitates, or encourages
    /// harmful acts.
    Dangerous = 6,
    /// **Gemini** - Harassment content.
    Harassment = 7,
    /// **Gemini** - Hate speech and content.
    HateSpeech = 8,
    /// **Gemini** - Sexually explicit content.
    SexuallyExplicit = 9,
    /// **Gemini** - Dangerous content.
    DangerousContent = 10,
    /// **Gemini** - Content that may be used to harm civic integrity.
    CivicIntegrity = 11,
}
impl HarmCategory {
    /// String value of the enum field names used in the ProtoBuf definition.
    ///
    /// The values are not transformed in any way and thus are considered stable
    /// (if the ProtoBuf definition does not change) and safe for programmatic use.
    pub fn as_str_name(&self) -> &'static str {
        match self {
            Self::Unspecified => "HARM_CATEGORY_UNSPECIFIED",
            Self::Derogatory => "HARM_CATEGORY_DEROGATORY",
            Self::Toxicity => "HARM_CATEGORY_TOXICITY",
            Self::Violence => "HARM_CATEGORY_VIOLENCE",
            Self::Sexual => "HARM_CATEGORY_SEXUAL",
            Self::Medical => "HARM_CATEGORY_MEDICAL",
            Self::Dangerous => "HARM_CATEGORY_DANGEROUS",
            Self::Harassment => "HARM_CATEGORY_HARASSMENT",
            Self::HateSpeech => "HARM_CATEGORY_HATE_SPEECH",
            Self::SexuallyExplicit => "HARM_CATEGORY_SEXUALLY_EXPLICIT",
            Self::DangerousContent => "HARM_CATEGORY_DANGEROUS_CONTENT",
            Self::CivicIntegrity => "HARM_CATEGORY_CIVIC_INTEGRITY",
        }
    }
    /// Creates an enum from field names used in the ProtoBuf definition.
    pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
        match value {
            "HARM_CATEGORY_UNSPECIFIED" => Some(Self::Unspecified),
            "HARM_CATEGORY_DEROGATORY" => Some(Self::Derogatory),
            "HARM_CATEGORY_TOXICITY" => Some(Self::Toxicity),
            "HARM_CATEGORY_VIOLENCE" => Some(Self::Violence),
            "HARM_CATEGORY_SEXUAL" => Some(Self::Sexual),
            "HARM_CATEGORY_MEDICAL" => Some(Self::Medical),
            "HARM_CATEGORY_DANGEROUS" => Some(Self::Dangerous),
            "HARM_CATEGORY_HARASSMENT" => Some(Self::Harassment),
            "HARM_CATEGORY_HATE_SPEECH" => Some(Self::HateSpeech),
            "HARM_CATEGORY_SEXUALLY_EXPLICIT" => Some(Self::SexuallyExplicit),
            "HARM_CATEGORY_DANGEROUS_CONTENT" => Some(Self::DangerousContent),
            "HARM_CATEGORY_CIVIC_INTEGRITY" => Some(Self::CivicIntegrity),
            _ => None,
        }
    }
}
/// Request to generate a completion from the model.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct GenerateContentRequest {
    /// Required. The name of the `Model` to use for generating the completion.
    ///
    /// Format: `models/{model}`.
    #[prost(string, tag = "1")]
    pub model: ::prost::alloc::string::String,
    /// Optional. Developer set [system
    /// instruction(s)](<https://ai.google.dev/gemini-api/docs/system-instructions>).
    /// Currently, text only.
    #[prost(message, optional, tag = "8")]
    pub system_instruction: ::core::option::Option<Content>,
    /// Required. The content of the current conversation with the model.
    ///
    /// For single-turn queries, this is a single instance. For multi-turn queries
    /// like [chat](<https://ai.google.dev/gemini-api/docs/text-generation#chat>),
    /// this is a repeated field that contains the conversation history and the
    /// latest request.
    #[prost(message, repeated, tag = "2")]
    pub contents: ::prost::alloc::vec::Vec<Content>,
    /// Optional. A list of `Tools` the `Model` may use to generate the next
    /// response.
    ///
    /// A `Tool` is a piece of code that enables the system to interact with
    /// external systems to perform an action, or set of actions, outside of
    /// knowledge and scope of the `Model`. Supported `Tool`s are `Function` and
    /// `code_execution`. Refer to the [Function
    /// calling](<https://ai.google.dev/gemini-api/docs/function-calling>) and the
    /// [Code execution](<https://ai.google.dev/gemini-api/docs/code-execution>)
    /// guides to learn more.
    #[prost(message, repeated, tag = "5")]
    pub tools: ::prost::alloc::vec::Vec<Tool>,
    /// Optional. Tool configuration for any `Tool` specified in the request. Refer
    /// to the [Function calling
    /// guide](<https://ai.google.dev/gemini-api/docs/function-calling#function_calling_mode>)
    /// for a usage example.
    #[prost(message, optional, tag = "7")]
    pub tool_config: ::core::option::Option<ToolConfig>,
    /// Optional. A list of unique `SafetySetting` instances for blocking unsafe
    /// content.
    ///
    /// This will be enforced on the `GenerateContentRequest.contents` and
    /// `GenerateContentResponse.candidates`. There should not be more than one
    /// setting for each `SafetyCategory` type. The API will block any contents and
    /// responses that fail to meet the thresholds set by these settings. This list
    /// overrides the default settings for each `SafetyCategory` specified in the
    /// safety_settings. If there is no `SafetySetting` for a given
    /// `SafetyCategory` provided in the list, the API will use the default safety
    /// setting for that category. Harm categories HARM_CATEGORY_HATE_SPEECH,
    /// HARM_CATEGORY_SEXUALLY_EXPLICIT, HARM_CATEGORY_DANGEROUS_CONTENT,
    /// HARM_CATEGORY_HARASSMENT, HARM_CATEGORY_CIVIC_INTEGRITY are supported.
    /// Refer to the [guide](<https://ai.google.dev/gemini-api/docs/safety-settings>)
    /// for detailed information on available safety settings. Also refer to the
    /// [Safety guidance](<https://ai.google.dev/gemini-api/docs/safety-guidance>) to
    /// learn how to incorporate safety considerations in your AI applications.
    #[prost(message, repeated, tag = "3")]
    pub safety_settings: ::prost::alloc::vec::Vec<SafetySetting>,
    /// Optional. Configuration options for model generation and outputs.
    #[prost(message, optional, tag = "4")]
    pub generation_config: ::core::option::Option<GenerationConfig>,
    /// Optional. The name of the content
    /// [cached](<https://ai.google.dev/gemini-api/docs/caching>) to use as context
    /// to serve the prediction. Format: `cachedContents/{cachedContent}`
    #[prost(string, optional, tag = "9")]
    pub cached_content: ::core::option::Option<::prost::alloc::string::String>,
}
/// The configuration for the prebuilt speaker to use.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct PrebuiltVoiceConfig {
    /// The name of the preset voice to use.
    #[prost(string, optional, tag = "1")]
    pub voice_name: ::core::option::Option<::prost::alloc::string::String>,
}
/// The configuration for the voice to use.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct VoiceConfig {
    /// The configuration for the speaker to use.
    #[prost(oneof = "voice_config::VoiceConfig", tags = "1")]
    pub voice_config: ::core::option::Option<voice_config::VoiceConfig>,
}
/// Nested message and enum types in `VoiceConfig`.
pub mod voice_config {
    /// The configuration for the speaker to use.
    #[derive(Clone, PartialEq, ::prost::Oneof)]
    pub enum VoiceConfig {
        /// The configuration for the prebuilt voice to use.
        #[prost(message, tag = "1")]
        PrebuiltVoiceConfig(super::PrebuiltVoiceConfig),
    }
}
/// The configuration for a single speaker in a multi speaker setup.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct SpeakerVoiceConfig {
    /// Required. The name of the speaker to use. Should be the same as in the
    /// prompt.
    #[prost(string, tag = "1")]
    pub speaker: ::prost::alloc::string::String,
    /// Required. The configuration for the voice to use.
    #[prost(message, optional, tag = "2")]
    pub voice_config: ::core::option::Option<VoiceConfig>,
}
/// The configuration for the multi-speaker setup.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct MultiSpeakerVoiceConfig {
    /// Required. All the enabled speaker voices.
    #[prost(message, repeated, tag = "2")]
    pub speaker_voice_configs: ::prost::alloc::vec::Vec<SpeakerVoiceConfig>,
}
/// The speech generation config.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct SpeechConfig {
    /// The configuration in case of single-voice output.
    #[prost(message, optional, tag = "1")]
    pub voice_config: ::core::option::Option<VoiceConfig>,
    /// Optional. The configuration for the multi-speaker setup.
    /// It is mutually exclusive with the voice_config field.
    #[prost(message, optional, tag = "3")]
    pub multi_speaker_voice_config: ::core::option::Option<MultiSpeakerVoiceConfig>,
    /// Optional. Language code (in BCP 47 format, e.g. "en-US") for speech
    /// synthesis.
    ///
    /// Valid values are: de-DE, en-AU, en-GB, en-IN, en-US, es-US, fr-FR, hi-IN,
    /// pt-BR, ar-XA, es-ES, fr-CA, id-ID, it-IT, ja-JP, tr-TR, vi-VN, bn-IN,
    /// gu-IN, kn-IN, ml-IN, mr-IN, ta-IN, te-IN, nl-NL, ko-KR, cmn-CN, pl-PL,
    /// ru-RU, and th-TH.
    #[prost(string, tag = "2")]
    pub language_code: ::prost::alloc::string::String,
}
/// Config for thinking features.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ThinkingConfig {
    /// Indicates whether to include thoughts in the response.
    /// If true, thoughts are returned only when available.
    #[prost(bool, optional, tag = "1")]
    pub include_thoughts: ::core::option::Option<bool>,
    /// The number of thoughts tokens that the model should generate.
    #[prost(int32, optional, tag = "2")]
    pub thinking_budget: ::core::option::Option<i32>,
}
/// Configuration options for model generation and outputs. Not all parameters
/// are configurable for every model.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct GenerationConfig {
    /// Optional. Number of generated responses to return. If unset, this will
    /// default to 1. Please note that this doesn't work for previous generation
    /// models (Gemini 1.0 family)
    #[prost(int32, optional, tag = "1")]
    pub candidate_count: ::core::option::Option<i32>,
    /// Optional. The set of character sequences (up to 5) that will stop output
    /// generation. If specified, the API will stop at the first appearance of a
    /// `stop_sequence`. The stop sequence will not be included as part of the
    /// response.
    #[prost(string, repeated, tag = "2")]
    pub stop_sequences: ::prost::alloc::vec::Vec<::prost::alloc::string::String>,
    /// Optional. The maximum number of tokens to include in a response candidate.
    ///
    /// Note: The default value varies by model, see the `Model.output_token_limit`
    /// attribute of the `Model` returned from the `getModel` function.
    #[prost(int32, optional, tag = "4")]
    pub max_output_tokens: ::core::option::Option<i32>,
    /// Optional. Controls the randomness of the output.
    ///
    /// Note: The default value varies by model, see the `Model.temperature`
    /// attribute of the `Model` returned from the `getModel` function.
    ///
    /// Values can range from \[0.0, 2.0\].
    #[prost(float, optional, tag = "5")]
    pub temperature: ::core::option::Option<f32>,
    /// Optional. The maximum cumulative probability of tokens to consider when
    /// sampling.
    ///
    /// The model uses combined Top-k and Top-p (nucleus) sampling.
    ///
    /// Tokens are sorted based on their assigned probabilities so that only the
    /// most likely tokens are considered. Top-k sampling directly limits the
    /// maximum number of tokens to consider, while Nucleus sampling limits the
    /// number of tokens based on the cumulative probability.
    ///
    /// Note: The default value varies by `Model` and is specified by
    /// the`Model.top_p` attribute returned from the `getModel` function. An empty
    /// `top_k` attribute indicates that the model doesn't apply top-k sampling
    /// and doesn't allow setting `top_k` on requests.
    #[prost(float, optional, tag = "6")]
    pub top_p: ::core::option::Option<f32>,
    /// Optional. The maximum number of tokens to consider when sampling.
    ///
    /// Gemini models use Top-p (nucleus) sampling or a combination of Top-k and
    /// nucleus sampling. Top-k sampling considers the set of `top_k` most probable
    /// tokens. Models running with nucleus sampling don't allow top_k setting.
    ///
    /// Note: The default value varies by `Model` and is specified by
    /// the`Model.top_p` attribute returned from the `getModel` function. An empty
    /// `top_k` attribute indicates that the model doesn't apply top-k sampling
    /// and doesn't allow setting `top_k` on requests.
    #[prost(int32, optional, tag = "7")]
    pub top_k: ::core::option::Option<i32>,
    /// Optional. Seed used in decoding. If not set, the request uses a randomly
    /// generated seed.
    #[prost(int32, optional, tag = "8")]
    pub seed: ::core::option::Option<i32>,
    /// Optional. MIME type of the generated candidate text.
    /// Supported MIME types are:
    /// `text/plain`: (default) Text output.
    /// `application/json`: JSON response in the response candidates.
    /// `text/x.enum`: ENUM as a string response in the response candidates.
    /// Refer to the
    /// [docs](<https://ai.google.dev/gemini-api/docs/prompting_with_media#plain_text_formats>)
    /// for a list of all supported text MIME types.
    #[prost(string, tag = "13")]
    pub response_mime_type: ::prost::alloc::string::String,
    /// Optional. Output schema of the generated candidate text. Schemas must be a
    /// subset of the [OpenAPI schema](<https://spec.openapis.org/oas/v3.0.3#schema>)
    /// and can be objects, primitives or arrays.
    ///
    /// If set, a compatible `response_mime_type` must also be set.
    /// Compatible MIME types:
    /// `application/json`: Schema for JSON response.
    /// Refer to the [JSON text generation
    /// guide](<https://ai.google.dev/gemini-api/docs/json-mode>) for more details.
    #[prost(message, optional, tag = "14")]
    pub response_schema: ::core::option::Option<Schema>,
    /// Optional. Output schema of the generated response. This is an alternative
    /// to `response_schema` that accepts [JSON Schema](<https://json-schema.org/>).
    ///
    /// If set, `response_schema` must be omitted, but `response_mime_type` is
    /// required.
    ///
    /// While the full JSON Schema may be sent, not all features are supported.
    /// Specifically, only the following properties are supported:
    ///
    /// - `$id`
    /// - `$defs`
    /// - `$ref`
    /// - `$anchor`
    /// - `type`
    /// - `format`
    /// - `title`
    /// - `description`
    /// - `enum` (for strings and numbers)
    /// - `items`
    /// - `prefixItems`
    /// - `minItems`
    /// - `maxItems`
    /// - `minimum`
    /// - `maximum`
    /// - `anyOf`
    /// - `oneOf` (interpreted the same as `anyOf`)
    /// - `properties`
    /// - `additionalProperties`
    /// - `required`
    ///
    /// The non-standard `propertyOrdering` property may also be set.
    ///
    /// Cyclic references are unrolled to a limited degree and, as such, may only
    /// be used within non-required properties. (Nullable properties are not
    /// sufficient.) If `$ref` is set on a sub-schema, no other properties, except
    /// for than those starting as a `$`, may be set.
    #[prost(message, optional, tag = "24")]
    pub response_json_schema: ::core::option::Option<::prost_types::Value>,
    /// Optional. Presence penalty applied to the next token's logprobs if the
    /// token has already been seen in the response.
    ///
    /// This penalty is binary on/off and not dependant on the number of times the
    /// token is used (after the first). Use
    /// [frequency_penalty][google.ai.generativelanguage.v1beta.GenerationConfig.frequency_penalty]
    /// for a penalty that increases with each use.
    ///
    /// A positive penalty will discourage the use of tokens that have already
    /// been used in the response, increasing the vocabulary.
    ///
    /// A negative penalty will encourage the use of tokens that have already been
    /// used in the response, decreasing the vocabulary.
    #[prost(float, optional, tag = "15")]
    pub presence_penalty: ::core::option::Option<f32>,
    /// Optional. Frequency penalty applied to the next token's logprobs,
    /// multiplied by the number of times each token has been seen in the respponse
    /// so far.
    ///
    /// A positive penalty will discourage the use of tokens that have already
    /// been used, proportional to the number of times the token has been used:
    /// The more a token is used, the more difficult it is for the model to use
    /// that token again increasing the vocabulary of responses.
    ///
    /// Caution: A _negative_ penalty will encourage the model to reuse tokens
    /// proportional to the number of times the token has been used. Small
    /// negative values will reduce the vocabulary of a response. Larger negative
    /// values will cause the model to start repeating a common token  until it
    /// hits the
    /// [max_output_tokens][google.ai.generativelanguage.v1beta.GenerationConfig.max_output_tokens]
    /// limit.
    #[prost(float, optional, tag = "16")]
    pub frequency_penalty: ::core::option::Option<f32>,
    /// Optional. If true, export the logprobs results in response.
    #[prost(bool, optional, tag = "17")]
    pub response_logprobs: ::core::option::Option<bool>,
    /// Optional. Only valid if
    /// [response_logprobs=True][google.ai.generativelanguage.v1beta.GenerationConfig.response_logprobs].
    /// This sets the number of top logprobs to return at each decoding step in the
    /// [Candidate.logprobs_result][google.ai.generativelanguage.v1beta.Candidate.logprobs_result].
    #[prost(int32, optional, tag = "18")]
    pub logprobs: ::core::option::Option<i32>,
    /// Optional. Enables enhanced civic answers. It may not be available for all
    /// models.
    #[prost(bool, optional, tag = "19")]
    pub enable_enhanced_civic_answers: ::core::option::Option<bool>,
    /// Optional. The requested modalities of the response. Represents the set of
    /// modalities that the model can return, and should be expected in the
    /// response. This is an exact match to the modalities of the response.
    ///
    /// A model may have multiple combinations of supported modalities. If the
    /// requested modalities do not match any of the supported combinations, an
    /// error will be returned.
    ///
    /// An empty list is equivalent to requesting only text.
    #[prost(
        enumeration = "generation_config::Modality",
        repeated,
        packed = "false",
        tag = "20"
    )]
    pub response_modalities: ::prost::alloc::vec::Vec<i32>,
    /// Optional. The speech generation config.
    #[prost(message, optional, tag = "21")]
    pub speech_config: ::core::option::Option<SpeechConfig>,
    /// Optional. Config for thinking features.
    /// An error will be returned if this field is set for models that don't
    /// support thinking.
    #[prost(message, optional, tag = "22")]
    pub thinking_config: ::core::option::Option<ThinkingConfig>,
    /// Optional. If specified, the media resolution specified will be used.
    #[prost(
        enumeration = "generation_config::MediaResolution",
        optional,
        tag = "23"
    )]
    pub media_resolution: ::core::option::Option<i32>,
}
/// Nested message and enum types in `GenerationConfig`.
pub mod generation_config {
    /// Supported modalities of the response.
    #[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord, ::prost::Enumeration)]
    #[repr(i32)]
    pub enum Modality {
        /// Default value.
        Unspecified = 0,
        /// Indicates the model should return text.
        Text = 1,
        /// Indicates the model should return images.
        Image = 2,
        /// Indicates the model should return audio.
        Audio = 3,
    }
    impl Modality {
        /// String value of the enum field names used in the ProtoBuf definition.
        ///
        /// The values are not transformed in any way and thus are considered stable
        /// (if the ProtoBuf definition does not change) and safe for programmatic use.
        pub fn as_str_name(&self) -> &'static str {
            match self {
                Self::Unspecified => "MODALITY_UNSPECIFIED",
                Self::Text => "TEXT",
                Self::Image => "IMAGE",
                Self::Audio => "AUDIO",
            }
        }
        /// Creates an enum from field names used in the ProtoBuf definition.
        pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
            match value {
                "MODALITY_UNSPECIFIED" => Some(Self::Unspecified),
                "TEXT" => Some(Self::Text),
                "IMAGE" => Some(Self::Image),
                "AUDIO" => Some(Self::Audio),
                _ => None,
            }
        }
    }
    /// Media resolution for the input media.
    #[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord, ::prost::Enumeration)]
    #[repr(i32)]
    pub enum MediaResolution {
        /// Media resolution has not been set.
        Unspecified = 0,
        /// Media resolution set to low (64 tokens).
        Low = 1,
        /// Media resolution set to medium (256 tokens).
        Medium = 2,
        /// Media resolution set to high (zoomed reframing with 256 tokens).
        High = 3,
    }
    impl MediaResolution {
        /// String value of the enum field names used in the ProtoBuf definition.
        ///
        /// The values are not transformed in any way and thus are considered stable
        /// (if the ProtoBuf definition does not change) and safe for programmatic use.
        pub fn as_str_name(&self) -> &'static str {
            match self {
                Self::Unspecified => "MEDIA_RESOLUTION_UNSPECIFIED",
                Self::Low => "MEDIA_RESOLUTION_LOW",
                Self::Medium => "MEDIA_RESOLUTION_MEDIUM",
                Self::High => "MEDIA_RESOLUTION_HIGH",
            }
        }
        /// Creates an enum from field names used in the ProtoBuf definition.
        pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
            match value {
                "MEDIA_RESOLUTION_UNSPECIFIED" => Some(Self::Unspecified),
                "MEDIA_RESOLUTION_LOW" => Some(Self::Low),
                "MEDIA_RESOLUTION_MEDIUM" => Some(Self::Medium),
                "MEDIA_RESOLUTION_HIGH" => Some(Self::High),
                _ => None,
            }
        }
    }
}
/// Configuration for retrieving grounding content from a `Corpus` or
/// `Document` created using the Semantic Retriever API.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct SemanticRetrieverConfig {
    /// Required. Name of the resource for retrieval. Example: `corpora/123` or
    /// `corpora/123/documents/abc`.
    #[prost(string, tag = "1")]
    pub source: ::prost::alloc::string::String,
    /// Required. Query to use for matching `Chunk`s in the given resource by
    /// similarity.
    #[prost(message, optional, tag = "2")]
    pub query: ::core::option::Option<Content>,
    /// Optional. Filters for selecting `Document`s and/or `Chunk`s from the
    /// resource.
    #[prost(message, repeated, tag = "3")]
    pub metadata_filters: ::prost::alloc::vec::Vec<MetadataFilter>,
    /// Optional. Maximum number of relevant `Chunk`s to retrieve.
    #[prost(int32, optional, tag = "4")]
    pub max_chunks_count: ::core::option::Option<i32>,
    /// Optional. Minimum relevance score for retrieved relevant `Chunk`s.
    #[prost(float, optional, tag = "5")]
    pub minimum_relevance_score: ::core::option::Option<f32>,
}
/// Response from the model supporting multiple candidate responses.
///
/// Safety ratings and content filtering are reported for both
/// prompt in `GenerateContentResponse.prompt_feedback` and for each candidate
/// in `finish_reason` and in `safety_ratings`. The API:
///   - Returns either all requested candidates or none of them
///   - Returns no candidates at all only if there was something wrong with the
///     prompt (check `prompt_feedback`)
///   - Reports feedback on each candidate in `finish_reason` and
///     `safety_ratings`.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct GenerateContentResponse {
    /// Candidate responses from the model.
    #[prost(message, repeated, tag = "1")]
    pub candidates: ::prost::alloc::vec::Vec<Candidate>,
    /// Returns the prompt's feedback related to the content filters.
    #[prost(message, optional, tag = "2")]
    pub prompt_feedback: ::core::option::Option<generate_content_response::PromptFeedback>,
    /// Output only. Metadata on the generation requests' token usage.
    #[prost(message, optional, tag = "3")]
    pub usage_metadata: ::core::option::Option<generate_content_response::UsageMetadata>,
    /// Output only. The model version used to generate the response.
    #[prost(string, tag = "4")]
    pub model_version: ::prost::alloc::string::String,
    /// Output only. response_id is used to identify each response.
    #[prost(string, tag = "5")]
    pub response_id: ::prost::alloc::string::String,
}
/// Nested message and enum types in `GenerateContentResponse`.
pub mod generate_content_response {
    /// A set of the feedback metadata the prompt specified in
    /// `GenerateContentRequest.content`.
    #[derive(Clone, PartialEq, ::prost::Message)]
    pub struct PromptFeedback {
        /// Optional. If set, the prompt was blocked and no candidates are returned.
        /// Rephrase the prompt.
        #[prost(enumeration = "prompt_feedback::BlockReason", tag = "1")]
        pub block_reason: i32,
        /// Ratings for safety of the prompt.
        /// There is at most one rating per category.
        #[prost(message, repeated, tag = "2")]
        pub safety_ratings: ::prost::alloc::vec::Vec<super::SafetyRating>,
    }
    /// Nested message and enum types in `PromptFeedback`.
    pub mod prompt_feedback {
        /// Specifies the reason why the prompt was blocked.
        #[derive(
            Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord, ::prost::Enumeration,
        )]
        #[repr(i32)]
        pub enum BlockReason {
            /// Default value. This value is unused.
            Unspecified = 0,
            /// Prompt was blocked due to safety reasons. Inspect `safety_ratings`
            /// to understand which safety category blocked it.
            Safety = 1,
            /// Prompt was blocked due to unknown reasons.
            Other = 2,
            /// Prompt was blocked due to the terms which are included from the
            /// terminology blocklist.
            Blocklist = 3,
            /// Prompt was blocked due to prohibited content.
            ProhibitedContent = 4,
            /// Candidates blocked due to unsafe image generation content.
            ImageSafety = 5,
        }
        impl BlockReason {
            /// String value of the enum field names used in the ProtoBuf definition.
            ///
            /// The values are not transformed in any way and thus are considered stable
            /// (if the ProtoBuf definition does not change) and safe for programmatic use.
            pub fn as_str_name(&self) -> &'static str {
                match self {
                    Self::Unspecified => "BLOCK_REASON_UNSPECIFIED",
                    Self::Safety => "SAFETY",
                    Self::Other => "OTHER",
                    Self::Blocklist => "BLOCKLIST",
                    Self::ProhibitedContent => "PROHIBITED_CONTENT",
                    Self::ImageSafety => "IMAGE_SAFETY",
                }
            }
            /// Creates an enum from field names used in the ProtoBuf definition.
            pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
                match value {
                    "BLOCK_REASON_UNSPECIFIED" => Some(Self::Unspecified),
                    "SAFETY" => Some(Self::Safety),
                    "OTHER" => Some(Self::Other),
                    "BLOCKLIST" => Some(Self::Blocklist),
                    "PROHIBITED_CONTENT" => Some(Self::ProhibitedContent),
                    "IMAGE_SAFETY" => Some(Self::ImageSafety),
                    _ => None,
                }
            }
        }
    }
    /// Metadata on the generation request's token usage.
    #[derive(Clone, PartialEq, ::prost::Message)]
    pub struct UsageMetadata {
        /// Number of tokens in the prompt. When `cached_content` is set, this is
        /// still the total effective prompt size meaning this includes the number of
        /// tokens in the cached content.
        #[prost(int32, tag = "1")]
        pub prompt_token_count: i32,
        /// Number of tokens in the cached part of the prompt (the cached content)
        #[prost(int32, tag = "4")]
        pub cached_content_token_count: i32,
        /// Total number of tokens across all the generated response candidates.
        #[prost(int32, tag = "2")]
        pub candidates_token_count: i32,
        /// Output only. Number of tokens present in tool-use prompt(s).
        #[prost(int32, tag = "8")]
        pub tool_use_prompt_token_count: i32,
        /// Output only. Number of tokens of thoughts for thinking models.
        #[prost(int32, tag = "10")]
        pub thoughts_token_count: i32,
        /// Total token count for the generation request (prompt + response
        /// candidates).
        #[prost(int32, tag = "3")]
        pub total_token_count: i32,
        /// Output only. List of modalities that were processed in the request input.
        #[prost(message, repeated, tag = "5")]
        pub prompt_tokens_details: ::prost::alloc::vec::Vec<super::ModalityTokenCount>,
        /// Output only. List of modalities of the cached content in the request
        /// input.
        #[prost(message, repeated, tag = "6")]
        pub cache_tokens_details: ::prost::alloc::vec::Vec<super::ModalityTokenCount>,
        /// Output only. List of modalities that were returned in the response.
        #[prost(message, repeated, tag = "7")]
        pub candidates_tokens_details: ::prost::alloc::vec::Vec<super::ModalityTokenCount>,
        /// Output only. List of modalities that were processed for tool-use request
        /// inputs.
        #[prost(message, repeated, tag = "9")]
        pub tool_use_prompt_tokens_details: ::prost::alloc::vec::Vec<super::ModalityTokenCount>,
    }
}
/// A response candidate generated from the model.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct Candidate {
    /// Output only. Index of the candidate in the list of response candidates.
    #[prost(int32, optional, tag = "3")]
    pub index: ::core::option::Option<i32>,
    /// Output only. Generated content returned from the model.
    #[prost(message, optional, tag = "1")]
    pub content: ::core::option::Option<Content>,
    /// Optional. Output only. The reason why the model stopped generating tokens.
    ///
    /// If empty, the model has not stopped generating tokens.
    #[prost(enumeration = "candidate::FinishReason", tag = "2")]
    pub finish_reason: i32,
    /// List of ratings for the safety of a response candidate.
    ///
    /// There is at most one rating per category.
    #[prost(message, repeated, tag = "5")]
    pub safety_ratings: ::prost::alloc::vec::Vec<SafetyRating>,
    /// Output only. Citation information for model-generated candidate.
    ///
    /// This field may be populated with recitation information for any text
    /// included in the `content`. These are passages that are "recited" from
    /// copyrighted material in the foundational LLM's training data.
    #[prost(message, optional, tag = "6")]
    pub citation_metadata: ::core::option::Option<CitationMetadata>,
    /// Output only. Token count for this candidate.
    #[prost(int32, tag = "7")]
    pub token_count: i32,
    /// Output only. Attribution information for sources that contributed to a
    /// grounded answer.
    ///
    /// This field is populated for `GenerateAnswer` calls.
    #[prost(message, repeated, tag = "8")]
    pub grounding_attributions: ::prost::alloc::vec::Vec<GroundingAttribution>,
    /// Output only. Grounding metadata for the candidate.
    ///
    /// This field is populated for `GenerateContent` calls.
    #[prost(message, optional, tag = "9")]
    pub grounding_metadata: ::core::option::Option<GroundingMetadata>,
    /// Output only. Average log probability score of the candidate.
    #[prost(double, tag = "10")]
    pub avg_logprobs: f64,
    /// Output only. Log-likelihood scores for the response tokens and top tokens
    #[prost(message, optional, tag = "11")]
    pub logprobs_result: ::core::option::Option<LogprobsResult>,
    /// Output only. Metadata related to url context retrieval tool.
    #[prost(message, optional, tag = "13")]
    pub url_context_metadata: ::core::option::Option<UrlContextMetadata>,
}
/// Nested message and enum types in `Candidate`.
pub mod candidate {
    /// Defines the reason why the model stopped generating tokens.
    #[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord, ::prost::Enumeration)]
    #[repr(i32)]
    pub enum FinishReason {
        /// Default value. This value is unused.
        Unspecified = 0,
        /// Natural stop point of the model or provided stop sequence.
        Stop = 1,
        /// The maximum number of tokens as specified in the request was reached.
        MaxTokens = 2,
        /// The response candidate content was flagged for safety reasons.
        Safety = 3,
        /// The response candidate content was flagged for recitation reasons.
        Recitation = 4,
        /// The response candidate content was flagged for using an unsupported
        /// language.
        Language = 6,
        /// Unknown reason.
        Other = 5,
        /// Token generation stopped because the content contains forbidden terms.
        Blocklist = 7,
        /// Token generation stopped for potentially containing prohibited content.
        ProhibitedContent = 8,
        /// Token generation stopped because the content potentially contains
        /// Sensitive Personally Identifiable Information (SPII).
        Spii = 9,
        /// The function call generated by the model is invalid.
        MalformedFunctionCall = 10,
        /// Token generation stopped because generated images contain safety
        /// violations.
        ImageSafety = 11,
        /// Model generated a tool call but no tools were enabled in the request.
        UnexpectedToolCall = 12,
    }
    impl FinishReason {
        /// String value of the enum field names used in the ProtoBuf definition.
        ///
        /// The values are not transformed in any way and thus are considered stable
        /// (if the ProtoBuf definition does not change) and safe for programmatic use.
        pub fn as_str_name(&self) -> &'static str {
            match self {
                Self::Unspecified => "FINISH_REASON_UNSPECIFIED",
                Self::Stop => "STOP",
                Self::MaxTokens => "MAX_TOKENS",
                Self::Safety => "SAFETY",
                Self::Recitation => "RECITATION",
                Self::Language => "LANGUAGE",
                Self::Other => "OTHER",
                Self::Blocklist => "BLOCKLIST",
                Self::ProhibitedContent => "PROHIBITED_CONTENT",
                Self::Spii => "SPII",
                Self::MalformedFunctionCall => "MALFORMED_FUNCTION_CALL",
                Self::ImageSafety => "IMAGE_SAFETY",
                Self::UnexpectedToolCall => "UNEXPECTED_TOOL_CALL",
            }
        }
        /// Creates an enum from field names used in the ProtoBuf definition.
        pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
            match value {
                "FINISH_REASON_UNSPECIFIED" => Some(Self::Unspecified),
                "STOP" => Some(Self::Stop),
                "MAX_TOKENS" => Some(Self::MaxTokens),
                "SAFETY" => Some(Self::Safety),
                "RECITATION" => Some(Self::Recitation),
                "LANGUAGE" => Some(Self::Language),
                "OTHER" => Some(Self::Other),
                "BLOCKLIST" => Some(Self::Blocklist),
                "PROHIBITED_CONTENT" => Some(Self::ProhibitedContent),
                "SPII" => Some(Self::Spii),
                "MALFORMED_FUNCTION_CALL" => Some(Self::MalformedFunctionCall),
                "IMAGE_SAFETY" => Some(Self::ImageSafety),
                "UNEXPECTED_TOOL_CALL" => Some(Self::UnexpectedToolCall),
                _ => None,
            }
        }
    }
}
/// Metadata related to url context retrieval tool.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct UrlContextMetadata {
    /// List of url context.
    #[prost(message, repeated, tag = "1")]
    pub url_metadata: ::prost::alloc::vec::Vec<UrlMetadata>,
}
/// Context of the a single url retrieval.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct UrlMetadata {
    /// Retrieved url by the tool.
    #[prost(string, tag = "1")]
    pub retrieved_url: ::prost::alloc::string::String,
    /// Status of the url retrieval.
    #[prost(enumeration = "url_metadata::UrlRetrievalStatus", tag = "2")]
    pub url_retrieval_status: i32,
}
/// Nested message and enum types in `UrlMetadata`.
pub mod url_metadata {
    /// Status of the url retrieval.
    #[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord, ::prost::Enumeration)]
    #[repr(i32)]
    pub enum UrlRetrievalStatus {
        /// Default value. This value is unused.
        Unspecified = 0,
        /// Url retrieval is successful.
        Success = 1,
        /// Url retrieval is failed due to error.
        Error = 2,
    }
    impl UrlRetrievalStatus {
        /// String value of the enum field names used in the ProtoBuf definition.
        ///
        /// The values are not transformed in any way and thus are considered stable
        /// (if the ProtoBuf definition does not change) and safe for programmatic use.
        pub fn as_str_name(&self) -> &'static str {
            match self {
                Self::Unspecified => "URL_RETRIEVAL_STATUS_UNSPECIFIED",
                Self::Success => "URL_RETRIEVAL_STATUS_SUCCESS",
                Self::Error => "URL_RETRIEVAL_STATUS_ERROR",
            }
        }
        /// Creates an enum from field names used in the ProtoBuf definition.
        pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
            match value {
                "URL_RETRIEVAL_STATUS_UNSPECIFIED" => Some(Self::Unspecified),
                "URL_RETRIEVAL_STATUS_SUCCESS" => Some(Self::Success),
                "URL_RETRIEVAL_STATUS_ERROR" => Some(Self::Error),
                _ => None,
            }
        }
    }
}
/// Logprobs Result
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct LogprobsResult {
    /// Length = total number of decoding steps.
    #[prost(message, repeated, tag = "1")]
    pub top_candidates: ::prost::alloc::vec::Vec<logprobs_result::TopCandidates>,
    /// Length = total number of decoding steps.
    /// The chosen candidates may or may not be in top_candidates.
    #[prost(message, repeated, tag = "2")]
    pub chosen_candidates: ::prost::alloc::vec::Vec<logprobs_result::Candidate>,
}
/// Nested message and enum types in `LogprobsResult`.
pub mod logprobs_result {
    /// Candidate for the logprobs token and score.
    #[derive(Clone, PartialEq, ::prost::Message)]
    pub struct Candidate {
        /// The candidate’s token string value.
        #[prost(string, optional, tag = "1")]
        pub token: ::core::option::Option<::prost::alloc::string::String>,
        /// The candidate’s token id value.
        #[prost(int32, optional, tag = "3")]
        pub token_id: ::core::option::Option<i32>,
        /// The candidate's log probability.
        #[prost(float, optional, tag = "2")]
        pub log_probability: ::core::option::Option<f32>,
    }
    /// Candidates with top log probabilities at each decoding step.
    #[derive(Clone, PartialEq, ::prost::Message)]
    pub struct TopCandidates {
        /// Sorted by log probability in descending order.
        #[prost(message, repeated, tag = "1")]
        pub candidates: ::prost::alloc::vec::Vec<Candidate>,
    }
}
/// Identifier for the source contributing to this attribution.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct AttributionSourceId {
    #[prost(oneof = "attribution_source_id::Source", tags = "1, 2")]
    pub source: ::core::option::Option<attribution_source_id::Source>,
}
/// Nested message and enum types in `AttributionSourceId`.
pub mod attribution_source_id {
    /// Identifier for a part within a `GroundingPassage`.
    #[derive(Clone, PartialEq, ::prost::Message)]
    pub struct GroundingPassageId {
        /// Output only. ID of the passage matching the `GenerateAnswerRequest`'s
        /// `GroundingPassage.id`.
        #[prost(string, tag = "1")]
        pub passage_id: ::prost::alloc::string::String,
        /// Output only. Index of the part within the `GenerateAnswerRequest`'s
        /// `GroundingPassage.content`.
        #[prost(int32, tag = "2")]
        pub part_index: i32,
    }
    /// Identifier for a `Chunk` retrieved via Semantic Retriever specified in the
    /// `GenerateAnswerRequest` using `SemanticRetrieverConfig`.
    #[derive(Clone, PartialEq, ::prost::Message)]
    pub struct SemanticRetrieverChunk {
        /// Output only. Name of the source matching the request's
        /// `SemanticRetrieverConfig.source`. Example: `corpora/123` or
        /// `corpora/123/documents/abc`
        #[prost(string, tag = "1")]
        pub source: ::prost::alloc::string::String,
        /// Output only. Name of the `Chunk` containing the attributed text.
        /// Example: `corpora/123/documents/abc/chunks/xyz`
        #[prost(string, tag = "2")]
        pub chunk: ::prost::alloc::string::String,
    }
    #[derive(Clone, PartialEq, ::prost::Oneof)]
    pub enum Source {
        /// Identifier for an inline passage.
        #[prost(message, tag = "1")]
        GroundingPassage(GroundingPassageId),
        /// Identifier for a `Chunk` fetched via Semantic Retriever.
        #[prost(message, tag = "2")]
        SemanticRetrieverChunk(SemanticRetrieverChunk),
    }
}
/// Attribution for a source that contributed to an answer.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct GroundingAttribution {
    /// Output only. Identifier for the source contributing to this attribution.
    #[prost(message, optional, tag = "3")]
    pub source_id: ::core::option::Option<AttributionSourceId>,
    /// Grounding source content that makes up this attribution.
    #[prost(message, optional, tag = "2")]
    pub content: ::core::option::Option<Content>,
}
/// Metadata related to retrieval in the grounding flow.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct RetrievalMetadata {
    /// Optional. Score indicating how likely information from google search could
    /// help answer the prompt. The score is in the range \[0, 1\], where 0 is the
    /// least likely and 1 is the most likely. This score is only populated when
    /// google search grounding and dynamic retrieval is enabled. It will be
    /// compared to the threshold to determine whether to trigger google search.
    #[prost(float, tag = "2")]
    pub google_search_dynamic_retrieval_score: f32,
}
/// Metadata returned to client when grounding is enabled.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct GroundingMetadata {
    /// Optional. Google search entry for the following-up web searches.
    #[prost(message, optional, tag = "1")]
    pub search_entry_point: ::core::option::Option<SearchEntryPoint>,
    /// List of supporting references retrieved from specified grounding source.
    #[prost(message, repeated, tag = "2")]
    pub grounding_chunks: ::prost::alloc::vec::Vec<GroundingChunk>,
    /// List of grounding support.
    #[prost(message, repeated, tag = "3")]
    pub grounding_supports: ::prost::alloc::vec::Vec<GroundingSupport>,
    /// Metadata related to retrieval in the grounding flow.
    #[prost(message, optional, tag = "4")]
    pub retrieval_metadata: ::core::option::Option<RetrievalMetadata>,
    /// Web search queries for the following-up web search.
    #[prost(string, repeated, tag = "5")]
    pub web_search_queries: ::prost::alloc::vec::Vec<::prost::alloc::string::String>,
}
/// Google search entry point.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct SearchEntryPoint {
    /// Optional. Web content snippet that can be embedded in a web page or an app
    /// webview.
    #[prost(string, tag = "1")]
    pub rendered_content: ::prost::alloc::string::String,
    /// Optional. Base64 encoded JSON representing array of <search term, search
    /// url> tuple.
    #[prost(bytes = "vec", tag = "2")]
    pub sdk_blob: ::prost::alloc::vec::Vec<u8>,
}
/// Grounding chunk.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct GroundingChunk {
    /// Chunk type.
    #[prost(oneof = "grounding_chunk::ChunkType", tags = "1")]
    pub chunk_type: ::core::option::Option<grounding_chunk::ChunkType>,
}
/// Nested message and enum types in `GroundingChunk`.
pub mod grounding_chunk {
    /// Chunk from the web.
    #[derive(Clone, PartialEq, ::prost::Message)]
    pub struct Web {
        /// URI reference of the chunk.
        #[prost(string, optional, tag = "1")]
        pub uri: ::core::option::Option<::prost::alloc::string::String>,
        /// Title of the chunk.
        #[prost(string, optional, tag = "2")]
        pub title: ::core::option::Option<::prost::alloc::string::String>,
    }
    /// Chunk type.
    #[derive(Clone, PartialEq, ::prost::Oneof)]
    pub enum ChunkType {
        /// Grounding chunk from the web.
        #[prost(message, tag = "1")]
        Web(Web),
    }
}
/// Segment of the content.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct Segment {
    /// Output only. The index of a Part object within its parent Content object.
    #[prost(int32, tag = "1")]
    pub part_index: i32,
    /// Output only. Start index in the given Part, measured in bytes. Offset from
    /// the start of the Part, inclusive, starting at zero.
    #[prost(int32, tag = "2")]
    pub start_index: i32,
    /// Output only. End index in the given Part, measured in bytes. Offset from
    /// the start of the Part, exclusive, starting at zero.
    #[prost(int32, tag = "3")]
    pub end_index: i32,
    /// Output only. The text corresponding to the segment from the response.
    #[prost(string, tag = "4")]
    pub text: ::prost::alloc::string::String,
}
/// Grounding support.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct GroundingSupport {
    /// Segment of the content this support belongs to.
    #[prost(message, optional, tag = "1")]
    pub segment: ::core::option::Option<Segment>,
    /// A list of indices (into 'grounding_chunk') specifying the
    /// citations associated with the claim. For instance \[1,3,4\] means
    /// that grounding_chunk\[1\], grounding_chunk\[3\],
    /// grounding_chunk\[4\] are the retrieved content attributed to the claim.
    #[prost(int32, repeated, tag = "2")]
    pub grounding_chunk_indices: ::prost::alloc::vec::Vec<i32>,
    /// Confidence score of the support references. Ranges from 0 to 1. 1 is the
    /// most confident. This list must have the same size as the
    /// grounding_chunk_indices.
    #[prost(float, repeated, tag = "3")]
    pub confidence_scores: ::prost::alloc::vec::Vec<f32>,
}
/// Request to generate a grounded answer from the `Model`.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct GenerateAnswerRequest {
    /// Required. The name of the `Model` to use for generating the grounded
    /// response.
    ///
    /// Format: `model=models/{model}`.
    #[prost(string, tag = "1")]
    pub model: ::prost::alloc::string::String,
    /// Required. The content of the current conversation with the `Model`. For
    /// single-turn queries, this is a single question to answer. For multi-turn
    /// queries, this is a repeated field that contains conversation history and
    /// the last `Content` in the list containing the question.
    ///
    /// Note: `GenerateAnswer` only supports queries in English.
    #[prost(message, repeated, tag = "2")]
    pub contents: ::prost::alloc::vec::Vec<Content>,
    /// Required. Style in which answers should be returned.
    #[prost(enumeration = "generate_answer_request::AnswerStyle", tag = "5")]
    pub answer_style: i32,
    /// Optional. A list of unique `SafetySetting` instances for blocking unsafe
    /// content.
    ///
    /// This will be enforced on the `GenerateAnswerRequest.contents` and
    /// `GenerateAnswerResponse.candidate`. There should not be more than one
    /// setting for each `SafetyCategory` type. The API will block any contents and
    /// responses that fail to meet the thresholds set by these settings. This list
    /// overrides the default settings for each `SafetyCategory` specified in the
    /// safety_settings. If there is no `SafetySetting` for a given
    /// `SafetyCategory` provided in the list, the API will use the default safety
    /// setting for that category. Harm categories HARM_CATEGORY_HATE_SPEECH,
    /// HARM_CATEGORY_SEXUALLY_EXPLICIT, HARM_CATEGORY_DANGEROUS_CONTENT,
    /// HARM_CATEGORY_HARASSMENT are supported.
    /// Refer to the
    /// [guide](<https://ai.google.dev/gemini-api/docs/safety-settings>)
    /// for detailed information on available safety settings. Also refer to the
    /// [Safety guidance](<https://ai.google.dev/gemini-api/docs/safety-guidance>) to
    /// learn how to incorporate safety considerations in your AI applications.
    #[prost(message, repeated, tag = "3")]
    pub safety_settings: ::prost::alloc::vec::Vec<SafetySetting>,
    /// Optional. Controls the randomness of the output.
    ///
    /// Values can range from \[0.0,1.0\], inclusive. A value closer to 1.0 will
    /// produce responses that are more varied and creative, while a value closer
    /// to 0.0 will typically result in more straightforward responses from the
    /// model. A low temperature (~0.2) is usually recommended for
    /// Attributed-Question-Answering use cases.
    #[prost(float, optional, tag = "4")]
    pub temperature: ::core::option::Option<f32>,
    /// The sources in which to ground the answer.
    #[prost(oneof = "generate_answer_request::GroundingSource", tags = "6, 7")]
    pub grounding_source: ::core::option::Option<generate_answer_request::GroundingSource>,
}
/// Nested message and enum types in `GenerateAnswerRequest`.
pub mod generate_answer_request {
    /// Style for grounded answers.
    #[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord, ::prost::Enumeration)]
    #[repr(i32)]
    pub enum AnswerStyle {
        /// Unspecified answer style.
        Unspecified = 0,
        /// Succinct but abstract style.
        Abstractive = 1,
        /// Very brief and extractive style.
        Extractive = 2,
        /// Verbose style including extra details. The response may be formatted as a
        /// sentence, paragraph, multiple paragraphs, or bullet points, etc.
        Verbose = 3,
    }
    impl AnswerStyle {
        /// String value of the enum field names used in the ProtoBuf definition.
        ///
        /// The values are not transformed in any way and thus are considered stable
        /// (if the ProtoBuf definition does not change) and safe for programmatic use.
        pub fn as_str_name(&self) -> &'static str {
            match self {
                Self::Unspecified => "ANSWER_STYLE_UNSPECIFIED",
                Self::Abstractive => "ABSTRACTIVE",
                Self::Extractive => "EXTRACTIVE",
                Self::Verbose => "VERBOSE",
            }
        }
        /// Creates an enum from field names used in the ProtoBuf definition.
        pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
            match value {
                "ANSWER_STYLE_UNSPECIFIED" => Some(Self::Unspecified),
                "ABSTRACTIVE" => Some(Self::Abstractive),
                "EXTRACTIVE" => Some(Self::Extractive),
                "VERBOSE" => Some(Self::Verbose),
                _ => None,
            }
        }
    }
    /// The sources in which to ground the answer.
    #[derive(Clone, PartialEq, ::prost::Oneof)]
    pub enum GroundingSource {
        /// Passages provided inline with the request.
        #[prost(message, tag = "6")]
        InlinePassages(super::GroundingPassages),
        /// Content retrieved from resources created via the Semantic Retriever
        /// API.
        #[prost(message, tag = "7")]
        SemanticRetriever(super::SemanticRetrieverConfig),
    }
}
/// Response from the model for a grounded answer.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct GenerateAnswerResponse {
    /// Candidate answer from the model.
    ///
    /// Note: The model *always* attempts to provide a grounded answer, even when
    /// the answer is unlikely to be answerable from the given passages.
    /// In that case, a low-quality or ungrounded answer may be provided, along
    /// with a low `answerable_probability`.
    #[prost(message, optional, tag = "1")]
    pub answer: ::core::option::Option<Candidate>,
    /// Output only. The model's estimate of the probability that its answer is
    /// correct and grounded in the input passages.
    ///
    /// A low `answerable_probability` indicates that the answer might not be
    /// grounded in the sources.
    ///
    /// When `answerable_probability` is low, you may want to:
    ///
    /// * Display a message to the effect of "We couldn’t answer that question" to
    /// the user.
    /// * Fall back to a general-purpose LLM that answers the question from world
    /// knowledge. The threshold and nature of such fallbacks will depend on
    /// individual use cases. `0.5` is a good starting threshold.
    #[prost(float, optional, tag = "2")]
    pub answerable_probability: ::core::option::Option<f32>,
    /// Output only. Feedback related to the input data used to answer the
    /// question, as opposed to the model-generated response to the question.
    ///
    /// The input data can be one or more of the following:
    ///
    /// - Question specified by the last entry in `GenerateAnswerRequest.content`
    /// - Conversation history specified by the other entries in
    /// `GenerateAnswerRequest.content`
    /// - Grounding sources (`GenerateAnswerRequest.semantic_retriever` or
    /// `GenerateAnswerRequest.inline_passages`)
    #[prost(message, optional, tag = "3")]
    pub input_feedback: ::core::option::Option<generate_answer_response::InputFeedback>,
}
/// Nested message and enum types in `GenerateAnswerResponse`.
pub mod generate_answer_response {
    /// Feedback related to the input data used to answer the question, as opposed
    /// to the model-generated response to the question.
    #[derive(Clone, PartialEq, ::prost::Message)]
    pub struct InputFeedback {
        /// Optional. If set, the input was blocked and no candidates are returned.
        /// Rephrase the input.
        #[prost(enumeration = "input_feedback::BlockReason", optional, tag = "1")]
        pub block_reason: ::core::option::Option<i32>,
        /// Ratings for safety of the input.
        /// There is at most one rating per category.
        #[prost(message, repeated, tag = "2")]
        pub safety_ratings: ::prost::alloc::vec::Vec<super::SafetyRating>,
    }
    /// Nested message and enum types in `InputFeedback`.
    pub mod input_feedback {
        /// Specifies what was the reason why input was blocked.
        #[derive(
            Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord, ::prost::Enumeration,
        )]
        #[repr(i32)]
        pub enum BlockReason {
            /// Default value. This value is unused.
            Unspecified = 0,
            /// Input was blocked due to safety reasons. Inspect
            /// `safety_ratings` to understand which safety category blocked it.
            Safety = 1,
            /// Input was blocked due to other reasons.
            Other = 2,
        }
        impl BlockReason {
            /// String value of the enum field names used in the ProtoBuf definition.
            ///
            /// The values are not transformed in any way and thus are considered stable
            /// (if the ProtoBuf definition does not change) and safe for programmatic use.
            pub fn as_str_name(&self) -> &'static str {
                match self {
                    Self::Unspecified => "BLOCK_REASON_UNSPECIFIED",
                    Self::Safety => "SAFETY",
                    Self::Other => "OTHER",
                }
            }
            /// Creates an enum from field names used in the ProtoBuf definition.
            pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
                match value {
                    "BLOCK_REASON_UNSPECIFIED" => Some(Self::Unspecified),
                    "SAFETY" => Some(Self::Safety),
                    "OTHER" => Some(Self::Other),
                    _ => None,
                }
            }
        }
    }
}
/// Request containing the `Content` for the model to embed.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct EmbedContentRequest {
    /// Required. The model's resource name. This serves as an ID for the Model to
    /// use.
    ///
    /// This name should match a model name returned by the `ListModels` method.
    ///
    /// Format: `models/{model}`
    #[prost(string, tag = "1")]
    pub model: ::prost::alloc::string::String,
    /// Required. The content to embed. Only the `parts.text` fields will be
    /// counted.
    #[prost(message, optional, tag = "2")]
    pub content: ::core::option::Option<Content>,
    /// Optional. Optional task type for which the embeddings will be used. Not
    /// supported on earlier models (`models/embedding-001`).
    #[prost(enumeration = "TaskType", optional, tag = "3")]
    pub task_type: ::core::option::Option<i32>,
    /// Optional. An optional title for the text. Only applicable when TaskType is
    /// `RETRIEVAL_DOCUMENT`.
    ///
    /// Note: Specifying a `title` for `RETRIEVAL_DOCUMENT` provides better quality
    /// embeddings for retrieval.
    #[prost(string, optional, tag = "4")]
    pub title: ::core::option::Option<::prost::alloc::string::String>,
    /// Optional. Optional reduced dimension for the output embedding. If set,
    /// excessive values in the output embedding are truncated from the end.
    /// Supported by newer models since 2024 only. You cannot set this value if
    /// using the earlier model (`models/embedding-001`).
    #[prost(int32, optional, tag = "5")]
    pub output_dimensionality: ::core::option::Option<i32>,
}
/// A list of floats representing an embedding.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ContentEmbedding {
    /// The embedding values.
    #[prost(float, repeated, tag = "1")]
    pub values: ::prost::alloc::vec::Vec<f32>,
}
/// The response to an `EmbedContentRequest`.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct EmbedContentResponse {
    /// Output only. The embedding generated from the input content.
    #[prost(message, optional, tag = "1")]
    pub embedding: ::core::option::Option<ContentEmbedding>,
}
/// Batch request to get embeddings from the model for a list of prompts.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct BatchEmbedContentsRequest {
    /// Required. The model's resource name. This serves as an ID for the Model to
    /// use.
    ///
    /// This name should match a model name returned by the `ListModels` method.
    ///
    /// Format: `models/{model}`
    #[prost(string, tag = "1")]
    pub model: ::prost::alloc::string::String,
    /// Required. Embed requests for the batch. The model in each of these requests
    /// must match the model specified `BatchEmbedContentsRequest.model`.
    #[prost(message, repeated, tag = "2")]
    pub requests: ::prost::alloc::vec::Vec<EmbedContentRequest>,
}
/// The response to a `BatchEmbedContentsRequest`.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct BatchEmbedContentsResponse {
    /// Output only. The embeddings for each request, in the same order as provided
    /// in the batch request.
    #[prost(message, repeated, tag = "1")]
    pub embeddings: ::prost::alloc::vec::Vec<ContentEmbedding>,
}
/// Counts the number of tokens in the `prompt` sent to a model.
///
/// Models may tokenize text differently, so each model may return a different
/// `token_count`.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct CountTokensRequest {
    /// Required. The model's resource name. This serves as an ID for the Model to
    /// use.
    ///
    /// This name should match a model name returned by the `ListModels` method.
    ///
    /// Format: `models/{model}`
    #[prost(string, tag = "1")]
    pub model: ::prost::alloc::string::String,
    /// Optional. The input given to the model as a prompt. This field is ignored
    /// when `generate_content_request` is set.
    #[prost(message, repeated, tag = "2")]
    pub contents: ::prost::alloc::vec::Vec<Content>,
    /// Optional. The overall input given to the `Model`. This includes the prompt
    /// as well as other model steering information like [system
    /// instructions](<https://ai.google.dev/gemini-api/docs/system-instructions>),
    /// and/or function declarations for [function
    /// calling](<https://ai.google.dev/gemini-api/docs/function-calling>).
    /// `Model`s/`Content`s and `generate_content_request`s are mutually
    /// exclusive. You can either send `Model` + `Content`s or a
    /// `generate_content_request`, but never both.
    #[prost(message, optional, tag = "3")]
    pub generate_content_request: ::core::option::Option<GenerateContentRequest>,
}
/// A response from `CountTokens`.
///
/// It returns the model's `token_count` for the `prompt`.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct CountTokensResponse {
    /// The number of tokens that the `Model` tokenizes the `prompt` into. Always
    /// non-negative.
    #[prost(int32, tag = "1")]
    pub total_tokens: i32,
    /// Number of tokens in the cached part of the prompt (the cached content).
    #[prost(int32, tag = "5")]
    pub cached_content_token_count: i32,
    /// Output only. List of modalities that were processed in the request input.
    #[prost(message, repeated, tag = "6")]
    pub prompt_tokens_details: ::prost::alloc::vec::Vec<ModalityTokenCount>,
    /// Output only. List of modalities that were processed in the cached content.
    #[prost(message, repeated, tag = "7")]
    pub cache_tokens_details: ::prost::alloc::vec::Vec<ModalityTokenCount>,
}
/// Configures the realtime input behavior in `BidiGenerateContent`.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct RealtimeInputConfig {
    /// Optional. If not set, automatic activity detection is enabled by default.
    /// If automatic voice detection is disabled, the client must send activity
    /// signals.
    #[prost(message, optional, tag = "1")]
    pub automatic_activity_detection:
        ::core::option::Option<realtime_input_config::AutomaticActivityDetection>,
    /// Optional. Defines what effect activity has.
    #[prost(
        enumeration = "realtime_input_config::ActivityHandling",
        optional,
        tag = "3"
    )]
    pub activity_handling: ::core::option::Option<i32>,
    /// Optional. Defines which input is included in the user's turn.
    #[prost(
        enumeration = "realtime_input_config::TurnCoverage",
        optional,
        tag = "4"
    )]
    pub turn_coverage: ::core::option::Option<i32>,
}
/// Nested message and enum types in `RealtimeInputConfig`.
pub mod realtime_input_config {
    /// Configures automatic detection of activity.
    #[derive(Clone, PartialEq, ::prost::Message)]
    pub struct AutomaticActivityDetection {
        /// Optional. If enabled (the default), detected voice and text input count
        /// as activity. If disabled, the client must send activity signals.
        #[prost(bool, optional, tag = "2")]
        pub disabled: ::core::option::Option<bool>,
        /// Optional. Determines how likely speech is to be detected.
        #[prost(
            enumeration = "automatic_activity_detection::StartSensitivity",
            optional,
            tag = "3"
        )]
        pub start_of_speech_sensitivity: ::core::option::Option<i32>,
        /// Optional. The required duration of detected speech before start-of-speech
        /// is committed. The lower this value, the more sensitive the
        /// start-of-speech detection is and shorter speech can be recognized.
        /// However, this also increases the probability of false positives.
        #[prost(int32, optional, tag = "4")]
        pub prefix_padding_ms: ::core::option::Option<i32>,
        /// Optional. Determines how likely detected speech is ended.
        #[prost(
            enumeration = "automatic_activity_detection::EndSensitivity",
            optional,
            tag = "5"
        )]
        pub end_of_speech_sensitivity: ::core::option::Option<i32>,
        /// Optional. The required duration of detected non-speech (e.g. silence)
        /// before end-of-speech is committed. The larger this value, the longer
        /// speech gaps can be without interrupting the user's activity but this will
        /// increase the model's latency.
        #[prost(int32, optional, tag = "6")]
        pub silence_duration_ms: ::core::option::Option<i32>,
    }
    /// Nested message and enum types in `AutomaticActivityDetection`.
    pub mod automatic_activity_detection {
        /// Determines how start of speech is detected.
        #[derive(
            Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord, ::prost::Enumeration,
        )]
        #[repr(i32)]
        pub enum StartSensitivity {
            /// The default is START_SENSITIVITY_HIGH.
            Unspecified = 0,
            /// Automatic detection will detect the start of speech more often.
            High = 1,
            /// Automatic detection will detect the start of speech less often.
            Low = 2,
        }
        impl StartSensitivity {
            /// String value of the enum field names used in the ProtoBuf definition.
            ///
            /// The values are not transformed in any way and thus are considered stable
            /// (if the ProtoBuf definition does not change) and safe for programmatic use.
            pub fn as_str_name(&self) -> &'static str {
                match self {
                    Self::Unspecified => "START_SENSITIVITY_UNSPECIFIED",
                    Self::High => "START_SENSITIVITY_HIGH",
                    Self::Low => "START_SENSITIVITY_LOW",
                }
            }
            /// Creates an enum from field names used in the ProtoBuf definition.
            pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
                match value {
                    "START_SENSITIVITY_UNSPECIFIED" => Some(Self::Unspecified),
                    "START_SENSITIVITY_HIGH" => Some(Self::High),
                    "START_SENSITIVITY_LOW" => Some(Self::Low),
                    _ => None,
                }
            }
        }
        /// Determines how end of speech is detected.
        #[derive(
            Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord, ::prost::Enumeration,
        )]
        #[repr(i32)]
        pub enum EndSensitivity {
            /// The default is END_SENSITIVITY_HIGH.
            Unspecified = 0,
            /// Automatic detection ends speech more often.
            High = 1,
            /// Automatic detection ends speech less often.
            Low = 2,
        }
        impl EndSensitivity {
            /// String value of the enum field names used in the ProtoBuf definition.
            ///
            /// The values are not transformed in any way and thus are considered stable
            /// (if the ProtoBuf definition does not change) and safe for programmatic use.
            pub fn as_str_name(&self) -> &'static str {
                match self {
                    Self::Unspecified => "END_SENSITIVITY_UNSPECIFIED",
                    Self::High => "END_SENSITIVITY_HIGH",
                    Self::Low => "END_SENSITIVITY_LOW",
                }
            }
            /// Creates an enum from field names used in the ProtoBuf definition.
            pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
                match value {
                    "END_SENSITIVITY_UNSPECIFIED" => Some(Self::Unspecified),
                    "END_SENSITIVITY_HIGH" => Some(Self::High),
                    "END_SENSITIVITY_LOW" => Some(Self::Low),
                    _ => None,
                }
            }
        }
    }
    /// The different ways of handling user activity.
    #[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord, ::prost::Enumeration)]
    #[repr(i32)]
    pub enum ActivityHandling {
        /// If unspecified, the default behavior is `START_OF_ACTIVITY_INTERRUPTS`.
        Unspecified = 0,
        /// If true, start of activity will interrupt the model's response (also
        /// called "barge in"). The model's current response will be cut-off in the
        /// moment of the interruption. This is the default behavior.
        StartOfActivityInterrupts = 1,
        /// The model's response will not be interrupted.
        NoInterruption = 2,
    }
    impl ActivityHandling {
        /// String value of the enum field names used in the ProtoBuf definition.
        ///
        /// The values are not transformed in any way and thus are considered stable
        /// (if the ProtoBuf definition does not change) and safe for programmatic use.
        pub fn as_str_name(&self) -> &'static str {
            match self {
                Self::Unspecified => "ACTIVITY_HANDLING_UNSPECIFIED",
                Self::StartOfActivityInterrupts => "START_OF_ACTIVITY_INTERRUPTS",
                Self::NoInterruption => "NO_INTERRUPTION",
            }
        }
        /// Creates an enum from field names used in the ProtoBuf definition.
        pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
            match value {
                "ACTIVITY_HANDLING_UNSPECIFIED" => Some(Self::Unspecified),
                "START_OF_ACTIVITY_INTERRUPTS" => Some(Self::StartOfActivityInterrupts),
                "NO_INTERRUPTION" => Some(Self::NoInterruption),
                _ => None,
            }
        }
    }
    /// Options about which input is included in the user's turn.
    #[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord, ::prost::Enumeration)]
    #[repr(i32)]
    pub enum TurnCoverage {
        /// If unspecified, the default behavior is `TURN_INCLUDES_ONLY_ACTIVITY`.
        Unspecified = 0,
        /// The users turn only includes activity since the last turn, excluding
        /// inactivity (e.g. silence on the audio stream). This is the default
        /// behavior.
        TurnIncludesOnlyActivity = 1,
        /// The users turn includes all realtime input since the last turn, including
        /// inactivity (e.g. silence on the audio stream).
        TurnIncludesAllInput = 2,
    }
    impl TurnCoverage {
        /// String value of the enum field names used in the ProtoBuf definition.
        ///
        /// The values are not transformed in any way and thus are considered stable
        /// (if the ProtoBuf definition does not change) and safe for programmatic use.
        pub fn as_str_name(&self) -> &'static str {
            match self {
                Self::Unspecified => "TURN_COVERAGE_UNSPECIFIED",
                Self::TurnIncludesOnlyActivity => "TURN_INCLUDES_ONLY_ACTIVITY",
                Self::TurnIncludesAllInput => "TURN_INCLUDES_ALL_INPUT",
            }
        }
        /// Creates an enum from field names used in the ProtoBuf definition.
        pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
            match value {
                "TURN_COVERAGE_UNSPECIFIED" => Some(Self::Unspecified),
                "TURN_INCLUDES_ONLY_ACTIVITY" => Some(Self::TurnIncludesOnlyActivity),
                "TURN_INCLUDES_ALL_INPUT" => Some(Self::TurnIncludesAllInput),
                _ => None,
            }
        }
    }
}
/// Session resumption configuration.
///
/// This message is included in the session configuration as
/// `BidiGenerateContentSetup.session_resumption`. If configured, the server
/// will send `SessionResumptionUpdate` messages.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct SessionResumptionConfig {
    /// The handle of a previous session. If not present then a new session is
    /// created.
    ///
    /// Session handles come from `SessionResumptionUpdate.token` values in
    /// previous connections.
    #[prost(string, optional, tag = "1")]
    pub handle: ::core::option::Option<::prost::alloc::string::String>,
}
/// Enables context window compression — a mechanism for managing the model's
/// context window so that it does not exceed a given length.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ContextWindowCompressionConfig {
    /// The number of tokens (before running a turn) required to trigger a context
    /// window compression.
    ///
    /// This can be used to balance quality against latency as shorter context
    /// windows may result in faster model responses. However, any compression
    /// operation will cause a temporary latency increase, so they should not be
    /// triggered frequently.
    ///
    /// If not set, the default is 80% of the model's context window limit. This
    /// leaves 20% for the next user request/model response.
    #[prost(int64, optional, tag = "1")]
    pub trigger_tokens: ::core::option::Option<i64>,
    /// The context window compression mechanism used.
    #[prost(
        oneof = "context_window_compression_config::CompressionMechanism",
        tags = "2"
    )]
    pub compression_mechanism:
        ::core::option::Option<context_window_compression_config::CompressionMechanism>,
}
/// Nested message and enum types in `ContextWindowCompressionConfig`.
pub mod context_window_compression_config {
    /// The SlidingWindow method operates by discarding content at the beginning of
    /// the context window. The resulting context will always begin at the start of
    /// a USER role turn. System instructions and any
    /// `BidiGenerateContentSetup.prefix_turns` will always remain at the beginning
    /// of the result.
    #[derive(Clone, PartialEq, ::prost::Message)]
    pub struct SlidingWindow {
        /// The target number of tokens to keep. The default value is
        /// trigger_tokens/2.
        ///
        /// Discarding parts of the context window causes a temporary latency
        /// increase so this value should be calibrated to avoid frequent compression
        /// operations.
        #[prost(int64, optional, tag = "1")]
        pub target_tokens: ::core::option::Option<i64>,
    }
    /// The context window compression mechanism used.
    #[derive(Clone, PartialEq, ::prost::Oneof)]
    pub enum CompressionMechanism {
        /// A sliding-window mechanism.
        #[prost(message, tag = "2")]
        SlidingWindow(SlidingWindow),
    }
}
/// The audio transcription configuration.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct AudioTranscriptionConfig {}
/// Message to be sent in the first (and only in the first)
/// `BidiGenerateContentClientMessage`. Contains configuration that will apply
/// for the duration of the streaming RPC.
///
/// Clients should wait for a `BidiGenerateContentSetupComplete` message before
/// sending any additional messages.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct BidiGenerateContentSetup {
    /// Required. The model's resource name. This serves as an ID for the Model to
    /// use.
    ///
    /// Format: `models/{model}`
    #[prost(string, tag = "1")]
    pub model: ::prost::alloc::string::String,
    /// Optional. Generation config.
    ///
    /// The following fields are not supported:
    ///
    ///   - `response_logprobs`
    ///   - `response_mime_type`
    ///   - `logprobs`
    ///   - `response_schema`
    ///   - `response_json_schema`
    ///   - `stop_sequence`
    ///   - `routing_config`
    ///   - `audio_timestamp`
    #[prost(message, optional, tag = "2")]
    pub generation_config: ::core::option::Option<GenerationConfig>,
    /// Optional. The user provided system instructions for the model.
    ///
    /// Note: Only text should be used in parts and content in each part will be
    /// in a separate paragraph.
    #[prost(message, optional, tag = "3")]
    pub system_instruction: ::core::option::Option<Content>,
    /// Optional. A list of `Tools` the model may use to generate the next
    /// response.
    ///
    /// A `Tool` is a piece of code that enables the system to interact with
    /// external systems to perform an action, or set of actions, outside of
    /// knowledge and scope of the model.
    #[prost(message, repeated, tag = "4")]
    pub tools: ::prost::alloc::vec::Vec<Tool>,
    /// Optional. Configures the handling of realtime input.
    #[prost(message, optional, tag = "6")]
    pub realtime_input_config: ::core::option::Option<RealtimeInputConfig>,
    /// Optional. Configures session resumption mechanism.
    ///
    /// If included, the server will send `SessionResumptionUpdate` messages.
    #[prost(message, optional, tag = "7")]
    pub session_resumption: ::core::option::Option<SessionResumptionConfig>,
    /// Optional. Configures a context window compression mechanism.
    ///
    /// If included, the server will automatically reduce the size of the context
    /// when it exceeds the configured length.
    #[prost(message, optional, tag = "8")]
    pub context_window_compression: ::core::option::Option<ContextWindowCompressionConfig>,
    /// Optional. If set, enables transcription of voice input. The transcription
    /// aligns with the input audio language, if configured.
    #[prost(message, optional, tag = "10")]
    pub input_audio_transcription: ::core::option::Option<AudioTranscriptionConfig>,
    /// Optional. If set, enables transcription of the model's audio output. The
    /// transcription aligns with the language code specified for the output
    /// audio, if configured.
    #[prost(message, optional, tag = "11")]
    pub output_audio_transcription: ::core::option::Option<AudioTranscriptionConfig>,
}
/// Incremental update of the current conversation delivered from the client.
/// All of the content here is unconditionally appended to the conversation
/// history and used as part of the prompt to the model to generate content.
///
/// A message here will interrupt any current model generation.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct BidiGenerateContentClientContent {
    /// Optional. The content appended to the current conversation with the model.
    ///
    /// For single-turn queries, this is a single instance. For multi-turn
    /// queries, this is a repeated field that contains conversation history and
    /// the latest request.
    #[prost(message, repeated, tag = "1")]
    pub turns: ::prost::alloc::vec::Vec<Content>,
    /// Optional. If true, indicates that the server content generation should
    /// start with the currently accumulated prompt. Otherwise, the server awaits
    /// additional messages before starting generation.
    #[prost(bool, tag = "2")]
    pub turn_complete: bool,
}
/// User input that is sent in real time.
///
/// The different modalities (audio, video and text) are handled as concurrent
/// streams. The ordering across these streams is not guaranteed.
///
/// This is different from
/// [BidiGenerateContentClientContent][google.ai.generativelanguage.v1beta.BidiGenerateContentClientContent]
/// in a few ways:
///
/// * Can be sent continuously without interruption to model generation.
/// * If there is a need to mix data interleaved across the
///    [BidiGenerateContentClientContent][google.ai.generativelanguage.v1beta.BidiGenerateContentClientContent]
///    and the
///    [BidiGenerateContentRealtimeInput][google.ai.generativelanguage.v1beta.BidiGenerateContentRealtimeInput],
///    the server attempts to optimize for best response, but there are no
///    guarantees.
/// * End of turn is not explicitly specified, but is rather derived from user
///    activity (for example, end of speech).
/// * Even before the end of turn, the data is processed incrementally
///    to optimize for a fast start of the response from the model.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct BidiGenerateContentRealtimeInput {
    /// Optional. Inlined bytes data for media input. Multiple `media_chunks` are
    /// not supported, all but the first will be ignored.
    ///
    /// DEPRECATED: Use one of `audio`, `video`, or `text` instead.
    #[prost(message, repeated, tag = "1")]
    pub media_chunks: ::prost::alloc::vec::Vec<Blob>,
    /// Optional. These form the realtime audio input stream.
    #[prost(message, optional, tag = "2")]
    pub audio: ::core::option::Option<Blob>,
    /// Optional. Indicates that the audio stream has ended, e.g. because the
    /// microphone was turned off.
    ///
    /// This should only be sent when automatic activity detection is enabled
    /// (which is the default).
    ///
    /// The client can reopen the stream by sending an audio message.
    #[prost(bool, optional, tag = "3")]
    pub audio_stream_end: ::core::option::Option<bool>,
    /// Optional. These form the realtime video input stream.
    #[prost(message, optional, tag = "4")]
    pub video: ::core::option::Option<Blob>,
    /// Optional. These form the realtime text input stream.
    #[prost(string, optional, tag = "5")]
    pub text: ::core::option::Option<::prost::alloc::string::String>,
    /// Optional. Marks the start of user activity. This can only be sent if
    /// automatic (i.e. server-side) activity detection is disabled.
    #[prost(message, optional, tag = "6")]
    pub activity_start: ::core::option::Option<bidi_generate_content_realtime_input::ActivityStart>,
    /// Optional. Marks the end of user activity. This can only be sent if
    /// automatic (i.e. server-side) activity detection is disabled.
    #[prost(message, optional, tag = "7")]
    pub activity_end: ::core::option::Option<bidi_generate_content_realtime_input::ActivityEnd>,
}
/// Nested message and enum types in `BidiGenerateContentRealtimeInput`.
pub mod bidi_generate_content_realtime_input {
    /// Marks the start of user activity.
    #[derive(Clone, PartialEq, ::prost::Message)]
    pub struct ActivityStart {}
    /// Marks the end of user activity.
    #[derive(Clone, PartialEq, ::prost::Message)]
    pub struct ActivityEnd {}
}
/// Client generated response to a `ToolCall` received from the server.
/// Individual `FunctionResponse` objects are matched to the respective
/// `FunctionCall` objects by the `id` field.
///
/// Note that in the unary and server-streaming GenerateContent APIs function
/// calling happens by exchanging the `Content` parts, while in the bidi
/// GenerateContent APIs function calling happens over these dedicated set of
/// messages.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct BidiGenerateContentToolResponse {
    /// Optional. The response to the function calls.
    #[prost(message, repeated, tag = "1")]
    pub function_responses: ::prost::alloc::vec::Vec<FunctionResponse>,
}
/// Messages sent by the client in the BidiGenerateContent call.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct BidiGenerateContentClientMessage {
    /// The type of the message.
    #[prost(
        oneof = "bidi_generate_content_client_message::MessageType",
        tags = "1, 2, 3, 4"
    )]
    pub message_type: ::core::option::Option<bidi_generate_content_client_message::MessageType>,
}
/// Nested message and enum types in `BidiGenerateContentClientMessage`.
pub mod bidi_generate_content_client_message {
    /// The type of the message.
    #[derive(Clone, PartialEq, ::prost::Oneof)]
    pub enum MessageType {
        /// Optional. Session configuration sent in the first and only first client
        /// message.
        #[prost(message, tag = "1")]
        Setup(super::BidiGenerateContentSetup),
        /// Optional. Incremental update of the current conversation delivered from
        /// the client.
        #[prost(message, tag = "2")]
        ClientContent(super::BidiGenerateContentClientContent),
        /// Optional. User input that is sent in real time.
        #[prost(message, tag = "3")]
        RealtimeInput(super::BidiGenerateContentRealtimeInput),
        /// Optional. Response to a `ToolCallMessage` received from the server.
        #[prost(message, tag = "4")]
        ToolResponse(super::BidiGenerateContentToolResponse),
    }
}
/// Sent in response to a `BidiGenerateContentSetup` message from the client.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct BidiGenerateContentSetupComplete {}
/// Incremental server update generated by the model in response to client
/// messages.
///
/// Content is generated as quickly as possible, and not in real time. Clients
/// may choose to buffer and play it out in real time.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct BidiGenerateContentServerContent {
    /// Output only. The content that the model has generated as part of the
    /// current conversation with the user.
    #[prost(message, optional, tag = "1")]
    pub model_turn: ::core::option::Option<Content>,
    /// Output only. If true, indicates that the model is done generating.
    ///
    /// When model is interrupted while generating there will be no
    /// 'generation_complete' message in interrupted turn, it will go through
    /// 'interrupted > turn_complete'.
    ///
    /// When model assumes realtime playback there will be delay between
    /// generation_complete and turn_complete that is caused by model waiting for
    /// playback to finish.
    #[prost(bool, tag = "5")]
    pub generation_complete: bool,
    /// Output only. If true, indicates that the model has completed its turn.
    /// Generation will only start in response to additional client messages.
    #[prost(bool, tag = "2")]
    pub turn_complete: bool,
    /// Output only. If true, indicates that a client message has interrupted
    /// current model generation. If the client is playing out the content in real
    /// time, this is a good signal to stop and empty the current playback queue.
    #[prost(bool, tag = "3")]
    pub interrupted: bool,
    /// Output only. Grounding metadata for the generated content.
    #[prost(message, optional, tag = "4")]
    pub grounding_metadata: ::core::option::Option<GroundingMetadata>,
    /// Output only. Input audio transcription. The transcription is sent
    /// independently of the other server messages and there is no guaranteed
    /// ordering.
    #[prost(message, optional, tag = "6")]
    pub input_transcription: ::core::option::Option<BidiGenerateContentTranscription>,
    /// Output only. Output audio transcription. These transcriptions are part of
    /// the Generation output of the server. The last output transcription of this
    /// turn is sent before either `generation_complete` or `interrupted`, which in
    /// turn are followed by `turn_complete`. There is no guaranteed exact ordering
    /// between transcriptions and other `model_turn` output but the server tries
    /// to send the transcripts close to the corresponding audio output.
    #[prost(message, optional, tag = "7")]
    pub output_transcription: ::core::option::Option<BidiGenerateContentTranscription>,
    #[prost(message, optional, tag = "9")]
    pub url_context_metadata: ::core::option::Option<UrlContextMetadata>,
}
/// Request for the client to execute the `function_calls` and return the
/// responses with the matching `id`s.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct BidiGenerateContentToolCall {
    /// Output only. The function call to be executed.
    #[prost(message, repeated, tag = "2")]
    pub function_calls: ::prost::alloc::vec::Vec<FunctionCall>,
}
/// Notification for the client that a previously issued `ToolCallMessage`
/// with the specified `id`s should not have been executed and should be
/// cancelled. If there were side-effects to those tool calls, clients may
/// attempt to undo the tool calls. This message occurs only in cases where the
/// clients interrupt server turns.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct BidiGenerateContentToolCallCancellation {
    /// Output only. The ids of the tool calls to be cancelled.
    #[prost(string, repeated, tag = "1")]
    pub ids: ::prost::alloc::vec::Vec<::prost::alloc::string::String>,
}
/// A notice that the server will soon disconnect.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct GoAway {
    /// The remaining time before the connection will be terminated as ABORTED.
    ///
    /// This duration will never be less than a model-specific minimum, which will
    /// be specified together with the rate limits for the model.
    #[prost(message, optional, tag = "1")]
    pub time_left: ::core::option::Option<::prost_types::Duration>,
}
/// Update of the session resumption state.
///
/// Only sent if `BidiGenerateContentSetup.session_resumption` was set.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct SessionResumptionUpdate {
    /// New handle that represents a state that can be resumed. Empty if
    /// `resumable`=false.
    #[prost(string, tag = "1")]
    pub new_handle: ::prost::alloc::string::String,
    /// True if the current session can be resumed at this point.
    ///
    /// Resumption is not possible at some points in the session. For example, when
    /// the model is executing function calls or generating. Resuming the session
    /// (using a previous session token) in such a state will result in some data
    /// loss. In these cases, `new_handle` will be empty and `resumable` will be
    /// false.
    #[prost(bool, tag = "2")]
    pub resumable: bool,
}
/// Transcription of audio (input or output).
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct BidiGenerateContentTranscription {
    /// Transcription text.
    #[prost(string, tag = "1")]
    pub text: ::prost::alloc::string::String,
}
/// Response message for the BidiGenerateContent call.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct BidiGenerateContentServerMessage {
    /// Output only. Usage metadata about the response(s).
    #[prost(message, optional, tag = "10")]
    pub usage_metadata: ::core::option::Option<UsageMetadata>,
    /// The type of the message.
    #[prost(
        oneof = "bidi_generate_content_server_message::MessageType",
        tags = "2, 3, 4, 5, 6, 7"
    )]
    pub message_type: ::core::option::Option<bidi_generate_content_server_message::MessageType>,
}
/// Nested message and enum types in `BidiGenerateContentServerMessage`.
pub mod bidi_generate_content_server_message {
    /// The type of the message.
    #[derive(Clone, PartialEq, ::prost::Oneof)]
    pub enum MessageType {
        /// Output only. Sent in response to a `BidiGenerateContentSetup` message
        /// from the client when setup is complete.
        #[prost(message, tag = "2")]
        SetupComplete(super::BidiGenerateContentSetupComplete),
        /// Output only. Content generated by the model in response to client
        /// messages.
        #[prost(message, tag = "3")]
        ServerContent(super::BidiGenerateContentServerContent),
        /// Output only. Request for the client to execute the `function_calls` and
        /// return the responses with the matching `id`s.
        #[prost(message, tag = "4")]
        ToolCall(super::BidiGenerateContentToolCall),
        /// Output only. Notification for the client that a previously issued
        /// `ToolCallMessage` with the specified `id`s should be cancelled.
        #[prost(message, tag = "5")]
        ToolCallCancellation(super::BidiGenerateContentToolCallCancellation),
        /// Output only. A notice that the server will soon disconnect.
        #[prost(message, tag = "6")]
        GoAway(super::GoAway),
        /// Output only. Update of the session resumption state.
        #[prost(message, tag = "7")]
        SessionResumptionUpdate(super::SessionResumptionUpdate),
    }
}
/// Usage metadata about response(s).
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct UsageMetadata {
    /// Output only. Number of tokens in the prompt. When `cached_content` is set,
    /// this is still the total effective prompt size meaning this includes the
    /// number of tokens in the cached content.
    #[prost(int32, tag = "1")]
    pub prompt_token_count: i32,
    /// Number of tokens in the cached part of the prompt (the cached content)
    #[prost(int32, tag = "4")]
    pub cached_content_token_count: i32,
    /// Output only. Total number of tokens across all the generated response
    /// candidates.
    #[prost(int32, tag = "2")]
    pub response_token_count: i32,
    /// Output only. Number of tokens present in tool-use prompt(s).
    #[prost(int32, tag = "8")]
    pub tool_use_prompt_token_count: i32,
    /// Output only. Number of tokens of thoughts for thinking models.
    #[prost(int32, tag = "10")]
    pub thoughts_token_count: i32,
    /// Output only. Total token count for the generation request (prompt +
    /// response candidates).
    #[prost(int32, tag = "3")]
    pub total_token_count: i32,
    /// Output only. List of modalities that were processed in the request input.
    #[prost(message, repeated, tag = "5")]
    pub prompt_tokens_details: ::prost::alloc::vec::Vec<ModalityTokenCount>,
    /// Output only. List of modalities of the cached content in the request input.
    #[prost(message, repeated, tag = "6")]
    pub cache_tokens_details: ::prost::alloc::vec::Vec<ModalityTokenCount>,
    /// Output only. List of modalities that were returned in the response.
    #[prost(message, repeated, tag = "7")]
    pub response_tokens_details: ::prost::alloc::vec::Vec<ModalityTokenCount>,
    /// Output only. List of modalities that were processed for tool-use request
    /// inputs.
    #[prost(message, repeated, tag = "9")]
    pub tool_use_prompt_tokens_details: ::prost::alloc::vec::Vec<ModalityTokenCount>,
}
/// Type of task for which the embedding will be used.
#[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord, ::prost::Enumeration)]
#[repr(i32)]
pub enum TaskType {
    /// Unset value, which will default to one of the other enum values.
    Unspecified = 0,
    /// Specifies the given text is a query in a search/retrieval setting.
    RetrievalQuery = 1,
    /// Specifies the given text is a document from the corpus being searched.
    RetrievalDocument = 2,
    /// Specifies the given text will be used for STS.
    SemanticSimilarity = 3,
    /// Specifies that the given text will be classified.
    Classification = 4,
    /// Specifies that the embeddings will be used for clustering.
    Clustering = 5,
    /// Specifies that the given text will be used for question answering.
    QuestionAnswering = 6,
    /// Specifies that the given text will be used for fact verification.
    FactVerification = 7,
    /// Specifies that the given text will be used for code retrieval.
    CodeRetrievalQuery = 8,
}
impl TaskType {
    /// String value of the enum field names used in the ProtoBuf definition.
    ///
    /// The values are not transformed in any way and thus are considered stable
    /// (if the ProtoBuf definition does not change) and safe for programmatic use.
    pub fn as_str_name(&self) -> &'static str {
        match self {
            Self::Unspecified => "TASK_TYPE_UNSPECIFIED",
            Self::RetrievalQuery => "RETRIEVAL_QUERY",
            Self::RetrievalDocument => "RETRIEVAL_DOCUMENT",
            Self::SemanticSimilarity => "SEMANTIC_SIMILARITY",
            Self::Classification => "CLASSIFICATION",
            Self::Clustering => "CLUSTERING",
            Self::QuestionAnswering => "QUESTION_ANSWERING",
            Self::FactVerification => "FACT_VERIFICATION",
            Self::CodeRetrievalQuery => "CODE_RETRIEVAL_QUERY",
        }
    }
    /// Creates an enum from field names used in the ProtoBuf definition.
    pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
        match value {
            "TASK_TYPE_UNSPECIFIED" => Some(Self::Unspecified),
            "RETRIEVAL_QUERY" => Some(Self::RetrievalQuery),
            "RETRIEVAL_DOCUMENT" => Some(Self::RetrievalDocument),
            "SEMANTIC_SIMILARITY" => Some(Self::SemanticSimilarity),
            "CLASSIFICATION" => Some(Self::Classification),
            "CLUSTERING" => Some(Self::Clustering),
            "QUESTION_ANSWERING" => Some(Self::QuestionAnswering),
            "FACT_VERIFICATION" => Some(Self::FactVerification),
            "CODE_RETRIEVAL_QUERY" => Some(Self::CodeRetrievalQuery),
            _ => None,
        }
    }
}
