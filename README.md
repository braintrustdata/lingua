# Lingua - A low-level library for translating between LLM formats

Lingua is a library and specification for defining a universal message format for large language model APIs. It enables developers to write messages, model parameters, and tool definitions in a single format that can be translated to and from any model provider's API client-side with zero runtime overhead.

## Goals

- You should be able to write messages, model parameters, and tool definitions in this format, and use them with any version of any model provider.
- The spec describes how message data is represented, and the implementation converts to-and-from model provider APIs and popular frameworks.
- ~Zero runtime overhead, because there is no execution logic. The sole purpose of this project is to define a universal message format that can be translated across different model providers.

## Anti-goals

- **Framework.** This project is explicitly _not_ providing any higher-level abstractions, guidance on how to structure your app, or model execution support. Frameworks can build on top of Lingua to avoid reimplementing model-provider translation.
- **Proxy.** This format could be used as the foundation for a proxy implementation, but has no concept of actually running prompts or handling authentication.
- **Optimization.** Messages written in this format will execute _exactly_ what you would expect from the model provider. 3rd party optimizers can be built on the format, and those optimizers will naturally work across providers.

## Principles

- Supports 100% of model-provider specific quirks (eg cache breakpoints, stateful responses).
- Messages you write in this format should be safe to store and survive many years of changes in model behavior and API versions.
- Zero dependencies and support for many languages including Typescript, Python, Java, Golang. Ideally can cross-compile or trivial for AI to generate support in language N+1.
- Code and tests are structured to facilitate coding agents to efficiently add new providers and support new features.
- Has a precise definition of usage (token) reporting that can be used to compute cost from a standard price table across providers.

## Architecture

```
Lingua Universal Format
         â†“
    Capability Detection
         â†“
   Provider Translators
         â†“
OpenAI â”‚ Anthropic â”‚ Google â”‚ Bedrock â”‚ ...
```

## Capabilities

[ ... list the known capabilities ... ]

## Compatability matrix

[ .. for each provider, list which capabilities are supported ... ]

## Project structure

```
lingua/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ universal/             # Universal Lingua format definitions
â”‚   â”œâ”€â”€ providers/             # Provider-specific API types
â”‚   â”œâ”€â”€ translators/           # Translation logic between formats
â”‚   â”œâ”€â”€ capabilities/          # Capability detection system
â”‚   â”œâ”€â”€ wasm.rs                # WebAssembly bindings
â”‚   â”œâ”€â”€ python.rs              # Python bindings (PyO3)
â”‚   â””â”€â”€ lib.rs                 # Main library entry
â”œâ”€â”€ bindings/
â”‚   â”œâ”€â”€ typescript/            # TypeScript/WASM bindings
â”‚   â””â”€â”€ python/                # Python bindings
â”œâ”€â”€ examples/                  # Usage examples
â””â”€â”€ tests/typescript/          # TypeScript compatibility tests
```

## Building bindings

Use the Makefile for easy building:

```bash
# Show all available targets
make help

# Build all bindings
make all

# Build specific bindings
make typescript
make python

# Run tests
make test
make test-rust
make test-typescript
make test-python

# Clean build artifacts
make clean
```

### TypeScript/WASM bindings

```bash
cd bindings/typescript
npm install
npm run build
npm test
```

See [bindings/typescript/README.md](bindings/typescript/README.md) for details.

### Python bindings

```bash
cd bindings/python
uv sync --extra dev
uv run pytest tests/
```

See [bindings/python/README.md](bindings/python/README.md) for details.

## Update pipeline

These two primitives make it very easy to, for example, reproduce how tool calls are represented in each of the major model providers, snapshot inputs/outputs, and then fill in logic to translate between them. Some of that has been handwritten,
but a lot of it is generated by LLMs. In general, a goal of this project is create enough scaffolding so that you can open a coding agent and say "fix support for parallel tool calls" and there should be enough context for an LLM to add the test
cases, generate snapshots, and make the necessary changes.

### LLM API pipeline

OpenAI and Anthropic do not have Rust SDKs, but they do publish OpenAPI specs, so we fetch those and use `quicktype` (with a few hacks) to generate Rust types. These types generally work but do not have really great discriminated unions (like they do in Typescript). Google has protobufs, which we are able to convert to Rust types, and Bedrock actually publishes a Rust SDK.

## Testing Strategy

Lingua employs a comprehensive testing strategy to ensure accurate and lossless conversion between provider-specific formats and the universal format.

### Roundtrip Testing

The core testing approach uses **roundtrip conversion tests** to verify that data can be converted from provider format â†’ universal format â†’ provider format without loss:

```
Provider Payload â†’ Universal ModelMessage â†’ Provider Payload
     (input)            (conversion)          (output)
```

**Key test scenarios:**

1. **Request Roundtrips**:

   - `openai_request â†’ universal â†’ openai_request` (should be identical)
   - `anthropic_request â†’ universal â†’ anthropic_request` (should be identical)

2. **Response Roundtrips**:

   - `openai_response â†’ universal â†’ openai_response` (should be identical)
   - `anthropic_response â†’ universal â†’ anthropic_response` (should be identical)

3. **Cross-Provider Compatibility**:
   - `openai_request â†’ universal â†’ anthropic_request` (should be equivalent)
   - `anthropic_response â†’ universal â†’ openai_response` (should be equivalent)

### Payload-Based Testing

Tests use **real API payloads** captured from actual provider interactions:

- **Payload Snapshots**: Located in `paylods/snapshots/` directory with real request/response examples
- **Comprehensive Coverage**: Tests cover simple messages, tool calls, streaming responses, multi-modal content
- **Version Tracking**: Payloads are version-controlled to detect breaking changes in provider APIs

### Testing Levels

1. **Unit Tests**: Individual conversion functions with synthetic data
2. **Integration Tests**: Full roundtrip tests using real payload snapshots
3. **Compatibility Tests**: Cross-provider conversion validation
4. **Regression Tests**: Ensure updates don't break existing functionality

This strategy ensures Lingua maintains 100% fidelity when converting between provider formats while providing confidence that the universal format can represent any provider-specific capability.

### Automated Updates

Provider types can be automatically updated using GitHub Actions:

1. **Manual trigger**: Go to Actions â†’ "Update Provider Types" â†’ Run workflow
2. **Choose providers**: Select `all`, or specific providers like `openai,anthropic`
3. **Automatic PR**: If changes are detected, a PR will be created automatically

The automation downloads the latest specifications, regenerates types, applies formatting, and creates a pull request for review.

## Tests / interesting cases

- [ ] Show token accounting across providers. Ideally we give users a way to access the provider's native usage + a unified format.
- [ ] How does structured outputs + Anthropic work? Translate to tool, and parse the response? Does that require carrying some state across request/response? Maybe we can generate an object when performing the forward translation that can be used in the reverse translation.
- [ ] Audit and remove all remaining `todo!()` calls

## Feature Flags

Lingua supports optional provider dependencies through feature flags to minimize build time and binary size:

### Available Features

- **`openai`** - OpenAI API types and translators
- **`anthropic`** - Anthropic API types and translators
- **`google`** - Google Gemini API types and translators
- **`bedrock`** - Amazon Bedrock API types and translators (pulls in AWS SDK)

### Usage

**Default (all providers):**

```toml
[dependencies]
lingua = "0.1.0"
```

**Minimal (only OpenAI):**

```toml
[dependencies]
lingua = { version = "0.1.0", default-features = false, features = ["openai"] }
```

**Without AWS dependencies:**

```toml
[dependencies]
lingua = { version = "0.1.0", default-features = false, features = ["openai", "anthropic", "google"] }
```

**Only Bedrock:**

```toml
[dependencies]
lingua = { version = "0.1.0", default-features = false, features = ["bedrock"] }
```

### Conditional Compilation

The translators and types are only available when their respective features are enabled:

```rust
#[cfg(feature = "openai")]
use lingua::translators::to_openai_format;

#[cfg(feature = "bedrock")]
use lingua::translators::to_bedrock_format_with_model;
```

## Status

ðŸš§ **In Development** - Currently building the foundational types and translator architecture.

- [ ] Support parsing streaming responses and combining streaming messages into a single response.

## Contributing

This project aims to support the entire ecosystem of LLM providers. Contributions for new providers, capability detection improvements, and format enhancements are welcome.

### Developer Setup

Prerequisites: Rust toolchain, Node.js, pnpm.

Run `./scripts/setup.sh` from the project root after cloning. If the script succeeds, you should be all set! Otherwise, follow the error messages.

### TypeScript Type Generation

TypeScript types for the universal `Message` format are automatically generated from Rust types using [ts-rs](https://github.com/Aleph-Alpha/ts-rs):

```bash
# Generate TypeScript types from Rust
make generate-types

# Generated files: bindings/typescript/src/generated/*.ts
```

**Important**: After modifying Rust types in `src/universal/`, run `make generate-types` and commit the updated TypeScript files. CI will verify that generated types are up to date.

## License

TBD
