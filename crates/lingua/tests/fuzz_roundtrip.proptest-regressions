# Seeds for failure cases proptest has generated in the past. It is
# automatically read and these particular cases re-run before any
# novel cases are generated.
#
# It is recommended to check this file in to source control so that
# everyone who runs the test benefits from these saved cases.
cc 571bebd27a681a4afddc88a50ab68906c2411c4653316c807667968e1da77dbf # shrinks to content = Array([Text(TextContentPart { text: "a", provider_options: None })])
cc 9c78a0e43216173390bc5704b23d8c3f03e950c41b292798b57e71ffa7b3e460 # shrinks to req = UniversalRequest { model: None, messages: [System { content: Array([Text(TextContentPart { text: "0", provider_options: None })]) }], params: UniversalParams { temperature: None, top_p: None, top_k: None, seed: None, presence_penalty: None, frequency_penalty: None, max_tokens: None, stop: None, logprobs: None, top_logprobs: None, tools: None, tool_choice: None, parallel_tool_calls: None, response_format: None, reasoning: None, metadata: None, store: None, service_tier: None, stream: None, extras: {} } }
cc f4f66bfaf60b020ad8dd448344f0127d0ffbf59ce9d042ee4755eb43d1de9131 # shrinks to req = UniversalRequest { model: None, messages: [Tool { content: [ToolResult(ToolResultContentPart { tool_call_id: "call_0aA00a00", tool_name: "___", output: Null, provider_options: None }), ToolResult(ToolResultContentPart { tool_call_id: "call_A0aaaaAA", tool_name: "aaa", output: Null, provider_options: None })] }], params: UniversalParams { temperature: None, top_p: None, top_k: None, seed: None, presence_penalty: None, frequency_penalty: None, max_tokens: None, stop: None, logprobs: None, top_logprobs: None, tools: None, tool_choice: None, parallel_tool_calls: None, response_format: None, reasoning: None, metadata: None, store: None, service_tier: None, stream: None, extras: {} } }
cc 3b06f6ee7178d80cdcf18873d071b554ef516e474543d66deee9c2bc3e2dcaec # shrinks to req = UniversalRequest { model: None, messages: [Tool { content: [ToolResult(ToolResultContentPart { tool_call_id: "call_0aaAAAA0", tool_name: "aa_", output: Null, provider_options: None }), ToolResult(ToolResultContentPart { tool_call_id: "call_0aaAAAaa", tool_name: "___", output: Null, provider_options: None })] }], params: UniversalParams { temperature: None, top_p: None, top_k: None, seed: None, presence_penalty: None, frequency_penalty: None, max_tokens: None, stop: None, logprobs: None, top_logprobs: None, tools: None, tool_choice: None, parallel_tool_calls: None, response_format: None, reasoning: None, metadata: None, store: None, service_tier: None, stream: None, extras: {} } }
cc 992d77a84f2c6777ee72c0183797d3015725b3d04feee90c992a94d4f5478aea # shrinks to req = UniversalRequest { model: None, messages: [Tool { content: [ToolResult(ToolResultContentPart { tool_call_id: "call_a00Aaa0a", tool_name: "a_a", output: Null, provider_options: None }), ToolResult(ToolResultContentPart { tool_call_id: "call_A0Aa00a0", tool_name: "_a_", output: Null, provider_options: None })] }], params: UniversalParams { temperature: None, top_p: None, top_k: None, seed: None, presence_penalty: None, frequency_penalty: None, max_tokens: None, stop: None, logprobs: None, top_logprobs: None, tools: None, tool_choice: None, parallel_tool_calls: None, response_format: None, reasoning: None, metadata: None, store: None, service_tier: None, stream: None, extras: {} } }
